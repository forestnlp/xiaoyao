{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b97edb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用中文字体: ['SimHei', 'Microsoft YaHei', 'Arial Unicode MS']\n",
      "加载全量数据中...\n",
      "数据时间范围: 2005-01-04 至 2025-09-25\n",
      "总数据量: 15,039,052 条记录\n",
      "\n",
      "训练集（2024年）数据量: 1,236,214 条\n",
      "测试集（2025年）数据量: 925,900 条\n",
      "\n",
      "计算情绪特征...\n",
      "计算上涨比例...\n",
      "\n",
      "准备训练数据...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_mean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 374\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;66;03m# 4. 准备训练数据（标准化特征+生成目标变量）\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m准备训练数据...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 374\u001b[0m train_data, normalized_feature_cols, norm_params \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_training_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_rise_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlag_days\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m    378\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;66;03m# 5. 准备测试数据（使用训练集的标准化参数）\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m准备测试数据...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 197\u001b[0m, in \u001b[0;36mprepare_training_data\u001b[1;34m(features_df, rise_ratio_df, lag_days)\u001b[0m\n\u001b[0;32m    195\u001b[0m         merged_df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormalized_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m merged_df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormalized_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mclip(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtrain_mean\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m         normalized, params \u001b[38;5;241m=\u001b[39m normalize_feature(\n\u001b[0;32m    199\u001b[0m             merged_df[col], \n\u001b[0;32m    200\u001b[0m             higher_better\u001b[38;5;241m=\u001b[39mfeature_params[col][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhigher_better\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    201\u001b[0m         )\n\u001b[0;32m    202\u001b[0m         merged_df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormalized_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m normalized\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_mean' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# ---------------------- 中文显示配置 ----------------------\n",
    "def setup_chinese_font():\n",
    "    \"\"\"配置matplotlib以正确显示中文\"\"\"\n",
    "    try:\n",
    "        font_names = set()\n",
    "        font_files = fm.findSystemFonts()\n",
    "        \n",
    "        for font_file in font_files:\n",
    "            try:\n",
    "                font_prop = fm.FontProperties(fname=font_file)\n",
    "                font_names.add(font_prop.get_name())\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        chinese_fonts = [\"SimHei\", \"Microsoft YaHei\", \"Heiti TC\", \"WenQuanYi Micro Hei\", \"Arial Unicode MS\"]\n",
    "        available_fonts = [f for f in chinese_fonts if f in font_names]\n",
    "        \n",
    "        if available_fonts:\n",
    "            plt.rcParams[\"font.family\"] = available_fonts\n",
    "            print(f\"使用中文字体: {available_fonts}\")\n",
    "        else:\n",
    "            print(\"警告：未找到中文字体，可能会显示乱码。\")\n",
    "            plt.rcParams[\"font.family\"] = [\"Arial Unicode MS\", \"sans-serif\"]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"字体配置警告: {str(e)}\")\n",
    "        plt.rcParams[\"font.family\"] = [\"SimHei\", \"Microsoft YaHei\", \"sans-serif\"]\n",
    "    \n",
    "    plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "setup_chinese_font()\n",
    "\n",
    "# ---------------------- 数据预处理与特征计算 ----------------------\n",
    "def calculate_sentiment_features(daily_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"计算情绪指标的原始特征（用于后续机器学习优化权重）\"\"\"\n",
    "    df = daily_data.copy()\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.sort_values(['date', 'stock_code'])\n",
    "    \n",
    "    # 个股级指标\n",
    "    df['daily_return'] = (df['close'] - df['open']) / df['open'] * 100\n",
    "    df['is_limit_up'] = (df['close'] >= df['high_limit']).astype(int)\n",
    "    df['is_limit_down'] = (df['close'] <= df['low_limit']).astype(int)\n",
    "    df['is_up'] = (df['daily_return'] > 0).astype(int)\n",
    "    \n",
    "    # 市场级特征（原始指标，未标准化）\n",
    "    daily_features = df.groupby('date').agg(\n",
    "        total_stocks=('stock_code', 'nunique'),\n",
    "        up_stocks=('is_up', 'sum'),\n",
    "        down_stocks=('is_up', lambda x: sum(1 - x)),\n",
    "        limit_up_stocks=('is_limit_up', 'sum'),\n",
    "        limit_down_stocks=('is_limit_down', 'sum'),\n",
    "        avg_return=('daily_return', 'mean'),\n",
    "        total_volume=('volume', 'sum'),\n",
    "        up_volume=('volume', lambda x: x[df.loc[x.index, 'is_up'] == 1].mean() if sum(df.loc[x.index, 'is_up']) > 0 else 0),\n",
    "        down_volume=('volume', lambda x: x[df.loc[x.index, 'is_up'] == 0].mean() if sum(1 - df.loc[x.index, 'is_up']) > 0 else 0)\n",
    "    ).reset_index()\n",
    "    \n",
    "    # 计算核心特征（与原逻辑一致，但保留原始值用于后续标准化）\n",
    "    daily_features['up_down_ratio'] = np.where(\n",
    "        daily_features['down_stocks'] > 0,\n",
    "        daily_features['up_stocks'] / daily_features['down_stocks'],\n",
    "        10\n",
    "    )\n",
    "    \n",
    "    daily_features['limit_spread_ratio'] = (\n",
    "        daily_features['limit_up_stocks'] + daily_features['limit_down_stocks']\n",
    "    ) / daily_features['total_stocks']\n",
    "    \n",
    "    daily_features['volume_price_fit'] = (\n",
    "        daily_features['up_volume'] / daily_features['down_volume']\n",
    "    ).rolling(window=5, min_periods=1).mean()\n",
    "    \n",
    "    daily_features['volume_expansion'] = (\n",
    "        daily_features['total_volume'] / \n",
    "        daily_features['total_volume'].rolling(window=20, min_periods=5).mean()\n",
    "    )\n",
    "    \n",
    "    daily_features['price_volatility'] = daily_features['avg_return'].abs()\n",
    "    \n",
    "    # 保留原始特征（后续会基于训练集标准化）\n",
    "    return daily_features\n",
    "\n",
    "def calculate_rise_ratio(daily_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"计算每日上涨股票比例（预测目标）\"\"\"\n",
    "    df = daily_data.copy()\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['prev_close'] = df.groupby('stock_code')['close'].shift(1)\n",
    "    df['is_rise'] = (df['close'] > df['prev_close']).astype(int)\n",
    "    \n",
    "    rise_ratio_df = df.groupby('date').agg(\n",
    "        total_stocks=('stock_code', 'nunique'),\n",
    "        rise_stocks=('is_rise', 'sum')\n",
    "    ).reset_index()\n",
    "    \n",
    "    rise_ratio_df['rise_ratio'] = rise_ratio_df['rise_stocks'] / rise_ratio_df['total_stocks']\n",
    "    rise_ratio_df = rise_ratio_df.dropna(subset=['rise_ratio'])\n",
    "    rise_ratio_df = rise_ratio_df[(rise_ratio_df['rise_ratio'] >= 0) & (rise_ratio_df['rise_ratio'] <= 1)]\n",
    "    \n",
    "    return rise_ratio_df[['date', 'rise_ratio']]\n",
    "\n",
    "# ---------------------- 特征标准化与标签生成 ----------------------\n",
    "def prepare_training_data(features_df, rise_ratio_df, lag_days=1):\n",
    "    \"\"\"\n",
    "    准备训练数据：\n",
    "    1. 特征标准化（基于训练集的均值和标准差）\n",
    "    2. 生成滞后的目标变量（次日上涨比例）\n",
    "    \"\"\"\n",
    "    # 合并特征与目标变量（滞后N天）\n",
    "    rise_ratio_shifted = rise_ratio_df.copy()\n",
    "    rise_ratio_shifted['date'] = rise_ratio_shifted['date'] - pd.Timedelta(days=lag_days)\n",
    "    \n",
    "    merged_df = pd.merge(\n",
    "        features_df, \n",
    "        rise_ratio_shifted[['date', 'rise_ratio']], \n",
    "        on='date', \n",
    "        how='inner'\n",
    "    ).dropna(subset=['rise_ratio'])\n",
    "    \n",
    "    # 定义用于预测的特征列（5个核心指标）\n",
    "    feature_cols = [\n",
    "        'up_down_ratio', \n",
    "        'volume_price_fit', \n",
    "        'volume_expansion', \n",
    "        'price_volatility', \n",
    "        'limit_spread_ratio'\n",
    "    ]\n",
    "    \n",
    "    # 对特征进行特殊标准化（根据指标特性）\n",
    "    def normalize_feature(series, higher_better=True, train_mean=None, train_std=None):\n",
    "        \"\"\"\n",
    "        标准化特征：\n",
    "        - 对正向指标（越高越好）：(x - min)/(max - min)\n",
    "        - 对负向指标（越低越好）：1 - (x - min)/(max - min)\n",
    "        - 对中性指标（适度最好）：特殊处理\n",
    "        \"\"\"\n",
    "        if train_mean is None:  # 训练集标准化\n",
    "            min_val = series.min()\n",
    "            max_val = series.max()\n",
    "            if max_val == min_val:\n",
    "                return series.transform(lambda x: 0.5), (min_val, max_val)\n",
    "            \n",
    "            if higher_better:\n",
    "                normalized = (series - min_val) / (max_val - min_val)\n",
    "            else:\n",
    "                normalized = 1 - (series - min_val) / (max_val - min_val)\n",
    "            return normalized, (min_val, max_val)\n",
    "        else:  # 测试集标准化（使用训练集的min/max）\n",
    "            min_val, max_val = train_mean\n",
    "            if max_val == min_val:\n",
    "                return series.transform(lambda x: 0.5)\n",
    "            \n",
    "            if higher_better:\n",
    "                normalized = (series - min_val) / (max_val - min_val)\n",
    "            else:\n",
    "                normalized = 1 - (series - min_val) / (max_val - min_val)\n",
    "            # 处理测试集超出训练集范围的情况\n",
    "            return normalized.clip(0, 1)\n",
    "    \n",
    "    # 为每个特征定义标准化方式（根据指标特性）\n",
    "    feature_params = {\n",
    "        'up_down_ratio': {'higher_better': True},         # 正向指标\n",
    "        'volume_price_fit': {'higher_better': True},      # 正向指标\n",
    "        'volume_expansion': {'higher_better': True},      # 正向指标\n",
    "        'price_volatility': {'higher_better': False},     # 中性指标（特殊处理）\n",
    "        'limit_spread_ratio': {'higher_better': False}    # 负向指标\n",
    "    }\n",
    "    \n",
    "    # 存储每个特征的标准化参数（用于测试集）\n",
    "    normalization_params = {}\n",
    "    \n",
    "    # 标准化特征\n",
    "    for col in feature_cols:\n",
    "        if col == 'price_volatility':\n",
    "            # 价格波动：适度波动最好（0.3-0.7区间）\n",
    "            if train_mean is None:\n",
    "                series = merged_df[col]\n",
    "                min_val = series.min()\n",
    "                max_val = series.max()\n",
    "                normalized = 1 - (series - 0.5).abs() * 2  # 转换为0-1\n",
    "                merged_df[f'normalized_{col}'] = normalized.clip(0, 1)\n",
    "                normalization_params[col] = (min_val, max_val)\n",
    "            else:\n",
    "                merged_df[f'normalized_{col}'] = 1 - (merged_df[col] - 0.5).abs() * 2\n",
    "                merged_df[f'normalized_{col}'] = merged_df[f'normalized_{col}'].clip(0, 1)\n",
    "        else:\n",
    "            if train_mean is None:\n",
    "                normalized, params = normalize_feature(\n",
    "                    merged_df[col], \n",
    "                    higher_better=feature_params[col]['higher_better']\n",
    "                )\n",
    "                merged_df[f'normalized_{col}'] = normalized\n",
    "                normalization_params[col] = params\n",
    "            else:\n",
    "                normalized = normalize_feature(\n",
    "                    merged_df[col], \n",
    "                    higher_better=feature_params[col]['higher_better'],\n",
    "                    train_mean=train_mean[col]\n",
    "                )\n",
    "                merged_df[f'normalized_{col}'] = normalized\n",
    "    \n",
    "    # 提取标准化后的特征列\n",
    "    normalized_feature_cols = [f'normalized_{col}' for col in feature_cols]\n",
    "    \n",
    "    return merged_df, normalized_feature_cols, normalization_params\n",
    "\n",
    "# ---------------------- 机器学习优化权重 ----------------------\n",
    "def optimize_sentiment_weights(train_data, normalized_feature_cols):\n",
    "    \"\"\"\n",
    "    使用线性回归（带正则化）优化特征权重，目标是最大化对次日上涨比例的预测能力\n",
    "    \"\"\"\n",
    "    # 特征矩阵（X）和目标变量（y）\n",
    "    X_train = train_data[normalized_feature_cols]\n",
    "    y_train = train_data['rise_ratio']\n",
    "    \n",
    "    # 使用带L2正则化的Ridge回归（避免过拟合）\n",
    "    # 时间序列交叉验证确定最优正则化参数\n",
    "    best_alpha = 0\n",
    "    best_score = -np.inf\n",
    "    alphas = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "    \n",
    "    tscv = TimeSeriesSplit(n_splits=5)  # 时间序列交叉验证（避免数据泄露）\n",
    "    \n",
    "    for alpha in alphas:\n",
    "        model = Ridge(alpha=alpha, random_state=42)\n",
    "        scores = cross_val_score(model, X_train, y_train, cv=tscv, scoring='r2')\n",
    "        mean_score = np.mean(scores)\n",
    "        \n",
    "        if mean_score > best_score:\n",
    "            best_score = mean_score\n",
    "            best_alpha = alpha\n",
    "    \n",
    "    # 用最优参数训练模型\n",
    "    final_model = Ridge(alpha=best_alpha, random_state=42)\n",
    "    final_model.fit(X_train, y_train)\n",
    "    \n",
    "    # 提取权重（并归一化到总和为1）\n",
    "    weights = final_model.coef_\n",
    "    weights = np.abs(weights)  # 取绝对值（确保权重为正）\n",
    "    weights = weights / np.sum(weights)  # 归一化\n",
    "    \n",
    "    # 输出权重\n",
    "    feature_names = [col.replace('normalized_', '') for col in normalized_feature_cols]\n",
    "    weight_df = pd.DataFrame({\n",
    "        '特征名称': feature_names,\n",
    "        '优化后权重': weights.round(4)\n",
    "    })\n",
    "    \n",
    "    print(\"\\n===== 机器学习优化后的特征权重 =====\")\n",
    "    print(weight_df)\n",
    "    \n",
    "    # 训练集上的R²分数（解释力）\n",
    "    y_pred = final_model.predict(X_train)\n",
    "    train_r2 = r2_score(y_train, y_pred)\n",
    "    print(f\"\\n训练集R²分数（解释力）：{train_r2:.4f}\")\n",
    "    \n",
    "    return weights, final_model, weight_df\n",
    "\n",
    "# ---------------------- 验证优化后的情绪指标 ----------------------\n",
    "def validate_optimized_sentiment(test_data, normalized_feature_cols, weights, normalization_params):\n",
    "    \"\"\"使用优化后的权重计算情绪得分，并验证其与上涨比例的相关性\"\"\"\n",
    "    # 计算优化后的情绪得分（加权求和）\n",
    "    feature_names = [col.replace('normalized_', '') for col in normalized_feature_cols]\n",
    "    test_data['optimized_sentiment'] = 0\n",
    "    \n",
    "    for i, col in enumerate(normalized_feature_cols):\n",
    "        test_data['optimized_sentiment'] += test_data[col] * weights[i]\n",
    "    \n",
    "    # 转换为0-100分\n",
    "    test_data['optimized_sentiment'] = test_data['optimized_sentiment'] * 100\n",
    "    \n",
    "    # 计算相关性\n",
    "    pearson_corr, pearson_pvalue = stats.pearsonr(\n",
    "        test_data['optimized_sentiment'], \n",
    "        test_data['rise_ratio']\n",
    "    )\n",
    "    \n",
    "    spearman_corr, spearman_pvalue = stats.spearmanr(\n",
    "        test_data['optimized_sentiment'], \n",
    "        test_data['rise_ratio']\n",
    "    )\n",
    "    \n",
    "    print(\"\\n===== 优化后情绪指标与次日上涨比例的相关性 =====\")\n",
    "    print(f\"皮尔逊相关系数：{pearson_corr:.4f}，p值：{pearson_pvalue:.4f}\")\n",
    "    print(f\"斯皮尔曼相关系数：{spearman_corr:.4f}，p值：{spearman_pvalue:.4f}\")\n",
    "    \n",
    "    # 按情绪区间分组（0-25,25-50,50-75,75-100）\n",
    "    test_data['sentiment_bin'] = pd.cut(\n",
    "        test_data['optimized_sentiment'],\n",
    "        bins=[0, 25, 50, 75, 100],\n",
    "        labels=['极度悲观', '谨慎', '乐观', '狂热']\n",
    "    )\n",
    "    \n",
    "    group_stats = test_data.groupby('sentiment_bin')['rise_ratio'].agg(\n",
    "        平均上涨比例='mean',\n",
    "        样本数量='count',\n",
    "        标准差='std'\n",
    "    ).reset_index()\n",
    "    \n",
    "    print(\"\\n===== 不同情绪区间对应的次日上涨比例统计 =====\")\n",
    "    print(group_stats.round(4))\n",
    "    \n",
    "    # 可视化对比（优化前后）\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # 1. 优化后情绪得分与次日上涨比例的散点图\n",
    "    plt.subplot(2, 1, 1)\n",
    "    sns.scatterplot(x='optimized_sentiment', y='rise_ratio', data=test_data, alpha=0.6)\n",
    "    plt.title(f'优化后情绪得分与次日上涨比例的关系 (r={pearson_corr:.2f})')\n",
    "    plt.xlabel('优化后情绪得分（0-100）')\n",
    "    plt.ylabel('次日上涨股票比例')\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    # 2. 不同情绪区间的上涨比例箱线图\n",
    "    plt.subplot(2, 1, 2)\n",
    "    sns.boxplot(x='sentiment_bin', y='rise_ratio', data=test_data, \n",
    "                order=['极度悲观', '谨慎', '乐观', '狂热'])\n",
    "    plt.title('优化后不同情绪区间对应的次日上涨比例分布')\n",
    "    plt.xlabel('情绪区间')\n",
    "    plt.ylabel('次日上涨股票比例')\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('optimized_sentiment_vs_rise_ratio.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"\\n可视化图表已保存至 optimized_sentiment_vs_rise_ratio.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    return test_data, pearson_corr, spearman_corr\n",
    "\n",
    "# ---------------------- 主函数 ----------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. 加载全量数据（包含2024和2025年）\n",
    "    print(\"加载全量数据中...\")\n",
    "    try:\n",
    "        # 替换为你的数据路径（确保包含2024和2025年数据）\n",
    "        df = pd.read_parquet(r\"D:\\workspace\\xiaoyao\\data\\stock_daily_price.parquet\")\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        \n",
    "        # 检查数据时间范围\n",
    "        print(f\"数据时间范围: {df['date'].min().date()} 至 {df['date'].max().date()}\")\n",
    "        print(f\"总数据量: {len(df):,} 条记录\")\n",
    "    except Exception as e:\n",
    "        print(f\"数据加载失败: {str(e)}\")\n",
    "        exit(1)\n",
    "    \n",
    "    # 2. 划分训练集（2024年）和测试集（2025年）\n",
    "    train_df = df[df['date'].dt.year == 2024].copy()\n",
    "    test_df = df[df['date'].dt.year == 2025].copy()\n",
    "    \n",
    "    print(f\"\\n训练集（2024年）数据量: {len(train_df):,} 条\")\n",
    "    print(f\"测试集（2025年）数据量: {len(test_df):,} 条\")\n",
    "    \n",
    "    # 3. 计算特征和目标变量\n",
    "    print(\"\\n计算情绪特征...\")\n",
    "    train_features = calculate_sentiment_features(train_df)\n",
    "    test_features = calculate_sentiment_features(test_df)\n",
    "    \n",
    "    print(\"计算上涨比例...\")\n",
    "    train_rise_ratio = calculate_rise_ratio(train_df)\n",
    "    test_rise_ratio = calculate_rise_ratio(test_df)\n",
    "    \n",
    "    # 4. 准备训练数据（标准化特征+生成目标变量）\n",
    "    print(\"\\n准备训练数据...\")\n",
    "    train_data, normalized_feature_cols, norm_params = prepare_training_data(\n",
    "        train_features, \n",
    "        train_rise_ratio, \n",
    "        lag_days=1\n",
    "    )\n",
    "    \n",
    "    # 5. 准备测试数据（使用训练集的标准化参数）\n",
    "    print(\"准备测试数据...\")\n",
    "    test_data, _, _ = prepare_training_data(\n",
    "        test_features, \n",
    "        test_rise_ratio, \n",
    "        lag_days=1,\n",
    "        train_mean=norm_params  # 关键：使用训练集的标准化参数\n",
    "    )\n",
    "    \n",
    "    print(f\"训练样本量: {len(train_data)} 个交易日\")\n",
    "    print(f\"测试样本量: {len(test_data)} 个交易日\")\n",
    "    \n",
    "    # 6. 机器学习优化权重（基于2024年数据）\n",
    "    print(\"\\n开始优化情绪指标权重...\")\n",
    "    optimized_weights, model, weight_df = optimize_sentiment_weights(\n",
    "        train_data, \n",
    "        normalized_feature_cols\n",
    "    )\n",
    "    \n",
    "    # 7. 在2025年测试集上验证效果\n",
    "    print(\"\\n在2025年测试集上验证效果...\")\n",
    "    result_data, pearson_corr, spearman_corr = validate_optimized_sentiment(\n",
    "        test_data, \n",
    "        normalized_feature_cols, \n",
    "        optimized_weights, \n",
    "        norm_params\n",
    "    )\n",
    "    \n",
    "    # 8. 保存结果\n",
    "    result_data.to_parquet(\"optimized_sentiment_results.parquet\", index=False)\n",
    "    weight_df.to_csv(\"optimized_sentiment_weights.csv\", index=False, encoding='utf-8-sig')\n",
    "    print(\"\\n优化结果已保存至 optimized_sentiment_results.parquet\")\n",
    "    print(\"优化后的权重已保存至 optimized_sentiment_weights.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488b1c62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xiaoyao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
