{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3efb6b79",
   "metadata": {},
   "source": [
    "### 将竞价信息与量价信息合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a098fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取集合竞价数据：D:\\workspace\\xiaoyao\\data\\stock_daily_auction.parquet\n",
      "读取每日量价数据：D:\\workspace\\xiaoyao\\data\\stock_daily_price.parquet\n",
      "合并关键字段数据...\n",
      "已对 open 进行复权处理\n",
      "已对 close 进行复权处理\n",
      "已对 high 进行复权处理\n",
      "已对 low 进行复权处理\n",
      "已对 pre_close 进行复权处理\n",
      "已对 high_limit 进行复权处理\n",
      "已对 low_limit 进行复权处理\n",
      "保存合并文件：D:\\workspace\\xiaoyao\\data\\stock_daily_auction_clean.parquet\n",
      "\n",
      "=== 合并结果验证 ===\n",
      "实际字段顺序：['stock_code', 'trade_date', 'date', 'current', 'auction_volume', 'high_limit', 'low_limit', 'open', 'close', 'high', 'low', 'pre_close', 'factor']\n",
      "预期字段顺序：['stock_code', 'trade_date', 'date', 'current', 'auction_volume', 'high_limit', 'low_limit', 'open', 'close', 'high', 'low', 'pre_close', 'factor']\n",
      "字段顺序匹配：True\n",
      "合并后数据条数：5555679\n",
      "覆盖股票数量：5337 只\n",
      "\n",
      "合并完成！文件已保存至：D:\\workspace\\xiaoyao\\data\\stock_daily_auction_clean.parquet\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def merge_parquet_core_fields(auction_input, daily_input, output_path):\n",
    "    \"\"\"\n",
    "    合并Parquet文件（确保字段顺序严格一致），输出轻量合并文件\n",
    "    \"\"\"\n",
    "    # 1. 读取数据\n",
    "    print(f\"读取集合竞价数据：{auction_input}\")\n",
    "    auction_cols = [\"stock_code\", \"date\", \"current\", \"volume\"]\n",
    "    auction_df = pd.read_parquet(auction_input, columns=auction_cols)\n",
    "    \n",
    "    print(f\"读取每日量价数据：{daily_input}\")\n",
    "    daily_cols = [\"stock_code\", \"date\", \"pre_close\", \"close\", \"open\", \"high\", \"low\", \n",
    "                 \"high_limit\", \"low_limit\", \"factor\"]\n",
    "    daily_df = pd.read_parquet(daily_input, columns=daily_cols)\n",
    "    \n",
    "    # 2. 基础预处理\n",
    "    for df in [auction_df, daily_df]:\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "        df[\"trade_date\"] = df[\"date\"].dt.date\n",
    "        df[\"stock_code\"] = df[\"stock_code\"].astype(str)\n",
    "    \n",
    "    auction_df.rename(columns={\"volume\": \"auction_volume\"}, inplace=True)\n",
    "    \n",
    "    # 3. 合并数据\n",
    "    print(\"合并关键字段数据...\")\n",
    "    merged_df = pd.merge(\n",
    "        left=auction_df,\n",
    "        right=daily_df,\n",
    "        on=[\"stock_code\", \"trade_date\"],\n",
    "        how=\"inner\",\n",
    "        suffixes=(\"\", \"_daily\")\n",
    "    )\n",
    "    \n",
    "    # 4. 价格复权处理\n",
    "    price_fields = [\"open\", \"close\", \"high\", \"low\", \"pre_close\", \"high_limit\", \"low_limit\"]\n",
    "    for field in price_fields:\n",
    "        if field in merged_df.columns and \"factor\" in merged_df.columns:\n",
    "            merged_df[field] = merged_df[field] / merged_df[\"factor\"].where(merged_df[\"factor\"] != 0, 1)\n",
    "            # 仅保留小数点后2位\n",
    "            merged_df[field] = merged_df[field].round(2)\n",
    "            print(f\"已对 {field} 进行复权处理\")\n",
    "    \n",
    "    # 5. 数据清理\n",
    "    merged_df = merged_df.sort_values([\"stock_code\", \"date\"]).reset_index(drop=True)\n",
    "    merged_df = merged_df.drop_duplicates(subset=[\"stock_code\", \"trade_date\"], keep=\"first\")\n",
    "    \n",
    "    # 6. 严格按照预期顺序排列字段（关键修复：确保列名唯一）\n",
    "    expected_columns = [\n",
    "        \"stock_code\", \"trade_date\", \"date\", \n",
    "        \"current\", \"auction_volume\", \"high_limit\", \n",
    "        \"low_limit\", \"open\", \"close\", \"high\", \n",
    "        \"low\", \"pre_close\", \"factor\"\n",
    "    ]\n",
    "    # 确保只包含预期字段，且顺序完全一致\n",
    "    merged_final = merged_df.reindex(columns=expected_columns)\n",
    "\n",
    "    print(f\"保存合并文件：{output_path}\")\n",
    "    merged_final.to_parquet(output_path, index=False)\n",
    "    \n",
    "    # 7. 验证字段顺序\n",
    "    print(\"\\n=== 合并结果验证 ===\")\n",
    "    print(f\"实际字段顺序：{merged_final.columns.tolist()}\")\n",
    "    print(f\"预期字段顺序：{expected_columns}\")\n",
    "    print(f\"字段顺序匹配：{merged_final.columns.tolist() == expected_columns}\")\n",
    "    print(f\"合并后数据条数：{len(merged_final)}\")\n",
    "    print(f\"覆盖股票数量：{merged_final['stock_code'].nunique()} 只\")\n",
    "    print(f\"\\n合并完成！文件已保存至：{output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    AUCTION_PATH = \"D:\\\\workspace\\\\xiaoyao\\\\data\\\\stock_daily_auction.parquet\"\n",
    "    DAILY_PATH = \"D:\\\\workspace\\\\xiaoyao\\\\data\\\\stock_daily_price.parquet\"\n",
    "    OUTPUT_PATH = \"D:\\\\workspace\\\\xiaoyao\\\\data\\\\stock_daily_auction_clean.parquet\"\n",
    "    \n",
    "    merge_parquet_core_fields(AUCTION_PATH, DAILY_PATH, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93937b49",
   "metadata": {},
   "source": [
    "### 计算量比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fad376b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始列数: 13, 列名: ['stock_code', 'trade_date', 'date', 'current', 'auction_volume']...\n",
      "警告：列数不匹配（差异: 1），自动修正...\n",
      "已删除意外新增的列: ['daily_increase', 'rp_60']\n",
      "\n",
      "验证结果：\n",
      "输出文件列数: 23\n",
      "BOLL指标样例:\n",
      "  trade_date   open   boll_mid    boll_up   boll_low\n",
      "0 2021-01-04  19.10  19.100000        NaN        NaN\n",
      "1 2021-01-05  18.40  18.750000  19.492462  18.007538\n",
      "2 2021-01-06  18.08  18.526667  19.309163  17.744171\n",
      "3 2021-01-07  19.52  18.775000  19.756440  17.793560\n",
      "4 2021-01-08  19.90  19.000000  20.136640  17.863360\n",
      "5 2021-01-11  20.00  19.166667  20.353494  17.979839\n",
      "6 2021-01-12  20.39  19.341429  20.627831  18.055026\n",
      "7 2021-01-13  21.00  19.548750  21.029326  18.068174\n",
      "8 2021-01-14  20.68  19.674444  21.170447  18.178441\n",
      "9 2021-01-15  21.00  19.807000  21.351248  18.262752\n",
      "文件已保存至: D:\\workspace\\xiaoyao\\data\\stock_daily_auction_with_metrics.parquet\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "def calculate_stock_metrics(input_path, output_path):\n",
    "    # 1. 读取原始数据\n",
    "    df = pd.read_parquet(input_path)\n",
    "    \n",
    "    # 2. 基础信息记录\n",
    "    original_cols = df.columns.tolist()\n",
    "    original_col_count = len(original_cols)\n",
    "    print(f\"原始列数: {original_col_count}, 列名: {original_cols[:5]}...\")\n",
    "    \n",
    "    # 3. 预处理\n",
    "    df['trade_date'] = pd.to_datetime(df['trade_date'])\n",
    "    df = df.sort_values(['stock_code', 'trade_date']).reset_index(drop=True)\n",
    "    df['stock_code'] = df['stock_code'].astype(str)\n",
    "    \n",
    "    # 4. 定义新增字段（包含BOLL指标）\n",
    "    new_columns = [\n",
    "        'auction_prev_ratio',\n",
    "        'auction_volume_ratio_3d', 'auction_volume_ratio_5d',\n",
    "        'auction_volume_ratio_8d', 'auction_volume_ratio_10d', 'auction_volume_ratio_20d', 'auction_volume_ratio_60d','rp_60'\n",
    "        'daily_increase',\n",
    "        'boll_mid', 'boll_up', 'boll_low'  # 新增BOLL相关字段\n",
    "    ]\n",
    "    \n",
    "    # 5. 清理已存在的目标字段\n",
    "    for col in new_columns:\n",
    "        if col in df.columns:\n",
    "            df = df.drop(columns=[col])\n",
    "            print(f\"移除已存在的字段: {col}\")\n",
    "    \n",
    "    # 6. 计算原有指标\n",
    "    # 6.1 竞价昨比\n",
    "    df['auction_prev_ratio'] = df.groupby('stock_code')['auction_volume'].transform(\n",
    "        lambda x: x / x.shift(1)\n",
    "    )\n",
    "    \n",
    "    # 6.2 竞价量比\n",
    "    window_sizes = [3, 5, 8, 10, 20, 60]\n",
    "    for window in window_sizes:\n",
    "        col_name = f'auction_volume_ratio_{window}d'\n",
    "        df[col_name] = df.groupby('stock_code')['auction_volume'].transform(\n",
    "            lambda x: x / x.shift(1).rolling(\n",
    "                window=window, min_periods=1, closed='left'\n",
    "            ).mean()\n",
    "        )\n",
    "    \n",
    "    # 6.3 当日涨幅\n",
    "    df['daily_increase'] = np.where(\n",
    "        df['open'] != 0,\n",
    "        (df['close'] - df['open']) / df['open'] * 100,\n",
    "        np.nan\n",
    "    )\n",
    "    \n",
    "    # 7. 新增BOLL指标计算（包含当日open）\n",
    "    # BOLL计算逻辑：基于开盘价，周期6天，2倍标准差\n",
    "    df['boll_mid'] = df.groupby('stock_code')['open'].transform(\n",
    "        lambda x: x.rolling(window=15, min_periods=1).mean()  # 中轨：6日开盘价均值（含当日）\n",
    "    )\n",
    "    df['boll_std'] = df.groupby('stock_code')['open'].transform(\n",
    "        lambda x: x.rolling(window=10, min_periods=1).std()   # 标准差（含当日）\n",
    "    )\n",
    "    df['boll_up'] = df['boll_mid'] + 1.5 * df['boll_std']    # 上轨：中轨 + 2倍标准差\n",
    "    df['boll_low'] = df['boll_mid'] - 1.5 * df['boll_std']   # 下轨：中轨 - 2倍标准差\n",
    "    \n",
    "    # 增加一列 计算rp值，即相对价格位置，取60日的最高价、最低价、当前价的位置比例\n",
    "    df['rp_60'] = df.groupby('stock_code')['open'].transform(\n",
    "        lambda x: (x - x.rolling(window=60, min_periods=1).min()) / (x.rolling(window=60, min_periods=1).max() - x.rolling(window=60, min_periods=1).min())\n",
    "    )\n",
    "\n",
    "    # 移除临时标准差列\n",
    "    if 'boll_std' in df.columns:\n",
    "        df = df.drop(columns=['boll_std'])\n",
    "    \n",
    "    # 8. 列数控制（原始列数 + 8个新列：原5个+新增3个BOLL字段）\n",
    "    final_col_count = original_col_count + 8 + 2 + 1\n",
    "    current_col_count = len(df.columns)\n",
    "    \n",
    "    if current_col_count != final_col_count:\n",
    "        diff = current_col_count - final_col_count\n",
    "        print(f\"警告：列数不匹配（差异: {diff}），自动修正...\")\n",
    "        \n",
    "        added_cols = [col for col in df.columns if col not in original_cols and col not in new_columns]\n",
    "        if added_cols:\n",
    "            df = df.drop(columns=added_cols)\n",
    "            print(f\"已删除意外新增的列: {added_cols}\")\n",
    "    \n",
    "    # 9. 数据类型标准化\n",
    "    for col in new_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype('float64')\n",
    "    \n",
    "    # 10. 写入并验证\n",
    "    table = pa.Table.from_pandas(df)\n",
    "    pq.write_table(table, output_path)\n",
    "    \n",
    "    validation_df = pd.read_parquet(output_path)\n",
    "    print(f\"\\n验证结果：\")\n",
    "    print(f\"输出文件列数: {len(validation_df.columns)}\")\n",
    "    print(f\"BOLL指标样例:\\n{validation_df[['trade_date', 'open', 'boll_mid', 'boll_up', 'boll_low']].head(10)}\")\n",
    "    print(f\"文件已保存至: {output_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = r\"D:\\workspace\\xiaoyao\\data\\stock_daily_auction_clean.parquet\"\n",
    "    output_file = r\"D:\\workspace\\xiaoyao\\data\\stock_daily_auction_with_metrics.parquet\"\n",
    "    calculate_stock_metrics(input_file, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a328360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每日前10股票及其当日涨幅已保存至：D:\\workspace\\xiaoyao\\data\\daily_top10_increase_analysis_top10_with_increase.parquet\n",
      "每日涨幅统计结果已保存至：D:\\workspace\\xiaoyao\\data\\daily_top10_increase_analysis_increase_stats.parquet\n",
      "\n",
      "===== 关键统计结果 =====\n",
      "有效交易日总数：257天\n",
      "所有交易日平均涨幅：-0.22%\n",
      "上涨概率：48.02%\n",
      "平均每日涨停数量：0.49只\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jay\\AppData\\Local\\Temp\\ipykernel_25756\\3478398000.py:50: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  daily_top10 = valid_high_open_df.groupby('trade_date', group_keys=False).apply(get_top10)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def analyze_daily_top10_increase(input_path, output_path):\n",
    "    # 读取数据\n",
    "    df = pd.read_parquet(input_path)\n",
    "    df['trade_date'] = pd.to_datetime(df['trade_date'])\n",
    "    valid_df = df\n",
    "    # 1. 筛选高开2个点以上的股票\n",
    "    # 确保前收盘价有效\n",
    "    # valid_df = df[df['trade_date'] > '2021-01-01'].copy()\n",
    "\n",
    "    # valid_df = df[\n",
    "    #     (df['trade_date'] >= '2021-02-01') & \n",
    "    #     (df['trade_date'] <= '2024-08-31')\n",
    "    # ].copy()\n",
    "    \n",
    "    valid_df = df[\n",
    "    (df['trade_date'] >= '2024-09-01') & \n",
    "    (df['trade_date'] <= '2025-09-30')\n",
    "    ].copy()\n",
    "\n",
    "    # stock_code 不是688开头的\n",
    "    valid_df = valid_df[~valid_df['stock_code'].str.startswith('688')].copy()\n",
    "\n",
    "    valid_df = valid_df[valid_df['auction_volume_ratio_20d'] > 10].copy()\n",
    "\n",
    "    valid_df = valid_df[valid_df['auction_volume_ratio_20d'] > 10].copy()\n",
    "\n",
    "    # 计算开盘涨幅\n",
    "    valid_df['open_pct'] = (valid_df['open'] - valid_df['pre_close']) / valid_df['pre_close'] * 100\n",
    "\n",
    "    high_open_df = valid_df\n",
    "    # high_open_df = high_open_df[high_open_df['open_pct'] < 4].copy()\n",
    "    # high_open_df = high_open_df[high_open_df['open_pct'] >-4].copy()\n",
    "\n",
    "    high_open_df = high_open_df[high_open_df['open'] < high_open_df['high_limit']].copy()\n",
    "    # high_open_df = high_open_df[high_open_df['current'] < high_open_df['boll_low']].copy()\n",
    "\n",
    "    \n",
    "    # 2. 确保量比数据有效\n",
    "    valid_high_open_df = high_open_df.dropna(subset=['auction_volume_ratio_20d']).copy()\n",
    "    \n",
    "    # 3. 按日筛选5日竞价量比最大的前10只股票\n",
    "    # 按日期分组，每组内按量比降序排序并取前10\n",
    "    def get_top10(group):\n",
    "        # 组内按量比降序排序\n",
    "        sorted_group = group.sort_values('auction_volume_ratio_20d', ascending=False)\n",
    "        # 取前10并保留所有字段\n",
    "        return sorted_group.head(10)\n",
    "    \n",
    "    # 应用分组函数\n",
    "    daily_top10 = valid_high_open_df.groupby('trade_date', group_keys=False).apply(get_top10)\n",
    "    \n",
    "    # 4. 提取每日前10股票的当日涨幅(daily_increase)\n",
    "    # 保留股票代码、日期、量比和涨幅等关键信息\n",
    "    top10_with_increase = daily_top10[\n",
    "        ['trade_date', 'stock_code', 'auction_volume_ratio_20d', 'daily_increase']\n",
    "    ].copy()\n",
    "    \n",
    "    # 5. 按日统计涨幅情况\n",
    "    daily_increase_stats = top10_with_increase.groupby('trade_date')['daily_increase'].agg(\n",
    "        平均涨幅='mean',\n",
    "        中位数涨幅='median',\n",
    "        最大涨幅='max',\n",
    "        最小涨幅='min',\n",
    "        上涨数量=lambda x: (x > 0).sum(),\n",
    "        涨停数量=lambda x: (x >= 9.8).sum(),  # 近似涨停标准\n",
    "        总数量='count'\n",
    "    ).reset_index()\n",
    "    \n",
    "    # 6. 保存结果\n",
    "    # 每日前10股票明细（含当日涨幅）\n",
    "    top10_with_increase.to_parquet(f\"{output_path}_top10_with_increase.parquet\", index=False)\n",
    "    # 每日涨幅统计\n",
    "    daily_increase_stats.to_parquet(f\"{output_path}_increase_stats.parquet\", index=False)\n",
    "    \n",
    "    print(f\"每日前10股票及其当日涨幅已保存至：{output_path}_top10_with_increase.parquet\")\n",
    "    print(f\"每日涨幅统计结果已保存至：{output_path}_increase_stats.parquet\")\n",
    "    \n",
    "    # 7. 打印关键统计信息\n",
    "    print(\"\\n===== 关键统计结果 =====\")\n",
    "    print(f\"有效交易日总数：{daily_increase_stats.shape[0]}天\")\n",
    "    print(f\"所有交易日平均涨幅：{daily_increase_stats['平均涨幅'].mean():.2f}%\")\n",
    "    print(f\"上涨概率：{daily_increase_stats['上涨数量'].sum() / daily_increase_stats['总数量'].sum():.2%}\")\n",
    "    print(f\"平均每日涨停数量：{daily_increase_stats['涨停数量'].mean():.2f}只\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = r\"D:\\workspace\\xiaoyao\\data\\stock_daily_auction_with_metrics.parquet\"\n",
    "    output_file = r\"D:\\workspace\\xiaoyao\\data\\daily_top10_increase_analysis\"\n",
    "    analyze_daily_top10_increase(input_file, output_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9ad44b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xiaoyao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
