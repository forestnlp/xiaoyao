{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7c12029",
   "metadata": {},
   "source": [
    "## 1.ä¸‹è½½æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb58c1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å‘é€ç«¯ï¼šRedisè¿æ¥æˆåŠŸ\n",
      "âœ… å‘é€ç«¯pandasç‰ˆæœ¬ï¼š2.3.2\n",
      "=== å…±éœ€è·å– 410 å¤©çš„æ•°æ® ===\n",
      "\n",
      "=== æ­£åœ¨å¤„ç† 1/410ï¼š20231118 ===\n",
      "ğŸ“¤ å·²è°ƒç”¨è¿œç¨‹å‡½æ•°ï¼šfetch_stock_conceptï¼ˆä»»åŠ¡IDï¼štask_233e384eï¼‰\n",
      "âš ï¸ æ•°æ®ä¸ºç©ºï¼Œä¸ä¿å­˜\n",
      "\n",
      "=== æ­£åœ¨å¤„ç† 2/410ï¼š20231119 ===\n",
      "ğŸ“¤ å·²è°ƒç”¨è¿œç¨‹å‡½æ•°ï¼šfetch_stock_conceptï¼ˆä»»åŠ¡IDï¼štask_d866b2f3ï¼‰\n",
      "âš ï¸ æ•°æ®ä¸ºç©ºï¼Œä¸ä¿å­˜\n",
      "\n",
      "=== æ­£åœ¨å¤„ç† 3/410ï¼š20231120 ===\n",
      "ğŸ“¤ å·²è°ƒç”¨è¿œç¨‹å‡½æ•°ï¼šfetch_stock_conceptï¼ˆä»»åŠ¡IDï¼štask_a3d0e23aï¼‰\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 125\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== æ­£åœ¨å¤„ç† \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(date_list)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mï¼š\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;66;03m# è°ƒç”¨è¿œç¨‹å‡½æ•°è·å–å½“æ—¥æ•°æ®\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     csv_data \u001b[38;5;241m=\u001b[39m \u001b[43msender\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_remote_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfetch_stock_concept\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;66;03m# ä¿å­˜ä¸ºCSVæ–‡ä»¶ï¼Œæ–‡ä»¶ååŒ…å«æ—¥æœŸ\u001b[39;00m\n\u001b[0;32m    127\u001b[0m     sender\u001b[38;5;241m.\u001b[39msave_to_csv(csv_data, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstock_daily_concept_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 39\u001b[0m, in \u001b[0;36mRemoteSender.call_remote_function\u001b[1;34m(self, func_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mredis\u001b[38;5;241m.\u001b[39mrpush(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_queue, pickle\u001b[38;5;241m.\u001b[39mdumps(task))\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ“¤ å·²è°ƒç”¨è¿œç¨‹å‡½æ•°ï¼š\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mï¼ˆä»»åŠ¡IDï¼š\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mï¼‰\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 44\u001b[0m, in \u001b[0;36mRemoteSender._get_result\u001b[1;34m(self, task_id, timeout)\u001b[0m\n\u001b[0;32m     42\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time \u001b[38;5;241m<\u001b[39m timeout:\n\u001b[1;32m---> 44\u001b[0m     result_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mredis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult_queue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result_data:\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32md:\\sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\redis\\commands\\core.py:2558\u001b[0m, in \u001b[0;36mListCommands.blpop\u001b[1;34m(self, keys, timeout)\u001b[0m\n\u001b[0;32m   2556\u001b[0m keys \u001b[38;5;241m=\u001b[39m list_or_args(keys, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   2557\u001b[0m keys\u001b[38;5;241m.\u001b[39mappend(timeout)\n\u001b[1;32m-> 2558\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_command\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBLPOP\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\redis\\client.py:621\u001b[0m, in \u001b[0;36mRedis.execute_command\u001b[1;34m(self, *args, **options)\u001b[0m\n\u001b[0;32m    620\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mexecute_command\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions):\n\u001b[1;32m--> 621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_command(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32md:\\sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\redis\\client.py:632\u001b[0m, in \u001b[0;36mRedis._execute_command\u001b[1;34m(self, *args, **options)\u001b[0m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msingle_connection_lock\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_command_parse_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommand_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_close_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_single_connection_client:\n",
      "File \u001b[1;32md:\\sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\redis\\retry.py:105\u001b[0m, in \u001b[0;36mRetry.call_with_retry\u001b[1;34m(self, do, fail)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_supported_errors \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m    107\u001b[0m         failures \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32md:\\sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\redis\\client.py:633\u001b[0m, in \u001b[0;36mRedis._execute_command.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msingle_connection_lock\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mretry\u001b[38;5;241m.\u001b[39mcall_with_retry(\n\u001b[1;32m--> 633\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_command_parse_response(\n\u001b[0;32m    634\u001b[0m             conn, command_name, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m    635\u001b[0m         ),\n\u001b[0;32m    636\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m _: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connection(conn),\n\u001b[0;32m    637\u001b[0m     )\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_single_connection_client:\n",
      "File \u001b[1;32md:\\sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\redis\\client.py:604\u001b[0m, in \u001b[0;36mRedis._send_command_parse_response\u001b[1;34m(self, conn, command_name, *args, **options)\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    601\u001b[0m \u001b[38;5;124;03mSend a command and parse the response\u001b[39;00m\n\u001b[0;32m    602\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    603\u001b[0m conn\u001b[38;5;241m.\u001b[39msend_command(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m--> 604\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_response(conn, command_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32md:\\sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\redis\\client.py:651\u001b[0m, in \u001b[0;36mRedis.parse_response\u001b[1;34m(self, connection, command_name, **options)\u001b[0m\n\u001b[0;32m    649\u001b[0m         options\u001b[38;5;241m.\u001b[39mpop(NEVER_DECODE)\n\u001b[0;32m    650\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 651\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ResponseError:\n\u001b[0;32m    653\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m EMPTY_RESPONSE \u001b[38;5;129;01min\u001b[39;00m options:\n",
      "File \u001b[1;32md:\\sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\redis\\connection.py:650\u001b[0m, in \u001b[0;36mAbstractConnection.read_response\u001b[1;34m(self, disable_decoding, disconnect_on_error, push_request)\u001b[0m\n\u001b[0;32m    646\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parser\u001b[38;5;241m.\u001b[39mread_response(\n\u001b[0;32m    647\u001b[0m             disable_decoding\u001b[38;5;241m=\u001b[39mdisable_decoding, push_request\u001b[38;5;241m=\u001b[39mpush_request\n\u001b[0;32m    648\u001b[0m         )\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdisable_decoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_decoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mtimeout:\n\u001b[0;32m    652\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m disconnect_on_error:\n",
      "File \u001b[1;32md:\\sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\redis\\_parsers\\resp2.py:15\u001b[0m, in \u001b[0;36m_RESP2Parser.read_response\u001b[1;34m(self, disable_decoding)\u001b[0m\n\u001b[0;32m     13\u001b[0m pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer\u001b[38;5;241m.\u001b[39mget_pos() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 15\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdisable_decoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_decoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer:\n",
      "File \u001b[1;32md:\\sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\redis\\_parsers\\resp2.py:25\u001b[0m, in \u001b[0;36m_RESP2Parser._read_response\u001b[1;34m(self, disable_decoding)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_response\u001b[39m(\u001b[38;5;28mself\u001b[39m, disable_decoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 25\u001b[0m     raw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw:\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(SERVER_CLOSED_CONNECTION_ERROR)\n",
      "File \u001b[1;32md:\\sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\redis\\_parsers\\socket.py:115\u001b[0m, in \u001b[0;36mSocketBuffer.readline\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    112\u001b[0m data \u001b[38;5;241m=\u001b[39m buf\u001b[38;5;241m.\u001b[39mreadline()\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data\u001b[38;5;241m.\u001b[39mendswith(SYM_CRLF):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;66;03m# there's more data in the socket that we need\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_from_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m     data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m buf\u001b[38;5;241m.\u001b[39mreadline()\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[1;32md:\\sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\redis\\_parsers\\socket.py:65\u001b[0m, in \u001b[0;36mSocketBuffer._read_from_socket\u001b[1;34m(self, length, timeout, raise_on_timeout)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43msocket_read_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m         \u001b[38;5;66;03m# an empty string indicates the server shutdown the socket\u001b[39;00m\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mbytes\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import redis\n",
    "import pickle\n",
    "import time\n",
    "import uuid\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from typing import Any, Optional\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "class RemoteSender:\n",
    "    def __init__(self, host='*', port=6379, password='*'):\n",
    "        self.redis = redis.Redis(\n",
    "            host=host, port=port, password=password,\n",
    "            decode_responses=False\n",
    "        )\n",
    "        self.task_queue = 'function_calls'\n",
    "        self.result_queue = 'function_results'\n",
    "        self._test_connection()\n",
    "        print(f\"âœ… å‘é€ç«¯pandasç‰ˆæœ¬ï¼š{pd.__version__}\")\n",
    "\n",
    "    def _test_connection(self):\n",
    "        try:\n",
    "            self.redis.ping()\n",
    "            print(\"âœ… å‘é€ç«¯ï¼šRedisè¿æ¥æˆåŠŸ\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ å‘é€ç«¯ï¼šè¿æ¥å¤±è´¥ - {e}\")\n",
    "            raise\n",
    "\n",
    "    def call_remote_function(self, func_name: str, *args, **kwargs) -> Any:\n",
    "        task_id = f\"task_{uuid.uuid4().hex[:8]}\"\n",
    "        task = {\n",
    "            'func_name': func_name,\n",
    "            'args': args,\n",
    "            'kwargs': kwargs,\n",
    "            'task_id': task_id\n",
    "        }\n",
    "        self.redis.rpush(self.task_queue, pickle.dumps(task))\n",
    "        print(f\"ğŸ“¤ å·²è°ƒç”¨è¿œç¨‹å‡½æ•°ï¼š{func_name}ï¼ˆä»»åŠ¡IDï¼š{task_id}ï¼‰\")\n",
    "        return self._get_result(task_id)\n",
    "\n",
    "    def _get_result(self, task_id: str, timeout=300) -> Any:\n",
    "        start_time = time.time()\n",
    "        while time.time() - start_time < timeout:\n",
    "            result_data = self.redis.blpop(self.result_queue, timeout=10)\n",
    "            if not result_data:\n",
    "                continue\n",
    "\n",
    "            _, res_bytes = result_data\n",
    "            result = pickle.loads(res_bytes)\n",
    "            if result['task_id'] == task_id:\n",
    "                if result['status'] == 'success':\n",
    "                    return result['result']  # è¿”å›CSVå­—ç¬¦ä¸²\n",
    "                else:\n",
    "                    raise Exception(f\"è¿œç¨‹æ‰§è¡Œå¤±è´¥ï¼š{result['error']}\")\n",
    "            self.redis.rpush(self.result_queue, res_bytes)\n",
    "        raise TimeoutError(\"ä»»åŠ¡è¶…æ—¶\")\n",
    "\n",
    "    def save_to_csv(self, csv_str: Optional[str], filename: str) -> bool:\n",
    "        \"\"\"å°†CSVå­—ç¬¦ä¸²ä¿å­˜ä¸ºæœ¬åœ°CSVæ–‡ä»¶ï¼ˆæ›¿ä»£Parquetï¼‰\"\"\"\n",
    "        if not csv_str:\n",
    "            print(\"âš ï¸ æ•°æ®ä¸ºç©ºï¼Œä¸ä¿å­˜\")\n",
    "            return False\n",
    "        try:\n",
    "            # ä»CSVå­—ç¬¦ä¸²æ¢å¤DataFrameï¼ˆå…¼å®¹æ‰€æœ‰pandasç‰ˆæœ¬ï¼‰\n",
    "            df = pd.read_csv(StringIO(csv_str))\n",
    "            # ä¿å­˜ä¸ºCSVæ–‡ä»¶\n",
    "            df.to_csv(filename, index=False)\n",
    "            print(f\"âœ… ä¿å­˜æˆåŠŸï¼š{filename}ï¼ˆ{len(df)}æ¡è®°å½•ï¼‰\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ä¿å­˜å¤±è´¥ï¼š{e}\")\n",
    "            return False\n",
    "\n",
    "def generate_date_range(start_date_str: str, end_date_str: str) -> list:\n",
    "    \"\"\"ç”Ÿæˆä»å¼€å§‹æ—¥æœŸåˆ°ç»“æŸæ—¥æœŸçš„æ‰€æœ‰æ—¥æœŸå­—ç¬¦ä¸²ï¼ˆYYYYMMDDæ ¼å¼ï¼‰\"\"\"\n",
    "    dates = []\n",
    "    try:\n",
    "        start_date = datetime.strptime(start_date_str, '%Y%m%d')\n",
    "        end_date = datetime.strptime(end_date_str, '%Y%m%d')\n",
    "        \n",
    "        if start_date > end_date:\n",
    "            raise ValueError(\"å¼€å§‹æ—¥æœŸæ™šäºç»“æŸæ—¥æœŸ\")\n",
    "            \n",
    "        current_date = start_date\n",
    "        while current_date <= end_date:\n",
    "            dates.append(current_date.strftime('%Y%m%d'))\n",
    "            current_date += timedelta(days=1)\n",
    "    except Exception as e:\n",
    "        print(f\"æ—¥æœŸå¤„ç†é”™è¯¯ï¼š{e}\")\n",
    "    return dates\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # ä»é…ç½®æ–‡ä»¶è¯»å–Redisè¿æ¥ä¿¡æ¯\n",
    "    with open('redis.conf', 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('host='):\n",
    "                host = line.split('=')[1].strip()\n",
    "            elif line.startswith('port='):\n",
    "                port = int(line.split('=')[1].strip())\n",
    "            elif line.startswith('password='):\n",
    "                password = line.split('=')[1].strip()\n",
    "    # åˆå§‹åŒ–Rediså‘é€ç«¯\n",
    "    sender = RemoteSender(host=host, port=port, password=password)\n",
    "    \n",
    "    # å®šä¹‰æ—¥æœŸèŒƒå›´ï¼šä»20250516åˆ°20250923\n",
    "    # è¯»å–../data/stock_daily_price.parquetæ–‡ä»¶ï¼Œè·å–æœ€å¤§çš„æ—¥æœŸ+1ï¼Œæ˜¯start_date\n",
    "    parquet_file = '../data/stock_daily_concept.parquet'\n",
    "    # å¦‚æœ parquet_file å­˜åœ¨ï¼Œè¯»å–æœ€å¤§æ—¥æœŸ+1ï¼Œå¦åˆ™ä»20250516å¼€å§‹\n",
    "    df = pd.read_parquet(parquet_file)\n",
    "    start_date = '20231118'#(df['date'].max() + timedelta(days=1)).strftime('%Y%m%d')\n",
    "    # è·å–å½“æ—¥æ—¥æœŸ-1ï¼Œæ˜¯end_date\n",
    "    end_date = '20241231'#(datetime.today() - timedelta(days=1)).strftime('%Y%m%d')\n",
    "    \n",
    "    # ç”Ÿæˆæ—¥æœŸåˆ—è¡¨\n",
    "    date_list = generate_date_range(start_date, end_date)\n",
    "\n",
    "    print(f\"=== å…±éœ€è·å– {len(date_list)} å¤©çš„æ•°æ® ===\")\n",
    "    \n",
    "    # å¾ªç¯è°ƒç”¨è·å–æ¯æ—¥æ•°æ®\n",
    "    for i, date in enumerate(date_list, 1):\n",
    "        print(f\"\\n=== æ­£åœ¨å¤„ç† {i}/{len(date_list)}ï¼š{date} ===\")\n",
    "        try:\n",
    "            # è°ƒç”¨è¿œç¨‹å‡½æ•°è·å–å½“æ—¥æ•°æ®\n",
    "            csv_data = sender.call_remote_function('fetch_stock_concept', date)\n",
    "            # ä¿å­˜ä¸ºCSVæ–‡ä»¶ï¼Œæ–‡ä»¶ååŒ…å«æ—¥æœŸ\n",
    "            sender.save_to_csv(csv_data, f'stock_daily_concept_{date}.csv')\n",
    "            \n",
    "            # é€‚å½“å»¶è¿Ÿï¼Œé¿å…è¯·æ±‚è¿‡äºé¢‘ç¹\n",
    "            time.sleep(0.05)\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ {date} å¤„ç†å¤±è´¥ï¼š{e}\")\n",
    "            # å¤±è´¥åä¹Ÿå»¶è¿Ÿä¸€ä¸‹ï¼Œé¿å…å¿«é€Ÿé‡è¯•å¯¼è‡´çš„é—®é¢˜\n",
    "            time.sleep(2)\n",
    "    \n",
    "    print(\"\\n=== æ‰€æœ‰æ—¥æœŸå¤„ç†å®Œæˆ ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47950e5",
   "metadata": {},
   "source": [
    "## å°†csvåˆå¹¶ä¸ºä¸€ä¸ªparquetæ–‡ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68654520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸš€ å¼€å§‹åˆå¹¶ stock_***.csv æ–‡ä»¶åˆ° parquet\n",
      "============================================================\n",
      "ğŸ“ å¼€å§‹å¤„ç†ç›®å½•: d:/workspace/xiaoyao/redis/\n",
      "ğŸ“Š æ‰¾åˆ° 1 ä¸ª CSV æ–‡ä»¶\n",
      "æ­£åœ¨å¤„ç† (1/1): stock_daily_concept_20251024.csv\n",
      "  âœ… æˆåŠŸè¯»å– 45761 æ¡è®°å½•\n",
      "\n",
      "ğŸ“Š åˆå¹¶æ‰€æœ‰æ•°æ®...\n",
      "ğŸ“ˆ æ€»è®¡ 45761 æ¡è®°å½•ï¼ˆå»é‡åï¼‰\n",
      "âœ… æˆåŠŸä¿å­˜åˆ°: d:/workspace/xiaoyao/redis/parquet\\stock_daily_concept_to_merged.parquet\n",
      "ğŸ“Š æ–‡ä»¶å¤§å°: 0.16 MB\n",
      "\n",
      "ğŸ‰ åˆå¹¶å®Œæˆï¼\n",
      "\n",
      "ğŸ“‹ éªŒè¯ç»“æœ:\n",
      "   æ€»è¡Œæ•°: 45761\n",
      "   æ—¥æœŸèŒƒå›´: 2025-10-24 00:00:00 åˆ° 2025-10-24 00:00:00\n",
      "   è‚¡ç¥¨æ•°é‡: 5132\n",
      "   åˆ—å: ['date', 'stock_code', 'concept_code', 'concept_name']\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "å°† /d:/workspace/xiaoyao/redis/ ç›®å½•ä¸‹çš„æ‰€æœ‰ stock_***.csv æ–‡ä»¶åˆå¹¶ä¸ºä¸€ä¸ª parquet æ–‡ä»¶\n",
    "ç¡®ä¿ä¸ç°æœ‰ /d:/workspace/xiaoyao/data/stock_daily_price.parquet ä¿æŒå­—æ®µã€å‹ç¼©æ–¹å¼ä¸€è‡´\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "\n",
    "def merge_stock_csv_to_parquet(csv_dir, output_parquet_file):\n",
    "    \"\"\"\n",
    "    åˆå¹¶æŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰ stock_***.csv æ–‡ä»¶åˆ°å•ä¸ª parquet æ–‡ä»¶\n",
    "    \n",
    "    Args:\n",
    "        csv_dir: CSV æ–‡ä»¶æ‰€åœ¨ç›®å½•\n",
    "        output_parquet_file: è¾“å‡ºçš„ parquet æ–‡ä»¶è·¯å¾„\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ“ å¼€å§‹å¤„ç†ç›®å½•: {csv_dir}\")\n",
    "    \n",
    "    # è·å–æ‰€æœ‰ stock_***.csv æ–‡ä»¶\n",
    "    csv_pattern = os.path.join(csv_dir, \"stock_daily_concept_*.csv\")\n",
    "    csv_files = glob.glob(csv_pattern)\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(\"âŒ æœªæ‰¾åˆ° stock_***.csv æ–‡ä»¶\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"ğŸ“Š æ‰¾åˆ° {len(csv_files)} ä¸ª CSV æ–‡ä»¶\")\n",
    "    \n",
    "    # æŒ‰æ–‡ä»¶åæ’åºï¼ˆç¡®ä¿æŒ‰æ—¥æœŸé¡ºåºå¤„ç†ï¼‰\n",
    "    csv_files.sort()\n",
    "    \n",
    "    # è¯»å–å¹¶åˆå¹¶æ‰€æœ‰ CSV æ–‡ä»¶\n",
    "    all_dataframes = []\n",
    "    total_records = 0\n",
    "    \n",
    "    for i, csv_file in enumerate(csv_files, 1):\n",
    "        filename = os.path.basename(csv_file)\n",
    "        print(f\"æ­£åœ¨å¤„ç† ({i}/{len(csv_files)}): {filename}\")\n",
    "        \n",
    "        try:\n",
    "            # è¯»å– CSV æ–‡ä»¶\n",
    "            df = pd.read_csv(csv_file)\n",
    "            \n",
    "            # æ•°æ®éªŒè¯å’Œæ¸…æ´—\n",
    "            # ç¡®ä¿ date åˆ—æ˜¯ datetime ç±»å‹\n",
    "            df['date'] = pd.to_datetime(df['date'])\n",
    "            \n",
    "            # ç¡®ä¿æ•°å€¼åˆ—çš„æ•°æ®ç±»å‹æ­£ç¡®\n",
    "            numeric_columns = []\n",
    "            \n",
    "            for col in numeric_columns:\n",
    "                if col in df.columns:\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            \n",
    "            # åˆ é™¤æ— æ•ˆæ•°æ®\n",
    "            df = df.dropna(subset=['date', 'stock_code'])\n",
    "            \n",
    "            all_dataframes.append(df)\n",
    "            total_records += len(df)\n",
    "            print(f\"  âœ… æˆåŠŸè¯»å– {len(df)} æ¡è®°å½•\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ å¤„ç†å¤±è´¥: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not all_dataframes:\n",
    "        print(\"âŒ æ²¡æœ‰æˆåŠŸè¯»å–ä»»ä½•æ•°æ®\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"\\nğŸ“Š åˆå¹¶æ‰€æœ‰æ•°æ®...\")\n",
    "    # åˆå¹¶æ‰€æœ‰æ•°æ®æ¡†\n",
    "    combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "    \n",
    "    # å»é‡ï¼ˆæŒ‰ date + stock_codeï¼‰\n",
    "    combined_df = combined_df.drop_duplicates(subset=['date', 'stock_code','concept_code'])\n",
    "    \n",
    "    # æŒ‰æ—¥æœŸå’Œè‚¡ç¥¨ä»£ç æ’åº\n",
    "    combined_df = combined_df.sort_values(['date', 'stock_code','concept_code']).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"ğŸ“ˆ æ€»è®¡ {len(combined_df)} æ¡è®°å½•ï¼ˆå»é‡åï¼‰\")\n",
    "    \n",
    "    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨\n",
    "    output_dir = os.path.dirname(output_parquet_file)\n",
    "    if output_dir and not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\"ğŸ“ åˆ›å»ºè¾“å‡ºç›®å½•: {output_dir}\")\n",
    "    \n",
    "    # è½¬æ¢ä¸º pyarrow Table\n",
    "    table = pa.Table.from_pandas(combined_df)\n",
    "    \n",
    "    # ä½¿ç”¨ä¸ç›®æ ‡æ–‡ä»¶ç›¸åŒçš„å‹ç¼©æ–¹å¼ (snappy) å’Œæ ¼å¼å†™å…¥ parquet\n",
    "    try:\n",
    "        pq.write_table(\n",
    "            table, \n",
    "            output_parquet_file,\n",
    "            compression='snappy',\n",
    "            version='2.6',  # ä½¿ç”¨è¾ƒæ–°çš„ parquet ç‰ˆæœ¬\n",
    "            use_dictionary=True,\n",
    "            write_batch_size=64 * 1024 * 1024  # 64MB batch size for better performance\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… æˆåŠŸä¿å­˜åˆ°: {output_parquet_file}\")\n",
    "        print(f\"ğŸ“Š æ–‡ä»¶å¤§å°: {os.path.getsize(output_parquet_file) / (1024*1024):.2f} MB\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ä¿å­˜ parquet æ–‡ä»¶å¤±è´¥: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"ä¸»å‡½æ•°\"\"\"\n",
    "    # è®¾ç½®è·¯å¾„\n",
    "    csv_directory = \"d:/workspace/xiaoyao/redis/\"\n",
    "    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨\n",
    "    output_dir = os.path.join(csv_directory, 'parquet')\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\"ğŸ“ åˆ›å»ºè¾“å‡ºç›®å½•: {output_dir}\")\n",
    "\n",
    "    output_file = os.path.join(output_dir, 'stock_daily_concept_to_merged.parquet')\n",
    "    \n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"ğŸš€ å¼€å§‹åˆå¹¶ stock_***.csv æ–‡ä»¶åˆ° parquet\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # æ‰§è¡Œåˆå¹¶\n",
    "    success = merge_stock_csv_to_parquet(csv_directory, output_file)\n",
    "    \n",
    "    if success:\n",
    "        print(\"\\nğŸ‰ åˆå¹¶å®Œæˆï¼\")\n",
    "        \n",
    "        # éªŒè¯ç»“æœ\n",
    "        try:\n",
    "            print(\"\\nğŸ“‹ éªŒè¯ç»“æœ:\")\n",
    "            result_df = pd.read_parquet(output_file)\n",
    "            print(f\"   æ€»è¡Œæ•°: {len(result_df)}\")\n",
    "            print(f\"   æ—¥æœŸèŒƒå›´: {result_df['date'].min()} åˆ° {result_df['date'].max()}\")\n",
    "            print(f\"   è‚¡ç¥¨æ•°é‡: {result_df['stock_code'].nunique()}\")\n",
    "            print(f\"   åˆ—å: {list(result_df.columns)}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸  éªŒè¯å¤±è´¥: {e}\")\n",
    "    \n",
    "    else:\n",
    "        print(\"\\nâŒ åˆå¹¶å¤±è´¥ï¼\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ab418c",
   "metadata": {},
   "source": [
    "## å°†æ–°ç”Ÿæˆçš„ stock_daily_auction_to_merged.parquet.parquet ä¸ç°æœ‰çš„ stock_daily_auction.parquet åˆå¹¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0e4253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸš€ å¼€å§‹åˆå¹¶ parquet æ–‡ä»¶\n",
      "============================================================\n",
      "ğŸ“Š å¼€å§‹åˆå¹¶ parquet æ–‡ä»¶...\n",
      "ğŸ“– è¯»å–ç°æœ‰æ–‡ä»¶: d:/workspace/xiaoyao/data/stock_daily_concept.parquet\n",
      "   ç°æœ‰æ•°æ®è¡Œæ•°: 15713908\n",
      "ğŸ“– è¯»å–æ–°æ–‡ä»¶: D:/workspace/xiaoyao/redis/parquet/stock_daily_concept_to_merged.parquet\n",
      "   æ–°æ•°æ®è¡Œæ•°: 45761\n",
      "ğŸ”„ åˆå¹¶æ•°æ®ä¸­...\n",
      "ğŸ§¹ å»é‡å¤„ç†...\n",
      "ğŸ“… æŒ‰æ—¥æœŸæ’åº...\n",
      "ğŸ“ˆ åˆå¹¶åæ€»è¡Œæ•°: 15759669\n",
      "ğŸ’¾ ä¿å­˜åˆå¹¶ç»“æœ: d:/workspace/xiaoyao/redis/parquet/stock_daily_concept.parquet\n",
      "âœ… åˆå¹¶å®Œæˆï¼æ–‡ä»¶å¤§å°: 45.71 MB\n",
      "\n",
      "ğŸ“‹ éªŒè¯ç»“æœ:\n",
      "   æœ€ç»ˆè¡Œæ•°: 15759669\n",
      "   æ—¥æœŸèŒƒå›´: 2023-01-03 00:00:00 åˆ° 2025-10-24 00:00:00\n",
      "   è‚¡ç¥¨æ•°é‡: 5273\n",
      "\n",
      "ğŸ‰ åˆå¹¶æˆåŠŸï¼\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "å°†æ–°ç”Ÿæˆçš„ stock_daily_auction_to_merged.parquet.parquet ä¸ç°æœ‰çš„ stock_daily_auction.parquet åˆå¹¶\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import os\n",
    "\n",
    "\n",
    "def merge_parquet_files(existing_file, new_file, output_file):\n",
    "    \"\"\"\n",
    "    åˆå¹¶ä¸¤ä¸ª parquet æ–‡ä»¶\n",
    "    \n",
    "    Args:\n",
    "        existing_file: ç°æœ‰çš„ parquet æ–‡ä»¶è·¯å¾„\n",
    "        new_file: æ–°çš„ parquet æ–‡ä»¶è·¯å¾„  \n",
    "        output_file: è¾“å‡ºçš„åˆå¹¶æ–‡ä»¶è·¯å¾„\n",
    "    \"\"\"\n",
    "    print(\"ğŸ“Š å¼€å§‹åˆå¹¶ parquet æ–‡ä»¶...\")\n",
    "    \n",
    "    try:\n",
    "        # è¯»å–ç°æœ‰æ•°æ®\n",
    "        print(f\"ğŸ“– è¯»å–ç°æœ‰æ–‡ä»¶: {existing_file}\")\n",
    "        existing_df = pd.read_parquet(existing_file)\n",
    "        print(f\"   ç°æœ‰æ•°æ®è¡Œæ•°: {len(existing_df)}\")\n",
    "        \n",
    "        # è¯»å–æ–°æ•°æ®\n",
    "        print(f\"ğŸ“– è¯»å–æ–°æ–‡ä»¶: {new_file}\")\n",
    "        new_df = pd.read_parquet(new_file)\n",
    "        print(f\"   æ–°æ•°æ®è¡Œæ•°: {len(new_df)}\")\n",
    "        \n",
    "        # åˆå¹¶æ•°æ®\n",
    "        print(\"ğŸ”„ åˆå¹¶æ•°æ®ä¸­...\")\n",
    "        combined_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
    "        \n",
    "        # å»é‡ï¼ˆæŒ‰ date + stock_codeï¼‰\n",
    "        print(\"ğŸ§¹ å»é‡å¤„ç†...\")\n",
    "        combined_df = combined_df.drop_duplicates(subset=['date', 'stock_code','concept_code'])\n",
    "        \n",
    "        # æ’åº\n",
    "        print(\"ğŸ“… æŒ‰æ—¥æœŸæ’åº...\")\n",
    "        combined_df = combined_df.sort_values(['date', 'stock_code','concept_code']).reset_index(drop=True)\n",
    "        \n",
    "        print(f\"ğŸ“ˆ åˆå¹¶åæ€»è¡Œæ•°: {len(combined_df)}\")\n",
    "        \n",
    "        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨\n",
    "        output_dir = os.path.dirname(output_file)\n",
    "        if output_dir and not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        \n",
    "        # è½¬æ¢ä¸º pyarrow Table\n",
    "        table = pa.Table.from_pandas(combined_df)\n",
    "        \n",
    "        # å†™å…¥ parquetï¼ˆä½¿ç”¨ä¸æºæ–‡ä»¶ç›¸åŒçš„æ ¼å¼ï¼‰\n",
    "        print(f\"ğŸ’¾ ä¿å­˜åˆå¹¶ç»“æœ: {output_file}\")\n",
    "        pq.write_table(\n",
    "            table,\n",
    "            output_file,\n",
    "            compression='snappy',\n",
    "            version='2.6',\n",
    "            use_dictionary=True,\n",
    "            write_batch_size=64 * 1024 * 1024\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… åˆå¹¶å®Œæˆï¼æ–‡ä»¶å¤§å°: {os.path.getsize(output_file) / (1024*1024):.2f} MB\")\n",
    "        \n",
    "        # éªŒè¯ç»“æœ\n",
    "        print(\"\\nğŸ“‹ éªŒè¯ç»“æœ:\")\n",
    "        result_df = pd.read_parquet(output_file)\n",
    "        print(f\"   æœ€ç»ˆè¡Œæ•°: {len(result_df)}\")\n",
    "        print(f\"   æ—¥æœŸèŒƒå›´: {result_df['date'].min()} åˆ° {result_df['date'].max()}\")\n",
    "        print(f\"   è‚¡ç¥¨æ•°é‡: {result_df['stock_code'].nunique()}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ åˆå¹¶å¤±è´¥: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"ä¸»å‡½æ•°\"\"\"\n",
    "    # è®¾ç½®æ–‡ä»¶è·¯å¾„\n",
    "\n",
    "    existing_file = r\"d:/workspace/xiaoyao/data/stock_daily_concept.parquet\"\n",
    "    new_file = r\"D:/workspace/xiaoyao/redis/parquet/stock_daily_concept_to_merged.parquet\"\n",
    "    output_file = r\"d:/workspace/xiaoyao/redis/parquet/stock_daily_concept.parquet\"\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ğŸš€ å¼€å§‹åˆå¹¶ parquet æ–‡ä»¶\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨\n",
    "    if not os.path.exists(existing_file):\n",
    "        print(f\"âŒ ç°æœ‰æ–‡ä»¶ä¸å­˜åœ¨: {existing_file}\")\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(new_file):\n",
    "        print(f\"âŒ æ–°æ–‡ä»¶ä¸å­˜åœ¨: {new_file}\")\n",
    "        return\n",
    "    \n",
    "    # æ‰§è¡Œåˆå¹¶\n",
    "    success = merge_parquet_files(existing_file, new_file, output_file)\n",
    "    \n",
    "    if success:\n",
    "        print(\"\\nğŸ‰ åˆå¹¶æˆåŠŸï¼\")\n",
    "    else:\n",
    "        print(\"\\nâŒ åˆå¹¶å¤±è´¥ï¼\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8770ce2",
   "metadata": {},
   "source": [
    "## åˆ é™¤å·²ä½¿ç”¨çš„csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c223ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å·²åˆ é™¤ï¼šD:\\workspace\\xiaoyao\\redis\\stock_daily_concept_20251024.csv\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "åˆ é™¤æŒ‡å®šç›®å½•ä¸‹çš„ stock_***.csv æ–‡ä»¶\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def delete_stock_csv_files(target_directory, pattern=\"stock_*.csv\"):\n",
    "    #åˆ é™¤æ»¡è¶³æ¨¡å¼çš„æ‰€æœ‰æ–‡ä»¶\n",
    "    files = glob.glob(os.path.join(target_directory, pattern))\n",
    "    for file in files:\n",
    "        try:\n",
    "            os.remove(file)\n",
    "            print(f\"å·²åˆ é™¤ï¼š{file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"åˆ é™¤ {file} å¤±è´¥ï¼š{e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    delete_stock_csv_files(r'D:\\workspace\\xiaoyao\\redis','stock_daily_concept_*.csv')\n",
    "    print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f46e4da",
   "metadata": {},
   "source": [
    "## å°†æ–°çš„parquetæ–‡ä»¶ç§»åŠ¨åˆ°dataç›®å½•è¦†ç›–åŸæ–‡ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2571397f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved: stock_daily_concept.parquet to D:\\workspace\\xiaoyao\\data\n",
      "Deleted: stock_daily_concept.parquet from D:\\workspace\\xiaoyao\\redis\\parquet\n"
     ]
    }
   ],
   "source": [
    "# å°†å­ç›®å½•ä¸‹çš„æŸä¸ªparquetæ–‡ä»¶ç§»åŠ¨åˆ°æŒ‡å®šç›®å½•\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# å®šä¹‰æºç›®å½•å’Œç›®æ ‡ç›®å½•\n",
    "source_dir = \"D:\\\\workspace\\\\xiaoyao\\\\redis\\\\parquet\"\n",
    "target_dir = \"D:\\\\workspace\\\\xiaoyao\\\\data\"\n",
    "\n",
    "# ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# å®šä¹‰è¦ç§»åŠ¨çš„æ–‡ä»¶\n",
    "file_to_move = \"stock_daily_concept.parquet\"\n",
    "\n",
    "# æ„å»ºæºæ–‡ä»¶çš„å®Œæ•´è·¯å¾„\n",
    "source_file_path = os.path.join(source_dir, file_to_move)\n",
    "\n",
    "# æ„å»ºç›®æ ‡æ–‡ä»¶çš„å®Œæ•´è·¯å¾„\n",
    "target_file_path = os.path.join(target_dir, file_to_move)\n",
    "\n",
    "# æ£€æŸ¥æºæ–‡ä»¶æ˜¯å¦å­˜åœ¨\n",
    "if os.path.exists(source_file_path):\n",
    "    # ç§»åŠ¨æ–‡ä»¶\n",
    "    shutil.move(source_file_path, target_file_path)\n",
    "    print(f\"Moved: {file_to_move} to {target_dir}\")\n",
    "else:\n",
    "    print(f\"File not found: {file_to_move}\")\n",
    "\n",
    "# åˆ é™¤æŒ‡å®šçš„parquetæ–‡ä»¶\n",
    "file_to_delete = os.path.join(source_dir, 'stock_daily_concept_to_merged.parquet')\n",
    "if os.path.exists(file_to_delete):\n",
    "    os.remove(file_to_delete)\n",
    "    print(f\"Deleted: {file_to_move} from {source_dir}\")\n",
    "else:\n",
    "    print(f\"File not found: {file_to_move} in {source_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d277a27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xiaoyao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
