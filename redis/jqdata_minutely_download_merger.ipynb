{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2539bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 已加载Redis配置：host=220.203.1.124, port=6379\n",
      "✅ 临时文件目录：D:\\workspace\\xiaoyao\\redis\\temp_csv\n",
      "✅ 最终存储目录：D:\\workspace\\xiaoyao\\data\\stock_minutely_price\n",
      "✅ Redis连接成功\n",
      "✅ 从Redis获取任务元信息，共71718个任务\n",
      "❌ 程序启动失败：'ResultProcessor' object has no attribute 'receive_and_process_results'\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jay\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py:3587: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import redis\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import threading\n",
    "import time\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor  # 线程池\n",
    "\n",
    "# ---------------------- 配置参数 ----------------------\n",
    "REDIS_CONFIG_PATH = \"redis.conf\"\n",
    "RESULT_QUEUE = \"function_results\"\n",
    "STORAGE_ROOT = r\"D:\\workspace\\xiaoyao\\data\\stock_minutely_price\"\n",
    "MAX_CONVERT_THREADS = 20  # 线程池大小，与worker数量匹配\n",
    "TEMP_DIR = r\"D:\\workspace\\xiaoyao\\redis\\temp_csv\"  # 临时文件目录\n",
    "\n",
    "# ---------------------- 工具函数 ----------------------\n",
    "def load_redis_config(config_path):\n",
    "    if not os.path.exists(config_path):\n",
    "        raise FileNotFoundError(f\"Redis配置文件不存在：{config_path}\")\n",
    "    \n",
    "    host = \"localhost\"\n",
    "    port = 6379\n",
    "    password = \"\"\n",
    "    \n",
    "    with open(config_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line or line.startswith('#'):\n",
    "                continue\n",
    "            if line.startswith('host='):\n",
    "                host = line.split('=', 1)[1].strip()\n",
    "            elif line.startswith('port='):\n",
    "                try:\n",
    "                    port = int(line.split('=', 1)[1].strip())\n",
    "                except ValueError:\n",
    "                    print(f\"警告：port配置格式错误，使用默认值{port}\")\n",
    "            elif line.startswith('password='):\n",
    "                password = line.split('=', 1)[1].strip()\n",
    "    \n",
    "    return {\n",
    "        \"host\": host,\n",
    "        \"port\": port,\n",
    "        \"password\": password,\n",
    "        \"decode_responses\": False,\n",
    "        \"socket_timeout\": 30,\n",
    "        \"socket_keepalive\": True\n",
    "    }\n",
    "\n",
    "# ---------------------- 结果处理类 ----------------------\n",
    "class ResultProcessor:\n",
    "    def __init__(self, redis_config):\n",
    "        # 1. 初始化目录（临时目录+存储目录）\n",
    "        os.makedirs(STORAGE_ROOT, exist_ok=True)\n",
    "        os.makedirs(TEMP_DIR, exist_ok=True)  # 确保临时目录存在\n",
    "        print(f\"✅ 临时文件目录：{TEMP_DIR}\")\n",
    "        print(f\"✅ 最终存储目录：{STORAGE_ROOT}\")\n",
    "        \n",
    "        # 2. Redis连接初始化\n",
    "        self.redis_config = redis_config\n",
    "        self.redis = redis.Redis(** redis_config)\n",
    "        self._test_connection()\n",
    "        \n",
    "        # 3. 元信息存储在Redis中\n",
    "        self.redis_metadata_key = \"task_metadata\"\n",
    "        self.total_tasks = self.redis.hlen(self.redis_metadata_key)\n",
    "        print(f\"✅ 从Redis获取任务元信息，共{self.total_tasks}个任务\")\n",
    "        \n",
    "        # 4. 统计与线程安全配置\n",
    "        self.processed_count = 0\n",
    "        self.success_count = 0\n",
    "        self.failed_count = 0\n",
    "        self.lock = threading.Lock()  # 线程锁（确保统计计数安全）\n",
    "        \n",
    "        # 5. 初始化线程池替代手动管理线程\n",
    "        self.thread_pool = ThreadPoolExecutor(max_workers=MAX_CONVERT_THREADS)\n",
    "        \n",
    "        # 6. 失败任务记录\n",
    "        self.failed_tasks = []\n",
    "        self.failed_tasks_lock = threading.Lock()\n",
    "\n",
    "    def _test_connection(self):\n",
    "        try:\n",
    "            self.redis.ping()\n",
    "            print(\"✅ Redis连接成功\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Redis连接失败：{e}\")\n",
    "            raise SystemExit(1)\n",
    "\n",
    "    def _create_temp_file(self, task_id, csv_str):\n",
    "        \"\"\"将CSV字符串写入临时文件，返回临时文件路径\"\"\"\n",
    "        try:\n",
    "            # 生成唯一临时文件名（避免冲突：任务ID+时间戳）\n",
    "            temp_filename = f\"temp_{task_id}_{datetime.now().strftime('%H%M%S%f')}.csv\"\n",
    "            temp_file_path = os.path.join(TEMP_DIR, temp_filename)\n",
    "            \n",
    "            # 写入CSV数据（UTF-8编码，避免中文乱码）\n",
    "            with open(temp_file_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(csv_str)\n",
    "            \n",
    "            return temp_file_path  # 返回临时文件路径\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 任务 {task_id} 创建临时文件失败：{str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def _append_to_parquet(self, task_id, temp_file_path, trade_date, stock_code):\n",
    "        \"\"\"从临时文件读取CSV，追加到对应分区的Parquet\"\"\"\n",
    "        try:\n",
    "            # 1. 从临时文件读取CSV（容错处理）\n",
    "            df = pd.read_csv(\n",
    "                temp_file_path,\n",
    "                encoding='utf-8',\n",
    "                sep=',',\n",
    "                on_bad_lines='skip',  # 跳过格式错误的行\n",
    "                dtype={\n",
    "                    \"date\": \"str\",\n",
    "                    \"stock_code\": \"str\",\n",
    "                    \"time\": \"str\",\n",
    "                    \"open\": \"float64\",\n",
    "                    \"close\": \"float64\",\n",
    "                    \"high\": \"float64\",\n",
    "                    \"low\": \"float64\",\n",
    "                    \"volume\": \"int64\"\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # 2. 数据校验（确保字段完整）\n",
    "            required_cols = [\"date\", \"stock_code\", \"time\", \"open\", \"close\", \"high\", \"low\", \"volume\"]\n",
    "            if not all(col in df.columns for col in required_cols):\n",
    "                missing = [col for col in required_cols if col not in df.columns]\n",
    "                raise ValueError(f\"缺少必要字段：{missing}\")\n",
    "            \n",
    "            # 3. 创建Parquet分区目录\n",
    "            # 关键修改：将 stock= 改为 stock_code=，保持与数据字段一致\n",
    "            partition_dir = os.path.join(STORAGE_ROOT, f\"date={trade_date}\", f\"stock_code={stock_code}\")\n",
    "            os.makedirs(partition_dir, exist_ok=True)\n",
    "            parquet_path = os.path.join(partition_dir, \"data.parquet\")\n",
    "            \n",
    "            # 4. 追加到Parquet（确保不添加额外字段）\n",
    "            table = pa.Table.from_pandas(df)\n",
    "            \n",
    "            # 检查并删除可能存在的多余字段\n",
    "            if 'stock' in table.column_names:\n",
    "                table = table.drop(['stock'])\n",
    "            \n",
    "            if os.path.exists(parquet_path):\n",
    "                existing_table = pq.read_table(parquet_path)\n",
    "                # 清理现有文件中可能的多余字段\n",
    "                if 'stock' in existing_table.column_names:\n",
    "                    existing_table = existing_table.drop(['stock'])\n",
    "                combined_table = pa.concat_tables([existing_table, table])\n",
    "                pq.write_table(combined_table, parquet_path, compression=\"snappy\")\n",
    "            else:\n",
    "                pq.write_table(table, parquet_path, compression=\"snappy\")\n",
    "            \n",
    "            print(f\"✅ 任务 {task_id}：成功追加到 {parquet_path}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 任务 {task_id} 追加Parquet失败：{str(e)}\")\n",
    "            return False\n",
    "\n",
    "    def _delete_temp_file(self, task_id, temp_file_path):\n",
    "        \"\"\"删除临时文件（确保数据已成功追加后调用）\"\"\"\n",
    "        try:\n",
    "            if os.path.exists(temp_file_path):\n",
    "                os.remove(temp_file_path)\n",
    "                print(f\"ℹ️  任务 {task_id}：已删除临时文件 {os.path.basename(temp_file_path)}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️  任务 {task_id} 删除临时文件失败：{str(e)}（需手动清理）\")\n",
    "            return False\n",
    "\n",
    "    def _process_task(self, task_id, csv_str):\n",
    "        \"\"\"处理单个任务的函数，供线程池调用\"\"\"\n",
    "        temp_file_path = None\n",
    "        \n",
    "        try:\n",
    "            # 1. 创建临时文件\n",
    "            temp_file_path = self._create_temp_file(task_id, csv_str)\n",
    "            if not temp_file_path:\n",
    "                raise Exception(\"创建临时文件失败\")\n",
    "            \n",
    "            # 2. 从Redis获取任务元信息\n",
    "            metadata_value = self.redis.hget(self.redis_metadata_key, task_id)\n",
    "            if not metadata_value:\n",
    "                raise KeyError(f\"任务{task_id}的元信息在Redis中不存在\")\n",
    "            trade_date, stock_code = pickle.loads(metadata_value)\n",
    "            \n",
    "            # 3. 追加到Parquet\n",
    "            append_success = self._append_to_parquet(task_id, temp_file_path, trade_date, stock_code)\n",
    "            if not append_success:\n",
    "                raise Exception(\"追加Parquet失败\")\n",
    "            \n",
    "            # 4. 删除临时文件和Redis中的元信息\n",
    "            self._delete_temp_file(task_id, temp_file_path)\n",
    "            self.redis.hdel(self.redis_metadata_key, task_id)\n",
    "            \n",
    "            # 5. 更新成功计数\n",
    "            with self.lock:\n",
    "                self.success_count += 1\n",
    "        \n",
    "        except Exception as e:\n",
    "            # 记录失败信息\n",
    "            with self.failed_tasks_lock:\n",
    "                self.failed_tasks.append({\n",
    "                    \"task_id\": task_id,\n",
    "                    \"error\": str(e),\n",
    "                    \"traceback\": traceback.format_exc()[:1000]\n",
    "                })\n",
    "            \n",
    "            # 更新失败计数\n",
    "            with self.lock:\n",
    "                self.failed_count += 1\n",
    "            \n",
    "            print(f\"❌ 任务 {task_id} 处理失败：{str(e)}\")\n",
    "            \n",
    "            # 失败时也尝试删除临时文件\n",
    "            if temp_file_path:\n",
    "                self._delete_temp_file(task_id, temp_file_path)\n",
    "        \n",
    "        finally:\n",
    "            # 更新已处理计数\n",
    "            with self.lock:\n",
    "                self.processed_count += 1\n",
    "                # 每100个任务打印一次进度\n",
    "                if self.processed_count % 100 == 0:\n",
    "                    if self.total_tasks > 0:\n",
    "                        progress = (self.processed_count / self.total_tasks) * 100\n",
    "                        print(f\"📊 处理中：进度 {progress:.2f}%，成功{self.success_count}/失败{self.failed_count}/总计{self.processed_count}\")\n",
    "                    else:\n",
    "                        print(f\"📊 处理中：成功{self.success_count}/失败{self.failed_count}/总计{self.processed_count}\")\n",
    "\n",
    "    def receive_and_process_results(self):\n",
    "        \"\"\"接收Redis结果，提交到线程池处理\"\"\"\n",
    "        print(f\"✅ 开始接收结果，总任务数：{self.total_tasks}\")\n",
    "        \n",
    "        # 如果总任务数为0，直接等待并退出\n",
    "        if self.total_tasks == 0:\n",
    "            print(\"ℹ️  没有任务需要处理，将等待10秒后退出\")\n",
    "            time.sleep(10)\n",
    "            print(\"✅ 退出程序\")\n",
    "            return\n",
    "            \n",
    "        last_report_time = time.time()\n",
    "        \n",
    "        # 用于跟踪线程池中的任务\n",
    "        futures = []\n",
    "        \n",
    "        while True:\n",
    "            # 检查是否所有任务已处理完成\n",
    "            with self.lock:\n",
    "                if self.processed_count >= self.total_tasks:\n",
    "                    break\n",
    "            \n",
    "            # 从Redis获取结果（支持重连）\n",
    "            try:\n",
    "                result_data = self.redis.blpop(RESULT_QUEUE, timeout=60)\n",
    "            except redis.exceptions.ConnectionError:\n",
    "                print(f\"⚠️ Redis连接断开，尝试重连...\")\n",
    "                self.redis = redis.Redis(** self.redis_config)\n",
    "                time.sleep(5)\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"❌ 获取Redis结果失败：{str(e)}\")\n",
    "                time.sleep(3)\n",
    "                continue\n",
    "            \n",
    "            if not result_data:\n",
    "                # 定期打印进度（每30秒一次）\n",
    "                with self.lock:\n",
    "                    if self.total_tasks > 0:\n",
    "                        progress = (self.processed_count / self.total_tasks) * 100\n",
    "                        print(f\"⏳ 处理中：进度 {progress:.2f}%，成功{self.success_count}/失败{self.failed_count}/总计{self.processed_count}\")\n",
    "                    else:\n",
    "                        print(f\"⏳ 处理中：成功{self.success_count}/失败{self.failed_count}/总计{self.processed_count}\")\n",
    "                last_report_time = time.time()\n",
    "                continue\n",
    "            \n",
    "            # 解析Redis结果，提交到线程池处理\n",
    "            _, result_bytes = result_data\n",
    "            try:\n",
    "                result = pickle.loads(result_bytes)\n",
    "                task_id = result.get(\"task_id\", \"未知\")\n",
    "                csv_str = result.get(\"result\", \"\")\n",
    "                \n",
    "                if result[\"status\"] == \"success\" and csv_str.strip():\n",
    "                    # 提交任务到线程池处理\n",
    "                    future = self.thread_pool.submit(self._process_task, task_id, csv_str)\n",
    "                    futures.append(future)\n",
    "                    print(f\"ℹ️  任务 {task_id}：已提交到线程池处理\")\n",
    "                else:\n",
    "                    # 远端直接返回失败，记录错误\n",
    "                    with self.failed_tasks_lock:\n",
    "                        self.failed_tasks.append({\n",
    "                            \"task_id\": task_id,\n",
    "                            \"error\": result.get(\"error\", \"远端执行失败\")\n",
    "                        })\n",
    "                    \n",
    "                    with self.lock:\n",
    "                        self.failed_count += 1\n",
    "                        self.processed_count += 1\n",
    "                    \n",
    "                    print(f\"❌ 任务 {task_id}：远端执行失败 → {result.get('error', '未知原因')}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                # 结果解析失败\n",
    "                with self.failed_tasks_lock:\n",
    "                    self.failed_tasks.append({\n",
    "                        \"task_id\": \"未知\",\n",
    "                        \"error\": f\"结果解析失败：{str(e)}\",\n",
    "                        \"traceback\": traceback.format_exc()[:500]\n",
    "                    })\n",
    "                \n",
    "                with self.lock:\n",
    "                    self.processed_count += 1\n",
    "                    self.failed_count += 1\n",
    "                \n",
    "                print(f\"❌ 结果解析失败：{str(e)}\")\n",
    "        \n",
    "        # 等待所有线程池任务完成\n",
    "        print(\"✅ 所有任务已接收，等待线程池处理完成...\")\n",
    "        for future in futures:\n",
    "            future.result()  # 等待任务完成\n",
    "        \n",
    "        # 关闭线程池\n",
    "        self.thread_pool.shutdown()\n",
    "        \n",
    "        # 保存失败任务列表\n",
    "        if self.failed_tasks:\n",
    "            failed_path = f\"failed_tasks_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl\"\n",
    "            with open(failed_path, \"wb\") as f:\n",
    "                pickle.dump(self.failed_tasks, f)\n",
    "            print(f\"⚠️  已保存 {len(self.failed_tasks)} 个失败任务到 {failed_path}\")\n",
    "        \n",
    "        # 最终统计\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"处理完成：总任务数 {self.total_tasks}\")\n",
    "        if self.total_tasks > 0:\n",
    "            print(f\"成功：{self.success_count} ({self.success_count/self.total_tasks*100:.2f}%)\")\n",
    "            print(f\"失败：{self.failed_count} ({self.failed_count/self.total_tasks*100:.2f}%)\")\n",
    "        else:\n",
    "            print(f\"成功：{self.success_count}\")\n",
    "            print(f\"失败：{self.failed_count}\")\n",
    "        print(f\"临时文件目录：{TEMP_DIR}（残留文件需手动清理）\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "# ---------------------- 主函数 ----------------------\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # 1. 加载Redis配置\n",
    "        redis_config = load_redis_config(REDIS_CONFIG_PATH)\n",
    "        print(f\"✅ 已加载Redis配置：host={redis_config['host']}, port={redis_config['port']}\")\n",
    "        \n",
    "        # 2. 初始化处理器并启动\n",
    "        processor = ResultProcessor(redis_config)\n",
    "        processor.receive_and_process_results()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 程序启动失败：{str(e)}\")\n",
    "        raise SystemExit(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909e08b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xiaoyao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
