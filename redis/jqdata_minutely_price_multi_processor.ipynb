{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7c12029",
   "metadata": {},
   "source": [
    "## 1.下载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb58c1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 发送端：Redis连接成功\n",
      "✅ 发送端pandas版本：2.3.2\n",
      "=== 共需获取 279 天的数据 ===\n",
      "=== 该日期下有 0 个股票 ===\n",
      "⚠️ 该日期下股票数量不足1000，跳过\n",
      "=== 该日期下有 0 个股票 ===\n",
      "⚠️ 该日期下股票数量不足1000，跳过\n",
      "=== 该日期下有 5106 个股票 ===\n",
      "📤 已调用远程函数：fetch_minute_stock_data（任务ID：task_7aef942e）\n",
      "✅ 保存成功：stock_minutely_price_20250106_000001.XSHE_000518.XSHE.csv（24000条记录）\n",
      "📤 已调用远程函数：fetch_minute_stock_data（任务ID：task_213d3923）\n",
      "✅ 保存成功：stock_minutely_price_20250106_000519.XSHE_000665.XSHE.csv（24000条记录）\n",
      "📤 已调用远程函数：fetch_minute_stock_data（任务ID：task_dcb0d97c）\n",
      "✅ 保存成功：stock_minutely_price_20250106_000668.XSHE_000819.XSHE.csv（24000条记录）\n",
      "📤 已调用远程函数：fetch_minute_stock_data（任务ID：task_36d879fa）\n",
      "✅ 保存成功：stock_minutely_price_20250106_000820.XSHE_000975.XSHE.csv（24000条记录）\n",
      "📤 已调用远程函数：fetch_minute_stock_data（任务ID：task_1a808839）\n",
      "✅ 保存成功：stock_minutely_price_20250106_000977.XSHE_001376.XSHE.csv（24000条记录）\n",
      "📤 已调用远程函数：fetch_minute_stock_data（任务ID：task_ee0e421c）\n",
      "✅ 保存成功：stock_minutely_price_20250106_001378.XSHE_002095.XSHE.csv（24000条记录）\n",
      "📤 已调用远程函数：fetch_minute_stock_data（任务ID：task_b8db6026）\n",
      "✅ 保存成功：stock_minutely_price_20250106_002096.XSHE_002200.XSHE.csv（24000条记录）\n",
      "📤 已调用远程函数：fetch_minute_stock_data（任务ID：task_0ff16690）\n",
      "✅ 保存成功：stock_minutely_price_20250106_002201.XSHE_002306.XSHE.csv（24000条记录）\n",
      "📤 已调用远程函数：fetch_minute_stock_data（任务ID：task_07e4a7ed）\n",
      "✅ 保存成功：stock_minutely_price_20250106_002307.XSHE_002413.XSHE.csv（24000条记录）\n",
      "📤 已调用远程函数：fetch_minute_stock_data（任务ID：task_23452cf3）\n",
      "✅ 保存成功：stock_minutely_price_20250106_002414.XSHE_002529.XSHE.csv（24000条记录）\n",
      "📤 已调用远程函数：fetch_minute_stock_data（任务ID：task_30c534dd）\n",
      "✅ 保存成功：stock_minutely_price_20250106_002530.XSHE_002634.XSHE.csv（24000条记录）\n",
      "📤 已调用远程函数：fetch_minute_stock_data（任务ID：task_f77d918d）\n",
      "✅ 保存成功：stock_minutely_price_20250106_002635.XSHE_002745.XSHE.csv（24000条记录）\n",
      "📤 已调用远程函数：fetch_minute_stock_data（任务ID：task_c86bf876）\n",
      "✅ 保存成功：stock_minutely_price_20250106_002746.XSHE_002858.XSHE.csv（24000条记录）\n",
      "📤 已调用远程函数：fetch_minute_stock_data（任务ID：task_2095ea4b）\n",
      "✅ 保存成功：stock_minutely_price_20250106_002859.XSHE_002967.XSHE.csv（24000条记录）\n",
      "📤 已调用远程函数：fetch_minute_stock_data（任务ID：task_a9397321）\n",
      "✅ 保存成功：stock_minutely_price_20250106_002968.XSHE_300030.XSHE.csv（24000条记录）\n",
      "📤 已调用远程函数：fetch_minute_stock_data（任务ID：task_5ffbef1f）\n",
      "✅ 保存成功：stock_minutely_price_20250106_300031.XSHE_300137.XSHE.csv（24000条记录）\n",
      "📤 已调用远程函数：fetch_minute_stock_data（任务ID：task_94bb420c）\n",
      "✅ 保存成功：stock_minutely_price_20250106_300138.XSHE_300242.XSHE.csv（24000条记录）\n",
      "📤 已调用远程函数：fetch_minute_stock_data（任务ID：task_c7817755）\n",
      "✅ 保存成功：stock_minutely_price_20250106_300243.XSHE_300351.XSHE.csv（24000条记录）\n",
      "📤 已调用远程函数：fetch_minute_stock_data（任务ID：task_1d2bb9ca）\n",
      "✅ 保存成功：stock_minutely_price_20250106_300352.XSHE_300458.XSHE.csv（24000条记录）\n",
      "📤 已调用远程函数：fetch_minute_stock_data（任务ID：task_52abc564）\n",
      "✅ 保存成功：stock_minutely_price_20250106_300459.XSHE_300562.XSHE.csv（24000条记录）\n",
      "📤 已调用远程函数：fetch_minute_stock_data（任务ID：task_d40b4da6）\n",
      "✅ 保存成功：stock_minutely_price_20250106_300563.XSHE_300665.XSHE.csv（24000条记录）\n",
      "📤 已调用远程函数：fetch_minute_stock_data（任务ID：task_7498a0dd）\n",
      "✅ 保存成功：stock_minutely_price_20250106_300666.XSHE_300773.XSHE.csv（24000条记录）\n",
      "📤 已调用远程函数：fetch_minute_stock_data（任务ID：task_bfed9152）\n",
      "✅ 保存成功：stock_minutely_price_20250106_300774.XSHE_300877.XSHE.csv（24000条记录）\n",
      "📤 已调用远程函数：fetch_minute_stock_data（任务ID：task_9098081e）\n",
      "✅ 保存成功：stock_minutely_price_20250106_300878.XSHE_300983.XSHE.csv（24000条记录）\n",
      "📤 已调用远程函数：fetch_minute_stock_data（任务ID：task_d721b7bf）\n",
      "✅ 保存成功：stock_minutely_price_20250106_300984.XSHE_301090.XSHE.csv（24000条记录）\n",
      "📤 已调用远程函数：fetch_minute_stock_data（任务ID：task_156c625f）\n",
      "✅ 保存成功：stock_minutely_price_20250106_301091.XSHE_301209.XSHE.csv（24000条记录）\n",
      "📤 已调用远程函数：fetch_minute_stock_data（任务ID：task_ad4130e9）\n",
      "✅ 保存成功：stock_minutely_price_20250106_301210.XSHE_301330.XSHE.csv（24000条记录）\n",
      "📤 已调用远程函数：fetch_minute_stock_data（任务ID：task_f5da9e79）\n",
      "✅ 保存成功：stock_minutely_price_20250106_301331.XSHE_301552.XSHE.csv（24000条记录）\n",
      "📤 已调用远程函数：fetch_minute_stock_data（任务ID：task_7e498a56）\n",
      "✅ 保存成功：stock_minutely_price_20250106_301555.XSHE_600085.XSHG.csv（24000条记录）\n",
      "📤 已调用远程函数：fetch_minute_stock_data（任务ID：task_729a0950）\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 135\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stock_code_group \u001b[38;5;129;01min\u001b[39;00m stock_code_groups:\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m         \u001b[38;5;66;03m# 调用远程函数获取当日数据\u001b[39;00m\n\u001b[1;32m--> 135\u001b[0m         csv_data \u001b[38;5;241m=\u001b[39m \u001b[43msender\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_remote_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfetch_minute_stock_data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstock_code_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m         \u001b[38;5;66;03m# 保存为CSV文件，文件名包含日期\u001b[39;00m\n\u001b[0;32m    137\u001b[0m         sender\u001b[38;5;241m.\u001b[39msave_to_csv(csv_data, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstock_minutely_price_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstock_code_group[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstock_code_group[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 39\u001b[0m, in \u001b[0;36mRemoteSender.call_remote_function\u001b[1;34m(self, func_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mredis\u001b[38;5;241m.\u001b[39mrpush(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_queue, pickle\u001b[38;5;241m.\u001b[39mdumps(task))\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m📤 已调用远程函数：\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m（任务ID：\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m）\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 44\u001b[0m, in \u001b[0;36mRemoteSender._get_result\u001b[1;34m(self, task_id, timeout)\u001b[0m\n\u001b[0;32m     42\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time \u001b[38;5;241m<\u001b[39m timeout:\n\u001b[1;32m---> 44\u001b[0m     result_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mredis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult_queue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result_data:\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32md:\\sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\redis\\commands\\core.py:2558\u001b[0m, in \u001b[0;36mListCommands.blpop\u001b[1;34m(self, keys, timeout)\u001b[0m\n\u001b[0;32m   2556\u001b[0m keys \u001b[38;5;241m=\u001b[39m list_or_args(keys, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   2557\u001b[0m keys\u001b[38;5;241m.\u001b[39mappend(timeout)\n\u001b[1;32m-> 2558\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_command\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBLPOP\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\redis\\client.py:621\u001b[0m, in \u001b[0;36mRedis.execute_command\u001b[1;34m(self, *args, **options)\u001b[0m\n\u001b[0;32m    620\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mexecute_command\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions):\n\u001b[1;32m--> 621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_command(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32md:\\sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\redis\\client.py:632\u001b[0m, in \u001b[0;36mRedis._execute_command\u001b[1;34m(self, *args, **options)\u001b[0m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msingle_connection_lock\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_command_parse_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommand_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_close_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_single_connection_client:\n",
      "File \u001b[1;32md:\\sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\redis\\retry.py:105\u001b[0m, in \u001b[0;36mRetry.call_with_retry\u001b[1;34m(self, do, fail)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_supported_errors \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m    107\u001b[0m         failures \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32md:\\sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\redis\\client.py:633\u001b[0m, in \u001b[0;36mRedis._execute_command.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msingle_connection_lock\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mretry\u001b[38;5;241m.\u001b[39mcall_with_retry(\n\u001b[1;32m--> 633\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_command_parse_response(\n\u001b[0;32m    634\u001b[0m             conn, command_name, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m    635\u001b[0m         ),\n\u001b[0;32m    636\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m _: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connection(conn),\n\u001b[0;32m    637\u001b[0m     )\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_single_connection_client:\n",
      "File \u001b[1;32md:\\sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\redis\\client.py:604\u001b[0m, in \u001b[0;36mRedis._send_command_parse_response\u001b[1;34m(self, conn, command_name, *args, **options)\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    601\u001b[0m \u001b[38;5;124;03mSend a command and parse the response\u001b[39;00m\n\u001b[0;32m    602\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    603\u001b[0m conn\u001b[38;5;241m.\u001b[39msend_command(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m--> 604\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_response(conn, command_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32md:\\sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\redis\\client.py:651\u001b[0m, in \u001b[0;36mRedis.parse_response\u001b[1;34m(self, connection, command_name, **options)\u001b[0m\n\u001b[0;32m    649\u001b[0m         options\u001b[38;5;241m.\u001b[39mpop(NEVER_DECODE)\n\u001b[0;32m    650\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 651\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ResponseError:\n\u001b[0;32m    653\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m EMPTY_RESPONSE \u001b[38;5;129;01min\u001b[39;00m options:\n",
      "File \u001b[1;32md:\\sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\redis\\connection.py:650\u001b[0m, in \u001b[0;36mAbstractConnection.read_response\u001b[1;34m(self, disable_decoding, disconnect_on_error, push_request)\u001b[0m\n\u001b[0;32m    646\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parser\u001b[38;5;241m.\u001b[39mread_response(\n\u001b[0;32m    647\u001b[0m             disable_decoding\u001b[38;5;241m=\u001b[39mdisable_decoding, push_request\u001b[38;5;241m=\u001b[39mpush_request\n\u001b[0;32m    648\u001b[0m         )\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdisable_decoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_decoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mtimeout:\n\u001b[0;32m    652\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m disconnect_on_error:\n",
      "File \u001b[1;32md:\\sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\redis\\_parsers\\resp2.py:15\u001b[0m, in \u001b[0;36m_RESP2Parser.read_response\u001b[1;34m(self, disable_decoding)\u001b[0m\n\u001b[0;32m     13\u001b[0m pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer\u001b[38;5;241m.\u001b[39mget_pos() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 15\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdisable_decoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_decoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer:\n",
      "File \u001b[1;32md:\\sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\redis\\_parsers\\resp2.py:59\u001b[0m, in \u001b[0;36m_RESP2Parser._read_response\u001b[1;34m(self, disable_decoding)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m byte \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 59\u001b[0m     response \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     60\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_response(disable_decoding\u001b[38;5;241m=\u001b[39mdisable_decoding)\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mint\u001b[39m(response))\n\u001b[0;32m     62\u001b[0m     ]\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidResponse(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProtocol Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mraw\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\redis\\_parsers\\resp2.py:60\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m byte \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     59\u001b[0m     response \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m---> 60\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdisable_decoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_decoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mint\u001b[39m(response))\n\u001b[0;32m     62\u001b[0m     ]\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidResponse(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProtocol Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mraw\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\redis\\_parsers\\resp2.py:54\u001b[0m, in \u001b[0;36m_RESP2Parser._read_response\u001b[1;34m(self, disable_decoding)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m byte \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 54\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# multi-bulk response\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m byte \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m response \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32md:\\sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\redis\\_parsers\\socket.py:106\u001b[0m, in \u001b[0;36mSocketBuffer.read\u001b[1;34m(self, length)\u001b[0m\n\u001b[0;32m    103\u001b[0m missing \u001b[38;5;241m=\u001b[39m length \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(data)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;66;03m# fill up the buffer and read the remainder\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_from_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m     data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer\u001b[38;5;241m.\u001b[39mread(missing)\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[1;32md:\\sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\redis\\_parsers\\socket.py:65\u001b[0m, in \u001b[0;36mSocketBuffer._read_from_socket\u001b[1;34m(self, length, timeout, raise_on_timeout)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43msocket_read_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m         \u001b[38;5;66;03m# an empty string indicates the server shutdown the socket\u001b[39;00m\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mbytes\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import redis\n",
    "import pickle\n",
    "import time\n",
    "import uuid\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from typing import Any, Optional\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "class RemoteSender:\n",
    "    def __init__(self, host='*', port=6379, password='*'):\n",
    "        self.redis = redis.Redis(\n",
    "            host=host, port=port, password=password,\n",
    "            decode_responses=False\n",
    "        )\n",
    "        self.task_queue = 'function_calls'\n",
    "        self.result_queue = 'function_results'\n",
    "        self._test_connection()\n",
    "        print(f\"✅ 发送端pandas版本：{pd.__version__}\")\n",
    "\n",
    "    def _test_connection(self):\n",
    "        try:\n",
    "            self.redis.ping()\n",
    "            print(\"✅ 发送端：Redis连接成功\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 发送端：连接失败 - {e}\")\n",
    "            raise\n",
    "\n",
    "    def call_remote_function(self, func_name: str, *args, **kwargs) -> Any:\n",
    "        task_id = f\"task_{uuid.uuid4().hex[:8]}\"\n",
    "        task = {\n",
    "            'func_name': func_name,\n",
    "            'args': args,\n",
    "            'kwargs': kwargs,\n",
    "            'task_id': task_id\n",
    "        }\n",
    "        self.redis.rpush(self.task_queue, pickle.dumps(task))\n",
    "        print(f\"📤 已调用远程函数：{func_name}（任务ID：{task_id}）\")\n",
    "        return self._get_result(task_id)\n",
    "\n",
    "    def _get_result(self, task_id: str, timeout=300) -> Any:\n",
    "        start_time = time.time()\n",
    "        while time.time() - start_time < timeout:\n",
    "            result_data = self.redis.blpop(self.result_queue, timeout=10)\n",
    "            if not result_data:\n",
    "                continue\n",
    "\n",
    "            _, res_bytes = result_data\n",
    "            result = pickle.loads(res_bytes)\n",
    "            if result['task_id'] == task_id:\n",
    "                if result['status'] == 'success':\n",
    "                    return result['result']  # 返回CSV字符串\n",
    "                else:\n",
    "                    raise Exception(f\"远程执行失败：{result['error']}\")\n",
    "            self.redis.rpush(self.result_queue, res_bytes)\n",
    "        raise TimeoutError(\"任务超时\")\n",
    "\n",
    "    def save_to_csv(self, csv_str: Optional[str], filename: str) -> bool:\n",
    "        \"\"\"将CSV字符串保存为本地CSV文件（替代Parquet）\"\"\"\n",
    "        if not csv_str:\n",
    "            print(\"⚠️ 数据为空，不保存\")\n",
    "            return False\n",
    "        try:\n",
    "            # 从CSV字符串恢复DataFrame（兼容所有pandas版本）\n",
    "            df = pd.read_csv(StringIO(csv_str))\n",
    "            # 保存为CSV文件\n",
    "            df.to_csv(filename, index=False)\n",
    "            print(f\"✅ 保存成功：{filename}（{len(df)}条记录）\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 保存失败：{e}\")\n",
    "            return False\n",
    "\n",
    "def generate_date_range(start_date_str: str, end_date_str: str) -> list:\n",
    "    \"\"\"生成从开始日期到结束日期的所有日期字符串（YYYYMMDD格式）\"\"\"\n",
    "    dates = []\n",
    "    try:\n",
    "        start_date = datetime.strptime(start_date_str, '%Y%m%d')\n",
    "        end_date = datetime.strptime(end_date_str, '%Y%m%d')\n",
    "        \n",
    "        if start_date > end_date:\n",
    "            raise ValueError(\"开始日期晚于结束日期\")\n",
    "            \n",
    "        current_date = start_date\n",
    "        while current_date <= end_date:\n",
    "            dates.append(current_date.strftime('%Y%m%d'))\n",
    "            current_date += timedelta(days=1)\n",
    "    except Exception as e:\n",
    "        print(f\"日期处理错误：{e}\")\n",
    "    return dates\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # 从配置文件读取Redis连接信息\n",
    "    with open('redis.conf', 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('host='):\n",
    "                host = line.split('=')[1].strip()\n",
    "            elif line.startswith('port='):\n",
    "                port = int(line.split('=')[1].strip())\n",
    "            elif line.startswith('password='):\n",
    "                password = line.split('=')[1].strip()\n",
    "    # 初始化Redis发送端\n",
    "    sender = RemoteSender(host=host, port=port, password=password)\n",
    "    \n",
    "    # 定义日期范围：从20250516到20250923\n",
    "    # 读取../data/stock_daily_price.parquet文件，获取最大的日期+1，是start_date\n",
    "    df = pd.read_parquet('../data/stock_minutely_price.parquet')\n",
    "\n",
    "    start_date = '20250104'#(df['date'].max() + timedelta(days=1)).strftime('%Y%m%d')\n",
    "    # 获取当日日期-1，是end_date\n",
    "    end_date = (datetime.today() - timedelta(days=1)).strftime('%Y%m%d')\n",
    "    \n",
    "    # 生成日期列表\n",
    "    date_list = generate_date_range(start_date, end_date)\n",
    "    print(f\"=== 共需获取 {len(date_list)} 天的数据 ===\")\n",
    "    \n",
    "\n",
    "    daily_df = pd.read_parquet('../data/stock_daily_price.parquet')\n",
    "    # 循环调用获取每日数据\n",
    "    for i, date in enumerate(date_list, 1):\n",
    "        # 读取daily_df，获取该date下、paused==0的stock_code列表\n",
    "        # stock_code_list = ['600570.XSHG','600570.XSHG']\n",
    "        stock_code_list = daily_df[(daily_df['date'] == date) & (daily_df['paused'] == 0)]['stock_code'].tolist()\n",
    "        print(f\"=== 该日期下有 {len(stock_code_list)} 个股票 ===\")\n",
    "        # 如果stock_code_list为空或者数量小于1000，就跳过\n",
    "        if not stock_code_list or len(stock_code_list) < 2:\n",
    "            print(f\"⚠️ 该日期下股票数量不足1000，跳过\")\n",
    "            continue\n",
    "        # 将 stock_code_list 分成每1000个一组\n",
    "        stock_code_groups = [stock_code_list[i:i+100] for i in range(0, len(stock_code_list), 100)]\n",
    "        for stock_code_group in stock_code_groups:\n",
    "            try:\n",
    "                # 调用远程函数获取当日数据\n",
    "                csv_data = sender.call_remote_function('fetch_minute_stock_data', date,stock_code_group)\n",
    "                # 保存为CSV文件，文件名包含日期\n",
    "                sender.save_to_csv(csv_data, f'stock_minutely_price_{date}_{stock_code_group[0]}_{stock_code_group[-1]}.csv')\n",
    "                # 适当延迟，避免请求过于频繁\n",
    "                time.sleep(0.05)\n",
    "            except Exception as e:\n",
    "                print(f\"❌ {date} 处理失败：{e}\")\n",
    "                # 失败后也延迟一下，避免快速重试导致的问题\n",
    "                time.sleep(1)\n",
    "    print(\"\\n=== 所有日期处理完成 ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47950e5",
   "metadata": {},
   "source": [
    "## 将csv合并为一个parquet文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68654520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "🚀 开始合并 stock_***.csv 文件到 parquet\n",
      "============================================================\n",
      "📁 开始处理目录: d:/workspace/xiaoyao/redis/\n",
      "📊 找到 29 个 CSV 文件\n",
      "正在处理 (1/29): stock_minutely_price_20250106_000001.XSHE_000518.XSHE.csv\n",
      "  ✅ 成功读取 24000 条记录\n",
      "正在处理 (2/29): stock_minutely_price_20250106_000519.XSHE_000665.XSHE.csv\n",
      "  ✅ 成功读取 24000 条记录\n",
      "正在处理 (3/29): stock_minutely_price_20250106_000668.XSHE_000819.XSHE.csv\n",
      "  ✅ 成功读取 24000 条记录\n",
      "正在处理 (4/29): stock_minutely_price_20250106_000820.XSHE_000975.XSHE.csv\n",
      "  ✅ 成功读取 24000 条记录\n",
      "正在处理 (5/29): stock_minutely_price_20250106_000977.XSHE_001376.XSHE.csv\n",
      "  ✅ 成功读取 24000 条记录\n",
      "正在处理 (6/29): stock_minutely_price_20250106_001378.XSHE_002095.XSHE.csv\n",
      "  ✅ 成功读取 24000 条记录\n",
      "正在处理 (7/29): stock_minutely_price_20250106_002096.XSHE_002200.XSHE.csv\n",
      "  ✅ 成功读取 24000 条记录\n",
      "正在处理 (8/29): stock_minutely_price_20250106_002201.XSHE_002306.XSHE.csv\n",
      "  ✅ 成功读取 24000 条记录\n",
      "正在处理 (9/29): stock_minutely_price_20250106_002307.XSHE_002413.XSHE.csv\n",
      "  ✅ 成功读取 24000 条记录\n",
      "正在处理 (10/29): stock_minutely_price_20250106_002414.XSHE_002529.XSHE.csv\n",
      "  ✅ 成功读取 24000 条记录\n",
      "正在处理 (11/29): stock_minutely_price_20250106_002530.XSHE_002634.XSHE.csv\n",
      "  ✅ 成功读取 24000 条记录\n",
      "正在处理 (12/29): stock_minutely_price_20250106_002635.XSHE_002745.XSHE.csv\n",
      "  ✅ 成功读取 24000 条记录\n",
      "正在处理 (13/29): stock_minutely_price_20250106_002746.XSHE_002858.XSHE.csv\n",
      "  ✅ 成功读取 24000 条记录\n",
      "正在处理 (14/29): stock_minutely_price_20250106_002859.XSHE_002967.XSHE.csv\n",
      "  ✅ 成功读取 24000 条记录\n",
      "正在处理 (15/29): stock_minutely_price_20250106_002968.XSHE_300030.XSHE.csv\n",
      "  ✅ 成功读取 24000 条记录\n",
      "正在处理 (16/29): stock_minutely_price_20250106_300031.XSHE_300137.XSHE.csv\n",
      "  ✅ 成功读取 24000 条记录\n",
      "正在处理 (17/29): stock_minutely_price_20250106_300138.XSHE_300242.XSHE.csv\n",
      "  ✅ 成功读取 24000 条记录\n",
      "正在处理 (18/29): stock_minutely_price_20250106_300243.XSHE_300351.XSHE.csv\n",
      "  ✅ 成功读取 24000 条记录\n",
      "正在处理 (19/29): stock_minutely_price_20250106_300352.XSHE_300458.XSHE.csv\n",
      "  ✅ 成功读取 24000 条记录\n",
      "正在处理 (20/29): stock_minutely_price_20250106_300459.XSHE_300562.XSHE.csv\n",
      "  ✅ 成功读取 24000 条记录\n",
      "正在处理 (21/29): stock_minutely_price_20250106_300563.XSHE_300665.XSHE.csv\n",
      "  ✅ 成功读取 24000 条记录\n",
      "正在处理 (22/29): stock_minutely_price_20250106_300666.XSHE_300773.XSHE.csv\n",
      "  ✅ 成功读取 24000 条记录\n",
      "正在处理 (23/29): stock_minutely_price_20250106_300774.XSHE_300877.XSHE.csv\n",
      "  ✅ 成功读取 24000 条记录\n",
      "正在处理 (24/29): stock_minutely_price_20250106_300878.XSHE_300983.XSHE.csv\n",
      "  ✅ 成功读取 24000 条记录\n",
      "正在处理 (25/29): stock_minutely_price_20250106_300984.XSHE_301090.XSHE.csv\n",
      "  ✅ 成功读取 24000 条记录\n",
      "正在处理 (26/29): stock_minutely_price_20250106_301091.XSHE_301209.XSHE.csv\n",
      "  ✅ 成功读取 24000 条记录\n",
      "正在处理 (27/29): stock_minutely_price_20250106_301210.XSHE_301330.XSHE.csv\n",
      "  ✅ 成功读取 24000 条记录\n",
      "正在处理 (28/29): stock_minutely_price_20250106_301331.XSHE_301552.XSHE.csv\n",
      "  ✅ 成功读取 24000 条记录\n",
      "正在处理 (29/29): stock_minutely_price_20250106_301555.XSHE_600085.XSHG.csv\n",
      "  ✅ 成功读取 24000 条记录\n",
      "\n",
      "📊 合并所有数据...\n",
      "📈 总计 696000 条记录（去重后）\n",
      "✅ 成功保存到: d:/workspace/xiaoyao/redis/parquet\\stock_minutely_price_to_merged.parquet\n",
      "📊 文件大小: 7.19 MB\n",
      "\n",
      "🎉 合并完成！\n",
      "\n",
      "📋 验证结果:\n",
      "   总行数: 696000\n",
      "   日期范围: 2025-01-06 00:00:00 到 2025-01-06 00:00:00\n",
      "   股票数量: 2900\n",
      "   列名: ['date', 'stock_code', 'time', 'open', 'close', 'high', 'low', 'volume']\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "将 /d:/workspace/xiaoyao/redis/ 目录下的所有 stock_***.csv 文件合并为一个 parquet 文件\n",
    "确保与现有 /d:/workspace/xiaoyao/data/stock_daily_price.parquet 保持字段、压缩方式一致\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "\n",
    "def merge_stock_csv_to_parquet(csv_dir, output_parquet_file):\n",
    "    \"\"\"\n",
    "    合并指定目录下的所有 stock_***.csv 文件到单个 parquet 文件\n",
    "    \n",
    "    Args:\n",
    "        csv_dir: CSV 文件所在目录\n",
    "        output_parquet_file: 输出的 parquet 文件路径\n",
    "    \"\"\"\n",
    "    print(f\"📁 开始处理目录: {csv_dir}\")\n",
    "    \n",
    "    # 获取所有 stock_***.csv 文件\n",
    "    csv_pattern = os.path.join(csv_dir, \"stock_minutely_price_*.csv\")\n",
    "    csv_files = glob.glob(csv_pattern)\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(\"❌ 未找到 stock_minutely_price_*.csv 文件\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"📊 找到 {len(csv_files)} 个 CSV 文件\")\n",
    "    \n",
    "    # 按文件名排序（确保按日期顺序处理）\n",
    "    csv_files.sort()\n",
    "    \n",
    "    # 读取并合并所有 CSV 文件\n",
    "    all_dataframes = []\n",
    "    total_records = 0\n",
    "    \n",
    "    for i, csv_file in enumerate(csv_files, 1):\n",
    "        filename = os.path.basename(csv_file)\n",
    "        print(f\"正在处理 ({i}/{len(csv_files)}): {filename}\")\n",
    "        \n",
    "        try:\n",
    "            # 读取 CSV 文件\n",
    "            df = pd.read_csv(csv_file)\n",
    "            \n",
    "            # 数据验证和清洗\n",
    "            # 确保 date 列是 datetime 类型\n",
    "            df['date'] = pd.to_datetime(df['date'])\n",
    "            \n",
    "            # 确保数值列的数据类型正确\n",
    "            numeric_columns = ['open', 'close', 'low', 'high', 'volume']\n",
    "            \n",
    "            for col in numeric_columns:\n",
    "                if col in df.columns:\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            \n",
    "            # 删除无效数据\n",
    "            df = df.dropna(subset=['date', 'stock_code','time'])\n",
    "            \n",
    "            all_dataframes.append(df)\n",
    "            total_records += len(df)\n",
    "            print(f\"  ✅ 成功读取 {len(df)} 条记录\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ❌ 处理失败: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not all_dataframes:\n",
    "        print(\"❌ 没有成功读取任何数据\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"\\n📊 合并所有数据...\")\n",
    "    # 合并所有数据框\n",
    "    combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "    \n",
    "    # 去重（按 date + stock_code + time）\n",
    "    combined_df = combined_df.drop_duplicates(subset=['date', 'stock_code','time'])\n",
    "    \n",
    "    # 按日期和股票代码排序\n",
    "    combined_df = combined_df.sort_values(['date', 'stock_code','time']).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"📈 总计 {len(combined_df)} 条记录（去重后）\")\n",
    "    \n",
    "    # 确保输出目录存在\n",
    "    output_dir = os.path.dirname(output_parquet_file)\n",
    "    if output_dir and not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\"📁 创建输出目录: {output_dir}\")\n",
    "    \n",
    "    # 转换为 pyarrow Table\n",
    "    table = pa.Table.from_pandas(combined_df)\n",
    "    \n",
    "    # 使用与目标文件相同的压缩方式 (snappy) 和格式写入 parquet\n",
    "    try:\n",
    "        pq.write_table(\n",
    "            table, \n",
    "            output_parquet_file,\n",
    "            compression='snappy',\n",
    "            version='2.6',  # 使用较新的 parquet 版本\n",
    "            use_dictionary=True,\n",
    "            write_batch_size=64 * 1024 * 1024  # 64MB batch size for better performance\n",
    "        )\n",
    "        \n",
    "        print(f\"✅ 成功保存到: {output_parquet_file}\")\n",
    "        print(f\"📊 文件大小: {os.path.getsize(output_parquet_file) / (1024*1024):.2f} MB\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 保存 parquet 文件失败: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数\"\"\"\n",
    "    # 设置路径\n",
    "    csv_directory = \"d:/workspace/xiaoyao/redis/\"\n",
    "    # 确保输出目录存在\n",
    "    output_dir = os.path.join(csv_directory, 'parquet')\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\"📁 创建输出目录: {output_dir}\")\n",
    "\n",
    "    output_file = os.path.join(output_dir, 'stock_minutely_price_to_merged.parquet')\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"🚀 开始合并 stock_***.csv 文件到 parquet\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 执行合并\n",
    "    success = merge_stock_csv_to_parquet(csv_directory, output_file)\n",
    "    \n",
    "    if success:\n",
    "        print(\"\\n🎉 合并完成！\")\n",
    "        \n",
    "        # 验证结果\n",
    "        try:\n",
    "            print(\"\\n📋 验证结果:\")\n",
    "            result_df = pd.read_parquet(output_file)\n",
    "            print(f\"   总行数: {len(result_df)}\")\n",
    "            print(f\"   日期范围: {result_df['date'].min()} 到 {result_df['date'].max()}\")\n",
    "            print(f\"   股票数量: {result_df['stock_code'].nunique()}\")\n",
    "            print(f\"   列名: {list(result_df.columns)}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️  验证失败: {e}\")\n",
    "    \n",
    "    else:\n",
    "        print(\"\\n❌ 合并失败！\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6ff005",
   "metadata": {},
   "source": [
    "## 将新生成的 merged_stock_data.parquet 与现有的 stock_daily_price.parquet 合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a0e4253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "🚀 开始合并 parquet 文件\n",
      "============================================================\n",
      "📊 开始合并 parquet 文件...\n",
      "📖 读取现有文件: d:/workspace/xiaoyao/data/stock_minutely_price.parquet\n",
      "   现有数据行数: 2494560\n",
      "📖 读取新文件: d:/workspace/xiaoyao/redis/parquet/stock_minutely_price_to_merged.parquet\n",
      "   新数据行数: 696000\n",
      "🔄 合并数据中...\n",
      "🧹 去重处理...\n",
      "📅 按日期排序...\n",
      "📈 合并后总行数: 3190560\n",
      "💾 保存合并结果: d:/workspace/xiaoyao/redis/parquet/stock_minutely_price.parquet\n",
      "✅ 合并完成！文件大小: 31.86 MB\n",
      "\n",
      "📋 验证结果:\n",
      "   最终行数: 3190560\n",
      "   日期范围: 2025-01-02 00:00:00 到 2025-09-30 00:00:00\n",
      "   股票数量: 5108\n",
      "\n",
      "🎉 合并成功！\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "将新生成的 merged_stock_data.parquet 与现有的 stock_daily_price.parquet 合并\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import os\n",
    "\n",
    "\n",
    "def merge_parquet_files(existing_file, new_file, output_file):\n",
    "    \"\"\"\n",
    "    合并两个 parquet 文件\n",
    "    \n",
    "    Args:\n",
    "        existing_file: 现有的 parquet 文件路径\n",
    "        new_file: 新的 parquet 文件路径  \n",
    "        output_file: 输出的合并文件路径\n",
    "    \"\"\"\n",
    "    print(\"📊 开始合并 parquet 文件...\")\n",
    "    \n",
    "    try:\n",
    "        # 读取现有数据\n",
    "        print(f\"📖 读取现有文件: {existing_file}\")\n",
    "        existing_df = pd.read_parquet(existing_file)\n",
    "        print(f\"   现有数据行数: {len(existing_df)}\")\n",
    "        \n",
    "        # 读取新数据\n",
    "        print(f\"📖 读取新文件: {new_file}\")\n",
    "        new_df = pd.read_parquet(new_file)\n",
    "        print(f\"   新数据行数: {len(new_df)}\")\n",
    "        \n",
    "        # 合并数据\n",
    "        print(\"🔄 合并数据中...\")\n",
    "        combined_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
    "        \n",
    "        # 去重（按 date + stock_code）\n",
    "        print(\"🧹 去重处理...\")\n",
    "        combined_df = combined_df.drop_duplicates(subset=['date', 'stock_code', 'time'])\n",
    "        \n",
    "        # 排序\n",
    "        print(\"📅 按日期排序...\")\n",
    "        combined_df = combined_df.sort_values(['date', 'stock_code', 'time']).reset_index(drop=True)\n",
    "        \n",
    "        print(f\"📈 合并后总行数: {len(combined_df)}\")\n",
    "        \n",
    "        # 确保输出目录存在\n",
    "        output_dir = os.path.dirname(output_file)\n",
    "        if output_dir and not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        \n",
    "        # 转换为 pyarrow Table\n",
    "        table = pa.Table.from_pandas(combined_df)\n",
    "        \n",
    "        # 写入 parquet（使用与源文件相同的格式）\n",
    "        print(f\"💾 保存合并结果: {output_file}\")\n",
    "        pq.write_table(\n",
    "            table,\n",
    "            output_file,\n",
    "            compression='snappy',\n",
    "            version='2.6',\n",
    "            use_dictionary=True,\n",
    "            write_batch_size=64 * 1024 * 1024\n",
    "        )\n",
    "        \n",
    "        print(f\"✅ 合并完成！文件大小: {os.path.getsize(output_file) / (1024*1024):.2f} MB\")\n",
    "        \n",
    "        # 验证结果\n",
    "        print(\"\\n📋 验证结果:\")\n",
    "        result_df = pd.read_parquet(output_file)\n",
    "        print(f\"   最终行数: {len(result_df)}\")\n",
    "        print(f\"   日期范围: {result_df['date'].min()} 到 {result_df['date'].max()}\")\n",
    "        print(f\"   股票数量: {result_df['stock_code'].nunique()}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 合并失败: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数\"\"\"\n",
    "    # 设置文件路径\n",
    "\n",
    "    existing_file = \"d:/workspace/xiaoyao/data/stock_minutely_price.parquet\"\n",
    "    new_file = \"d:/workspace/xiaoyao/redis/parquet/stock_minutely_price_to_merged.parquet\"\n",
    "    output_file = \"d:/workspace/xiaoyao/redis/parquet/stock_minutely_price.parquet\"\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(\"🚀 开始合并 parquet 文件\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 检查文件是否存在\n",
    "    if not os.path.exists(existing_file):\n",
    "        print(f\"❌ 现有文件不存在: {existing_file}\")\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(new_file):\n",
    "        print(f\"❌ 新文件不存在: {new_file}\")\n",
    "        return\n",
    "    \n",
    "    # 执行合并\n",
    "    success = merge_parquet_files(existing_file, new_file, output_file)\n",
    "    \n",
    "    if success:\n",
    "        print(\"\\n🎉 合并成功！\")\n",
    "    else:\n",
    "        print(\"\\n❌ 合并失败！\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8770ce2",
   "metadata": {},
   "source": [
    "## 删除已使用的csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10c223ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_minutely_price_20250106_000001.XSHE_000518.XSHE.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_minutely_price_20250106_000519.XSHE_000665.XSHE.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_minutely_price_20250106_000668.XSHE_000819.XSHE.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_minutely_price_20250106_000820.XSHE_000975.XSHE.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_minutely_price_20250106_000977.XSHE_001376.XSHE.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_minutely_price_20250106_001378.XSHE_002095.XSHE.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_minutely_price_20250106_002096.XSHE_002200.XSHE.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_minutely_price_20250106_002201.XSHE_002306.XSHE.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_minutely_price_20250106_002307.XSHE_002413.XSHE.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_minutely_price_20250106_002414.XSHE_002529.XSHE.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_minutely_price_20250106_002530.XSHE_002634.XSHE.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_minutely_price_20250106_002635.XSHE_002745.XSHE.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_minutely_price_20250106_002746.XSHE_002858.XSHE.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_minutely_price_20250106_002859.XSHE_002967.XSHE.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_minutely_price_20250106_002968.XSHE_300030.XSHE.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_minutely_price_20250106_300031.XSHE_300137.XSHE.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_minutely_price_20250106_300138.XSHE_300242.XSHE.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_minutely_price_20250106_300243.XSHE_300351.XSHE.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_minutely_price_20250106_300352.XSHE_300458.XSHE.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_minutely_price_20250106_300459.XSHE_300562.XSHE.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_minutely_price_20250106_300563.XSHE_300665.XSHE.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_minutely_price_20250106_300666.XSHE_300773.XSHE.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_minutely_price_20250106_300774.XSHE_300877.XSHE.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_minutely_price_20250106_300878.XSHE_300983.XSHE.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_minutely_price_20250106_300984.XSHE_301090.XSHE.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_minutely_price_20250106_301091.XSHE_301209.XSHE.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_minutely_price_20250106_301210.XSHE_301330.XSHE.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_minutely_price_20250106_301331.XSHE_301552.XSHE.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_minutely_price_20250106_301555.XSHE_600085.XSHG.csv\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "删除指定目录下的 stock_***.csv 文件\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def delete_stock_csv_files(target_directory, pattern=\"stock_*.csv\"):\n",
    "    #删除满足模式的所有文件\n",
    "    files = glob.glob(os.path.join(target_directory, pattern))\n",
    "    for file in files:\n",
    "        try:\n",
    "            os.remove(file)\n",
    "            print(f\"已删除：{file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"删除 {file} 失败：{e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    delete_stock_csv_files(r'D:\\workspace\\xiaoyao\\redis','stock_minutely_price_*.csv')\n",
    "    print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f46e4da",
   "metadata": {},
   "source": [
    "## 将新的parquet文件移动到data目录覆盖原文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2571397f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved: stock_minutely_price.parquet to D:\\workspace\\xiaoyao\\data\n",
      "Deleted: stock_minutely_price.parquet from D:\\workspace\\xiaoyao\\redis\\parquet\n"
     ]
    }
   ],
   "source": [
    "# 将子目录下的某个parquet文件移动到指定目录\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# 定义源目录和目标目录\n",
    "source_dir = \"D:\\\\workspace\\\\xiaoyao\\\\redis\\\\parquet\"\n",
    "target_dir = \"D:\\\\workspace\\\\xiaoyao\\\\data\"\n",
    "\n",
    "# 确保目标目录存在\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# 定义要移动的文件\n",
    "file_to_move = \"stock_minutely_price.parquet\"\n",
    "\n",
    "# 构建源文件的完整路径\n",
    "source_file_path = os.path.join(source_dir, file_to_move)\n",
    "\n",
    "# 构建目标文件的完整路径\n",
    "target_file_path = os.path.join(target_dir, file_to_move)\n",
    "\n",
    "# 检查源文件是否存在\n",
    "if os.path.exists(source_file_path):\n",
    "    # 移动文件\n",
    "    shutil.move(source_file_path, target_file_path)\n",
    "    print(f\"Moved: {file_to_move} to {target_dir}\")\n",
    "else:\n",
    "    print(f\"File not found: {file_to_move}\")\n",
    "\n",
    "# 删除指定的parquet文件\n",
    "file_to_delete = os.path.join(source_dir, 'stock_minutely_price_to_merged.parquet')\n",
    "if os.path.exists(file_to_delete):\n",
    "    os.remove(file_to_delete)\n",
    "    print(f\"Deleted: {file_to_move} from {source_dir}\")\n",
    "else:\n",
    "    print(f\"File not found: {file_to_move} in {source_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d277a27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6225bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c712c785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xiaoyao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
