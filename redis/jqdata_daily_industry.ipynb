{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7c12029",
   "metadata": {},
   "source": [
    "## 1.下载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb58c1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "import pickle\n",
    "import time\n",
    "import uuid\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from typing import Any, Optional\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "class RemoteSender:\n",
    "    def __init__(self, host='*', port=6379, password='*'):\n",
    "        self.redis = redis.Redis(\n",
    "            host=host, port=port, password=password,\n",
    "            decode_responses=False\n",
    "        )\n",
    "        self.task_queue = 'function_calls'\n",
    "        self.result_queue = 'function_results'\n",
    "        self._test_connection()\n",
    "        print(f\"✅ 发送端pandas版本：{pd.__version__}\")\n",
    "\n",
    "    def _test_connection(self):\n",
    "        try:\n",
    "            self.redis.ping()\n",
    "            print(\"✅ 发送端：Redis连接成功\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 发送端：连接失败 - {e}\")\n",
    "            raise\n",
    "\n",
    "    def call_remote_function(self, func_name: str, *args, **kwargs) -> Any:\n",
    "        task_id = f\"task_{uuid.uuid4().hex[:8]}\"\n",
    "        task = {\n",
    "            'func_name': func_name,\n",
    "            'args': args,\n",
    "            'kwargs': kwargs,\n",
    "            'task_id': task_id\n",
    "        }\n",
    "        self.redis.rpush(self.task_queue, pickle.dumps(task))\n",
    "        print(f\"📤 已调用远程函数：{func_name}（任务ID：{task_id}）\")\n",
    "        return self._get_result(task_id)\n",
    "\n",
    "    def _get_result(self, task_id: str, timeout=300) -> Any:\n",
    "        start_time = time.time()\n",
    "        while time.time() - start_time < timeout:\n",
    "            result_data = self.redis.blpop(self.result_queue, timeout=10)\n",
    "            if not result_data:\n",
    "                continue\n",
    "\n",
    "            _, res_bytes = result_data\n",
    "            result = pickle.loads(res_bytes)\n",
    "            if result['task_id'] == task_id:\n",
    "                if result['status'] == 'success':\n",
    "                    return result['result']  # 返回CSV字符串\n",
    "                else:\n",
    "                    raise Exception(f\"远程执行失败：{result['error']}\")\n",
    "            self.redis.rpush(self.result_queue, res_bytes)\n",
    "        raise TimeoutError(\"任务超时\")\n",
    "\n",
    "    def save_to_csv(self, csv_str: Optional[str], filename: str) -> bool:\n",
    "        \"\"\"将CSV字符串保存为本地CSV文件（替代Parquet）\"\"\"\n",
    "        if not csv_str:\n",
    "            print(\"⚠️ 数据为空，不保存\")\n",
    "            return False\n",
    "        try:\n",
    "            # 从CSV字符串恢复DataFrame（兼容所有pandas版本）\n",
    "            df = pd.read_csv(StringIO(csv_str))\n",
    "            # 保存为CSV文件\n",
    "            df.to_csv(filename, index=False)\n",
    "            print(f\"✅ 保存成功：{filename}（{len(df)}条记录）\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 保存失败：{e}\")\n",
    "            return False\n",
    "\n",
    "def generate_date_range(start_date_str: str, end_date_str: str) -> list:\n",
    "    \"\"\"生成从开始日期到结束日期的所有日期字符串（YYYYMMDD格式）\"\"\"\n",
    "    dates = []\n",
    "    try:\n",
    "        start_date = datetime.strptime(start_date_str, '%Y%m%d')\n",
    "        end_date = datetime.strptime(end_date_str, '%Y%m%d')\n",
    "        \n",
    "        if start_date > end_date:\n",
    "            raise ValueError(\"开始日期晚于结束日期\")\n",
    "            \n",
    "        current_date = start_date\n",
    "        while current_date <= end_date:\n",
    "            dates.append(current_date.strftime('%Y%m%d'))\n",
    "            current_date += timedelta(days=1)\n",
    "    except Exception as e:\n",
    "        print(f\"日期处理错误：{e}\")\n",
    "    return dates\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # 从配置文件读取Redis连接信息\n",
    "    with open('redis.conf', 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('host='):\n",
    "                host = line.split('=')[1].strip()\n",
    "            elif line.startswith('port='):\n",
    "                port = int(line.split('=')[1].strip())\n",
    "            elif line.startswith('password='):\n",
    "                password = line.split('=')[1].strip()\n",
    "    # 初始化Redis发送端\n",
    "    sender = RemoteSender(host=host, port=port, password=password)\n",
    "    \n",
    "    # 定义日期范围：从20250516到20250923\n",
    "    # 读取../data/stock_daily_price.parquet文件，获取最大的日期+1，是start_date\n",
    "    df = pd.read_parquet('../data/stock_daily_industry.parquet')\n",
    "    start_date = '20250101' #(df['date'].max() + timedelta(days=1)).strftime('%Y%m%d')\n",
    "    # 获取当日日期-1，是end_date\n",
    "    end_date = (datetime.today() - timedelta(days=1)).strftime('%Y%m%d')\n",
    "    \n",
    "    # 生成日期列表\n",
    "    date_list = generate_date_range(start_date, end_date)\n",
    "    print(f\"=== 共需获取 {len(date_list)} 天的数据 ===\")\n",
    "    \n",
    "    # 循环调用获取每日数据\n",
    "    for i, date in enumerate(date_list, 1):\n",
    "        print(f\"\\n=== 正在处理 {i}/{len(date_list)}：{date} ===\")\n",
    "        try:\n",
    "            # 调用远程函数获取当日数据\n",
    "            csv_data = sender.call_remote_function('fetch_stock_industry', date)\n",
    "            # 保存为CSV文件，文件名包含日期\n",
    "            sender.save_to_csv(csv_data, f'stock_daily_industry_{date}.csv')\n",
    "            \n",
    "            # 适当延迟，避免请求过于频繁\n",
    "            time.sleep(0.5)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ {date} 处理失败：{e}\")\n",
    "            # 失败后也延迟一下，避免快速重试导致的问题\n",
    "            time.sleep(2)\n",
    "    \n",
    "    print(\"\\n=== 所有日期处理完成 ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47950e5",
   "metadata": {},
   "source": [
    "## 将csv合并为一个parquet文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68654520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "🚀 开始合并 stock_***.csv 文件到 parquet\n",
      "============================================================\n",
      "📁 开始处理目录: d:/workspace/xiaoyao/redis/\n",
      "📊 找到 242 个 CSV 文件\n",
      "正在处理 (1/242): stock_daily_industry_20230103.csv\n",
      "  ✅ 成功读取 4905 条记录\n",
      "正在处理 (2/242): stock_daily_industry_20230104.csv\n",
      "  ✅ 成功读取 4905 条记录\n",
      "正在处理 (3/242): stock_daily_industry_20230105.csv\n",
      "  ✅ 成功读取 4905 条记录\n",
      "正在处理 (4/242): stock_daily_industry_20230106.csv\n",
      "  ✅ 成功读取 4906 条记录\n",
      "正在处理 (5/242): stock_daily_industry_20230109.csv\n",
      "  ✅ 成功读取 4906 条记录\n",
      "正在处理 (6/242): stock_daily_industry_20230110.csv\n",
      "  ✅ 成功读取 4906 条记录\n",
      "正在处理 (7/242): stock_daily_industry_20230111.csv\n",
      "  ✅ 成功读取 4906 条记录\n",
      "正在处理 (8/242): stock_daily_industry_20230112.csv\n",
      "  ✅ 成功读取 4906 条记录\n",
      "正在处理 (9/242): stock_daily_industry_20230113.csv\n",
      "  ✅ 成功读取 4906 条记录\n",
      "正在处理 (10/242): stock_daily_industry_20230116.csv\n",
      "  ✅ 成功读取 4906 条记录\n",
      "正在处理 (11/242): stock_daily_industry_20230117.csv\n",
      "  ✅ 成功读取 4906 条记录\n",
      "正在处理 (12/242): stock_daily_industry_20230118.csv\n",
      "  ✅ 成功读取 4907 条记录\n",
      "正在处理 (13/242): stock_daily_industry_20230119.csv\n",
      "  ✅ 成功读取 4909 条记录\n",
      "正在处理 (14/242): stock_daily_industry_20230120.csv\n",
      "  ✅ 成功读取 4909 条记录\n",
      "正在处理 (15/242): stock_daily_industry_20230130.csv\n",
      "  ✅ 成功读取 4910 条记录\n",
      "正在处理 (16/242): stock_daily_industry_20230131.csv\n",
      "  ✅ 成功读取 4911 条记录\n",
      "正在处理 (17/242): stock_daily_industry_20230201.csv\n",
      "  ✅ 成功读取 4912 条记录\n",
      "正在处理 (18/242): stock_daily_industry_20230202.csv\n",
      "  ✅ 成功读取 4912 条记录\n",
      "正在处理 (19/242): stock_daily_industry_20230203.csv\n",
      "  ✅ 成功读取 4912 条记录\n",
      "正在处理 (20/242): stock_daily_industry_20230206.csv\n",
      "  ✅ 成功读取 4912 条记录\n",
      "正在处理 (21/242): stock_daily_industry_20230207.csv\n",
      "  ✅ 成功读取 4912 条记录\n",
      "正在处理 (22/242): stock_daily_industry_20230208.csv\n",
      "  ✅ 成功读取 4914 条记录\n",
      "正在处理 (23/242): stock_daily_industry_20230209.csv\n",
      "  ✅ 成功读取 4916 条记录\n",
      "正在处理 (24/242): stock_daily_industry_20230210.csv\n",
      "  ✅ 成功读取 4916 条记录\n",
      "正在处理 (25/242): stock_daily_industry_20230213.csv\n",
      "  ✅ 成功读取 4916 条记录\n",
      "正在处理 (26/242): stock_daily_industry_20230214.csv\n",
      "  ✅ 成功读取 4917 条记录\n",
      "正在处理 (27/242): stock_daily_industry_20230215.csv\n",
      "  ✅ 成功读取 4917 条记录\n",
      "正在处理 (28/242): stock_daily_industry_20230216.csv\n",
      "  ✅ 成功读取 4920 条记录\n",
      "正在处理 (29/242): stock_daily_industry_20230217.csv\n",
      "  ✅ 成功读取 4921 条记录\n",
      "正在处理 (30/242): stock_daily_industry_20230220.csv\n",
      "  ✅ 成功读取 4922 条记录\n",
      "正在处理 (31/242): stock_daily_industry_20230221.csv\n",
      "  ✅ 成功读取 4923 条记录\n",
      "正在处理 (32/242): stock_daily_industry_20230222.csv\n",
      "  ✅ 成功读取 4924 条记录\n",
      "正在处理 (33/242): stock_daily_industry_20230223.csv\n",
      "  ✅ 成功读取 4924 条记录\n",
      "正在处理 (34/242): stock_daily_industry_20230224.csv\n",
      "  ✅ 成功读取 4924 条记录\n",
      "正在处理 (35/242): stock_daily_industry_20230227.csv\n",
      "  ✅ 成功读取 4925 条记录\n",
      "正在处理 (36/242): stock_daily_industry_20230228.csv\n",
      "  ✅ 成功读取 4925 条记录\n",
      "正在处理 (37/242): stock_daily_industry_20230301.csv\n",
      "  ✅ 成功读取 4927 条记录\n",
      "正在处理 (38/242): stock_daily_industry_20230302.csv\n",
      "  ✅ 成功读取 4927 条记录\n",
      "正在处理 (39/242): stock_daily_industry_20230303.csv\n",
      "  ✅ 成功读取 4929 条记录\n",
      "正在处理 (40/242): stock_daily_industry_20230306.csv\n",
      "  ✅ 成功读取 4930 条记录\n",
      "正在处理 (41/242): stock_daily_industry_20230307.csv\n",
      "  ✅ 成功读取 4931 条记录\n",
      "正在处理 (42/242): stock_daily_industry_20230308.csv\n",
      "  ✅ 成功读取 4932 条记录\n",
      "正在处理 (43/242): stock_daily_industry_20230309.csv\n",
      "  ✅ 成功读取 4934 条记录\n",
      "正在处理 (44/242): stock_daily_industry_20230310.csv\n",
      "  ✅ 成功读取 4935 条记录\n",
      "正在处理 (45/242): stock_daily_industry_20230313.csv\n",
      "  ✅ 成功读取 4937 条记录\n",
      "正在处理 (46/242): stock_daily_industry_20230314.csv\n",
      "  ✅ 成功读取 4937 条记录\n",
      "正在处理 (47/242): stock_daily_industry_20230315.csv\n",
      "  ✅ 成功读取 4938 条记录\n",
      "正在处理 (48/242): stock_daily_industry_20230316.csv\n",
      "  ✅ 成功读取 4939 条记录\n",
      "正在处理 (49/242): stock_daily_industry_20230317.csv\n",
      "  ✅ 成功读取 4939 条记录\n",
      "正在处理 (50/242): stock_daily_industry_20230320.csv\n",
      "  ✅ 成功读取 4941 条记录\n",
      "正在处理 (51/242): stock_daily_industry_20230321.csv\n",
      "  ✅ 成功读取 4943 条记录\n",
      "正在处理 (52/242): stock_daily_industry_20230322.csv\n",
      "  ✅ 成功读取 4941 条记录\n",
      "正在处理 (53/242): stock_daily_industry_20230323.csv\n",
      "  ✅ 成功读取 4941 条记录\n",
      "正在处理 (54/242): stock_daily_industry_20230324.csv\n",
      "  ✅ 成功读取 4941 条记录\n",
      "正在处理 (55/242): stock_daily_industry_20230327.csv\n",
      "  ✅ 成功读取 4942 条记录\n",
      "正在处理 (56/242): stock_daily_industry_20230328.csv\n",
      "  ✅ 成功读取 4943 条记录\n",
      "正在处理 (57/242): stock_daily_industry_20230329.csv\n",
      "  ✅ 成功读取 4946 条记录\n",
      "正在处理 (58/242): stock_daily_industry_20230330.csv\n",
      "  ✅ 成功读取 4946 条记录\n",
      "正在处理 (59/242): stock_daily_industry_20230331.csv\n",
      "  ✅ 成功读取 4947 条记录\n",
      "正在处理 (60/242): stock_daily_industry_20230403.csv\n",
      "  ✅ 成功读取 4947 条记录\n",
      "正在处理 (61/242): stock_daily_industry_20230404.csv\n",
      "  ✅ 成功读取 4951 条记录\n",
      "正在处理 (62/242): stock_daily_industry_20230406.csv\n",
      "  ✅ 成功读取 4951 条记录\n",
      "正在处理 (63/242): stock_daily_industry_20230407.csv\n",
      "  ✅ 成功读取 4952 条记录\n",
      "正在处理 (64/242): stock_daily_industry_20230410.csv\n",
      "  ✅ 成功读取 4962 条记录\n",
      "正在处理 (65/242): stock_daily_industry_20230411.csv\n",
      "  ✅ 成功读取 4962 条记录\n",
      "正在处理 (66/242): stock_daily_industry_20230412.csv\n",
      "  ✅ 成功读取 4962 条记录\n",
      "正在处理 (67/242): stock_daily_industry_20230413.csv\n",
      "  ✅ 成功读取 4962 条记录\n",
      "正在处理 (68/242): stock_daily_industry_20230414.csv\n",
      "  ✅ 成功读取 4962 条记录\n",
      "正在处理 (69/242): stock_daily_industry_20230417.csv\n",
      "  ✅ 成功读取 4964 条记录\n",
      "正在处理 (70/242): stock_daily_industry_20230418.csv\n",
      "  ✅ 成功读取 4967 条记录\n",
      "正在处理 (71/242): stock_daily_industry_20230419.csv\n",
      "  ✅ 成功读取 4968 条记录\n",
      "正在处理 (72/242): stock_daily_industry_20230420.csv\n",
      "  ✅ 成功读取 4969 条记录\n",
      "正在处理 (73/242): stock_daily_industry_20230421.csv\n",
      "  ✅ 成功读取 4970 条记录\n",
      "正在处理 (74/242): stock_daily_industry_20230424.csv\n",
      "  ✅ 成功读取 4972 条记录\n",
      "正在处理 (75/242): stock_daily_industry_20230425.csv\n",
      "  ✅ 成功读取 4973 条记录\n",
      "正在处理 (76/242): stock_daily_industry_20230426.csv\n",
      "  ✅ 成功读取 4973 条记录\n",
      "正在处理 (77/242): stock_daily_industry_20230427.csv\n",
      "  ✅ 成功读取 4973 条记录\n",
      "正在处理 (78/242): stock_daily_industry_20230428.csv\n",
      "  ✅ 成功读取 4973 条记录\n",
      "正在处理 (79/242): stock_daily_industry_20230504.csv\n",
      "  ✅ 成功读取 4973 条记录\n",
      "正在处理 (80/242): stock_daily_industry_20230505.csv\n",
      "  ✅ 成功读取 4975 条记录\n",
      "正在处理 (81/242): stock_daily_industry_20230508.csv\n",
      "  ✅ 成功读取 4976 条记录\n",
      "正在处理 (82/242): stock_daily_industry_20230509.csv\n",
      "  ✅ 成功读取 4976 条记录\n",
      "正在处理 (83/242): stock_daily_industry_20230510.csv\n",
      "  ✅ 成功读取 4978 条记录\n",
      "正在处理 (84/242): stock_daily_industry_20230511.csv\n",
      "  ✅ 成功读取 4979 条记录\n",
      "正在处理 (85/242): stock_daily_industry_20230512.csv\n",
      "  ✅ 成功读取 4980 条记录\n",
      "正在处理 (86/242): stock_daily_industry_20230515.csv\n",
      "  ✅ 成功读取 4980 条记录\n",
      "正在处理 (87/242): stock_daily_industry_20230516.csv\n",
      "  ✅ 成功读取 4982 条记录\n",
      "正在处理 (88/242): stock_daily_industry_20230517.csv\n",
      "  ✅ 成功读取 4983 条记录\n",
      "正在处理 (89/242): stock_daily_industry_20230518.csv\n",
      "  ✅ 成功读取 4985 条记录\n",
      "正在处理 (90/242): stock_daily_industry_20230519.csv\n",
      "  ✅ 成功读取 4988 条记录\n",
      "正在处理 (91/242): stock_daily_industry_20230522.csv\n",
      "  ✅ 成功读取 4990 条记录\n",
      "正在处理 (92/242): stock_daily_industry_20230523.csv\n",
      "  ✅ 成功读取 4992 条记录\n",
      "正在处理 (93/242): stock_daily_industry_20230524.csv\n",
      "  ✅ 成功读取 4993 条记录\n",
      "正在处理 (94/242): stock_daily_industry_20230525.csv\n",
      "  ✅ 成功读取 4994 条记录\n",
      "正在处理 (95/242): stock_daily_industry_20230526.csv\n",
      "  ✅ 成功读取 4995 条记录\n",
      "正在处理 (96/242): stock_daily_industry_20230529.csv\n",
      "  ✅ 成功读取 4995 条记录\n",
      "正在处理 (97/242): stock_daily_industry_20230530.csv\n",
      "  ✅ 成功读取 4995 条记录\n",
      "正在处理 (98/242): stock_daily_industry_20230531.csv\n",
      "  ✅ 成功读取 4995 条记录\n",
      "正在处理 (99/242): stock_daily_industry_20230601.csv\n",
      "  ✅ 成功读取 4997 条记录\n",
      "正在处理 (100/242): stock_daily_industry_20230602.csv\n",
      "  ✅ 成功读取 4999 条记录\n",
      "正在处理 (101/242): stock_daily_industry_20230605.csv\n",
      "  ✅ 成功读取 5000 条记录\n",
      "正在处理 (102/242): stock_daily_industry_20230606.csv\n",
      "  ✅ 成功读取 5002 条记录\n",
      "正在处理 (103/242): stock_daily_industry_20230607.csv\n",
      "  ✅ 成功读取 5001 条记录\n",
      "正在处理 (104/242): stock_daily_industry_20230608.csv\n",
      "  ✅ 成功读取 5002 条记录\n",
      "正在处理 (105/242): stock_daily_industry_20230609.csv\n",
      "  ✅ 成功读取 5004 条记录\n",
      "正在处理 (106/242): stock_daily_industry_20230612.csv\n",
      "  ✅ 成功读取 5005 条记录\n",
      "正在处理 (107/242): stock_daily_industry_20230613.csv\n",
      "  ✅ 成功读取 5005 条记录\n",
      "正在处理 (108/242): stock_daily_industry_20230614.csv\n",
      "  ✅ 成功读取 5006 条记录\n",
      "正在处理 (109/242): stock_daily_industry_20230615.csv\n",
      "  ✅ 成功读取 5007 条记录\n",
      "正在处理 (110/242): stock_daily_industry_20230616.csv\n",
      "  ✅ 成功读取 5008 条记录\n",
      "正在处理 (111/242): stock_daily_industry_20230619.csv\n",
      "  ✅ 成功读取 5009 条记录\n",
      "正在处理 (112/242): stock_daily_industry_20230620.csv\n",
      "  ✅ 成功读取 5011 条记录\n",
      "正在处理 (113/242): stock_daily_industry_20230621.csv\n",
      "  ✅ 成功读取 5012 条记录\n",
      "正在处理 (114/242): stock_daily_industry_20230626.csv\n",
      "  ✅ 成功读取 5009 条记录\n",
      "正在处理 (115/242): stock_daily_industry_20230627.csv\n",
      "  ✅ 成功读取 5013 条记录\n",
      "正在处理 (116/242): stock_daily_industry_20230628.csv\n",
      "  ✅ 成功读取 5016 条记录\n",
      "正在处理 (117/242): stock_daily_industry_20230629.csv\n",
      "  ✅ 成功读取 5017 条记录\n",
      "正在处理 (118/242): stock_daily_industry_20230630.csv\n",
      "  ✅ 成功读取 5019 条记录\n",
      "正在处理 (119/242): stock_daily_industry_20230703.csv\n",
      "  ✅ 成功读取 5018 条记录\n",
      "正在处理 (120/242): stock_daily_industry_20230704.csv\n",
      "  ✅ 成功读取 5019 条记录\n",
      "正在处理 (121/242): stock_daily_industry_20230705.csv\n",
      "  ✅ 成功读取 5018 条记录\n",
      "正在处理 (122/242): stock_daily_industry_20230706.csv\n",
      "  ✅ 成功读取 5015 条记录\n",
      "正在处理 (123/242): stock_daily_industry_20230707.csv\n",
      "  ✅ 成功读取 5017 条记录\n",
      "正在处理 (124/242): stock_daily_industry_20230710.csv\n",
      "  ✅ 成功读取 5017 条记录\n",
      "正在处理 (125/242): stock_daily_industry_20230711.csv\n",
      "  ✅ 成功读取 5017 条记录\n",
      "正在处理 (126/242): stock_daily_industry_20230712.csv\n",
      "  ✅ 成功读取 5018 条记录\n",
      "正在处理 (127/242): stock_daily_industry_20230713.csv\n",
      "  ✅ 成功读取 5015 条记录\n",
      "正在处理 (128/242): stock_daily_industry_20230714.csv\n",
      "  ✅ 成功读取 5015 条记录\n",
      "正在处理 (129/242): stock_daily_industry_20230717.csv\n",
      "  ✅ 成功读取 5017 条记录\n",
      "正在处理 (130/242): stock_daily_industry_20230718.csv\n",
      "  ✅ 成功读取 5018 条记录\n",
      "正在处理 (131/242): stock_daily_industry_20230719.csv\n",
      "  ✅ 成功读取 5021 条记录\n",
      "正在处理 (132/242): stock_daily_industry_20230720.csv\n",
      "  ✅ 成功读取 5022 条记录\n",
      "正在处理 (133/242): stock_daily_industry_20230721.csv\n",
      "  ✅ 成功读取 5023 条记录\n",
      "正在处理 (134/242): stock_daily_industry_20230724.csv\n",
      "  ✅ 成功读取 5025 条记录\n",
      "正在处理 (135/242): stock_daily_industry_20230725.csv\n",
      "  ✅ 成功读取 5027 条记录\n",
      "正在处理 (136/242): stock_daily_industry_20230726.csv\n",
      "  ✅ 成功读取 5030 条记录\n",
      "正在处理 (137/242): stock_daily_industry_20230727.csv\n",
      "  ✅ 成功读取 5031 条记录\n",
      "正在处理 (138/242): stock_daily_industry_20230728.csv\n",
      "  ✅ 成功读取 5031 条记录\n",
      "正在处理 (139/242): stock_daily_industry_20230731.csv\n",
      "  ✅ 成功读取 5030 条记录\n",
      "正在处理 (140/242): stock_daily_industry_20230801.csv\n",
      "  ✅ 成功读取 5031 条记录\n",
      "正在处理 (141/242): stock_daily_industry_20230802.csv\n",
      "  ✅ 成功读取 5031 条记录\n",
      "正在处理 (142/242): stock_daily_industry_20230803.csv\n",
      "  ✅ 成功读取 5033 条记录\n",
      "正在处理 (143/242): stock_daily_industry_20230804.csv\n",
      "  ✅ 成功读取 5033 条记录\n",
      "正在处理 (144/242): stock_daily_industry_20230807.csv\n",
      "  ✅ 成功读取 5034 条记录\n",
      "正在处理 (145/242): stock_daily_industry_20230808.csv\n",
      "  ✅ 成功读取 5035 条记录\n",
      "正在处理 (146/242): stock_daily_industry_20230809.csv\n",
      "  ✅ 成功读取 5038 条记录\n",
      "正在处理 (147/242): stock_daily_industry_20230810.csv\n",
      "  ✅ 成功读取 5039 条记录\n",
      "正在处理 (148/242): stock_daily_industry_20230811.csv\n",
      "  ✅ 成功读取 5038 条记录\n",
      "正在处理 (149/242): stock_daily_industry_20230814.csv\n",
      "  ✅ 成功读取 5038 条记录\n",
      "正在处理 (150/242): stock_daily_industry_20230815.csv\n",
      "  ✅ 成功读取 5040 条记录\n",
      "正在处理 (151/242): stock_daily_industry_20230816.csv\n",
      "  ✅ 成功读取 5041 条记录\n",
      "正在处理 (152/242): stock_daily_industry_20230817.csv\n",
      "  ✅ 成功读取 5043 条记录\n",
      "正在处理 (153/242): stock_daily_industry_20230818.csv\n",
      "  ✅ 成功读取 5045 条记录\n",
      "正在处理 (154/242): stock_daily_industry_20230821.csv\n",
      "  ✅ 成功读取 5045 条记录\n",
      "正在处理 (155/242): stock_daily_industry_20230822.csv\n",
      "  ✅ 成功读取 5046 条记录\n",
      "正在处理 (156/242): stock_daily_industry_20230823.csv\n",
      "  ✅ 成功读取 5047 条记录\n",
      "正在处理 (157/242): stock_daily_industry_20230824.csv\n",
      "  ✅ 成功读取 5047 条记录\n",
      "正在处理 (158/242): stock_daily_industry_20230825.csv\n",
      "  ✅ 成功读取 5048 条记录\n",
      "正在处理 (159/242): stock_daily_industry_20230828.csv\n",
      "  ✅ 成功读取 5049 条记录\n",
      "正在处理 (160/242): stock_daily_industry_20230829.csv\n",
      "  ✅ 成功读取 5049 条记录\n",
      "正在处理 (161/242): stock_daily_industry_20230830.csv\n",
      "  ✅ 成功读取 5050 条记录\n",
      "正在处理 (162/242): stock_daily_industry_20230831.csv\n",
      "  ✅ 成功读取 5050 条记录\n",
      "正在处理 (163/242): stock_daily_industry_20230901.csv\n",
      "  ✅ 成功读取 5051 条记录\n",
      "正在处理 (164/242): stock_daily_industry_20230904.csv\n",
      "  ✅ 成功读取 5051 条记录\n",
      "正在处理 (165/242): stock_daily_industry_20230905.csv\n",
      "  ✅ 成功读取 5052 条记录\n",
      "正在处理 (166/242): stock_daily_industry_20230906.csv\n",
      "  ✅ 成功读取 5053 条记录\n",
      "正在处理 (167/242): stock_daily_industry_20230907.csv\n",
      "  ✅ 成功读取 5053 条记录\n",
      "正在处理 (168/242): stock_daily_industry_20230908.csv\n",
      "  ✅ 成功读取 5054 条记录\n",
      "正在处理 (169/242): stock_daily_industry_20230911.csv\n",
      "  ✅ 成功读取 5056 条记录\n",
      "正在处理 (170/242): stock_daily_industry_20230912.csv\n",
      "  ✅ 成功读取 5056 条记录\n",
      "正在处理 (171/242): stock_daily_industry_20230913.csv\n",
      "  ✅ 成功读取 5056 条记录\n",
      "正在处理 (172/242): stock_daily_industry_20230914.csv\n",
      "  ✅ 成功读取 5057 条记录\n",
      "正在处理 (173/242): stock_daily_industry_20230915.csv\n",
      "  ✅ 成功读取 5058 条记录\n",
      "正在处理 (174/242): stock_daily_industry_20230918.csv\n",
      "  ✅ 成功读取 5058 条记录\n",
      "正在处理 (175/242): stock_daily_industry_20230919.csv\n",
      "  ✅ 成功读取 5058 条记录\n",
      "正在处理 (176/242): stock_daily_industry_20230920.csv\n",
      "  ✅ 成功读取 5060 条记录\n",
      "正在处理 (177/242): stock_daily_industry_20230921.csv\n",
      "  ✅ 成功读取 5061 条记录\n",
      "正在处理 (178/242): stock_daily_industry_20230922.csv\n",
      "  ✅ 成功读取 5061 条记录\n",
      "正在处理 (179/242): stock_daily_industry_20230925.csv\n",
      "  ✅ 成功读取 5063 条记录\n",
      "正在处理 (180/242): stock_daily_industry_20230926.csv\n",
      "  ✅ 成功读取 5063 条记录\n",
      "正在处理 (181/242): stock_daily_industry_20230927.csv\n",
      "  ✅ 成功读取 5063 条记录\n",
      "正在处理 (182/242): stock_daily_industry_20230928.csv\n",
      "  ✅ 成功读取 5065 条记录\n",
      "正在处理 (183/242): stock_daily_industry_20231009.csv\n",
      "  ✅ 成功读取 5065 条记录\n",
      "正在处理 (184/242): stock_daily_industry_20231010.csv\n",
      "  ✅ 成功读取 5066 条记录\n",
      "正在处理 (185/242): stock_daily_industry_20231011.csv\n",
      "  ✅ 成功读取 5067 条记录\n",
      "正在处理 (186/242): stock_daily_industry_20231012.csv\n",
      "  ✅ 成功读取 5067 条记录\n",
      "正在处理 (187/242): stock_daily_industry_20231013.csv\n",
      "  ✅ 成功读取 5067 条记录\n",
      "正在处理 (188/242): stock_daily_industry_20231016.csv\n",
      "  ✅ 成功读取 5067 条记录\n",
      "正在处理 (189/242): stock_daily_industry_20231017.csv\n",
      "  ✅ 成功读取 5069 条记录\n",
      "正在处理 (190/242): stock_daily_industry_20231018.csv\n",
      "  ✅ 成功读取 5069 条记录\n",
      "正在处理 (191/242): stock_daily_industry_20231019.csv\n",
      "  ✅ 成功读取 5069 条记录\n",
      "正在处理 (192/242): stock_daily_industry_20231020.csv\n",
      "  ✅ 成功读取 5069 条记录\n",
      "正在处理 (193/242): stock_daily_industry_20231023.csv\n",
      "  ✅ 成功读取 5070 条记录\n",
      "正在处理 (194/242): stock_daily_industry_20231024.csv\n",
      "  ✅ 成功读取 5071 条记录\n",
      "正在处理 (195/242): stock_daily_industry_20231025.csv\n",
      "  ✅ 成功读取 5071 条记录\n",
      "正在处理 (196/242): stock_daily_industry_20231026.csv\n",
      "  ✅ 成功读取 5070 条记录\n",
      "正在处理 (197/242): stock_daily_industry_20231027.csv\n",
      "  ✅ 成功读取 5070 条记录\n",
      "正在处理 (198/242): stock_daily_industry_20231030.csv\n",
      "  ✅ 成功读取 5071 条记录\n",
      "正在处理 (199/242): stock_daily_industry_20231031.csv\n",
      "  ✅ 成功读取 5072 条记录\n",
      "正在处理 (200/242): stock_daily_industry_20231101.csv\n",
      "  ✅ 成功读取 5073 条记录\n",
      "正在处理 (201/242): stock_daily_industry_20231102.csv\n",
      "  ✅ 成功读取 5073 条记录\n",
      "正在处理 (202/242): stock_daily_industry_20231103.csv\n",
      "  ✅ 成功读取 5074 条记录\n",
      "正在处理 (203/242): stock_daily_industry_20231106.csv\n",
      "  ✅ 成功读取 5074 条记录\n",
      "正在处理 (204/242): stock_daily_industry_20231107.csv\n",
      "  ✅ 成功读取 5075 条记录\n",
      "正在处理 (205/242): stock_daily_industry_20231108.csv\n",
      "  ✅ 成功读取 5075 条记录\n",
      "正在处理 (206/242): stock_daily_industry_20231109.csv\n",
      "  ✅ 成功读取 5076 条记录\n",
      "正在处理 (207/242): stock_daily_industry_20231110.csv\n",
      "  ✅ 成功读取 5076 条记录\n",
      "正在处理 (208/242): stock_daily_industry_20231113.csv\n",
      "  ✅ 成功读取 5077 条记录\n",
      "正在处理 (209/242): stock_daily_industry_20231114.csv\n",
      "  ✅ 成功读取 5077 条记录\n",
      "正在处理 (210/242): stock_daily_industry_20231115.csv\n",
      "  ✅ 成功读取 5077 条记录\n",
      "正在处理 (211/242): stock_daily_industry_20231116.csv\n",
      "  ✅ 成功读取 5078 条记录\n",
      "正在处理 (212/242): stock_daily_industry_20231117.csv\n",
      "  ✅ 成功读取 5079 条记录\n",
      "正在处理 (213/242): stock_daily_industry_20231120.csv\n",
      "  ✅ 成功读取 5079 条记录\n",
      "正在处理 (214/242): stock_daily_industry_20231121.csv\n",
      "  ✅ 成功读取 5079 条记录\n",
      "正在处理 (215/242): stock_daily_industry_20231122.csv\n",
      "  ✅ 成功读取 5079 条记录\n",
      "正在处理 (216/242): stock_daily_industry_20231123.csv\n",
      "  ✅ 成功读取 5079 条记录\n",
      "正在处理 (217/242): stock_daily_industry_20231124.csv\n",
      "  ✅ 成功读取 5079 条记录\n",
      "正在处理 (218/242): stock_daily_industry_20231127.csv\n",
      "  ✅ 成功读取 5079 条记录\n",
      "正在处理 (219/242): stock_daily_industry_20231128.csv\n",
      "  ✅ 成功读取 5080 条记录\n",
      "正在处理 (220/242): stock_daily_industry_20231129.csv\n",
      "  ✅ 成功读取 5081 条记录\n",
      "正在处理 (221/242): stock_daily_industry_20231130.csv\n",
      "  ✅ 成功读取 5081 条记录\n",
      "正在处理 (222/242): stock_daily_industry_20231201.csv\n",
      "  ✅ 成功读取 5082 条记录\n",
      "正在处理 (223/242): stock_daily_industry_20231204.csv\n",
      "  ✅ 成功读取 5082 条记录\n",
      "正在处理 (224/242): stock_daily_industry_20231205.csv\n",
      "  ✅ 成功读取 5083 条记录\n",
      "正在处理 (225/242): stock_daily_industry_20231206.csv\n",
      "  ✅ 成功读取 5084 条记录\n",
      "正在处理 (226/242): stock_daily_industry_20231207.csv\n",
      "  ✅ 成功读取 5084 条记录\n",
      "正在处理 (227/242): stock_daily_industry_20231208.csv\n",
      "  ✅ 成功读取 5085 条记录\n",
      "正在处理 (228/242): stock_daily_industry_20231211.csv\n",
      "  ✅ 成功读取 5085 条记录\n",
      "正在处理 (229/242): stock_daily_industry_20231212.csv\n",
      "  ✅ 成功读取 5086 条记录\n",
      "正在处理 (230/242): stock_daily_industry_20231213.csv\n",
      "  ✅ 成功读取 5087 条记录\n",
      "正在处理 (231/242): stock_daily_industry_20231214.csv\n",
      "  ✅ 成功读取 5087 条记录\n",
      "正在处理 (232/242): stock_daily_industry_20231215.csv\n",
      "  ✅ 成功读取 5088 条记录\n",
      "正在处理 (233/242): stock_daily_industry_20231218.csv\n",
      "  ✅ 成功读取 5089 条记录\n",
      "正在处理 (234/242): stock_daily_industry_20231219.csv\n",
      "  ✅ 成功读取 5089 条记录\n",
      "正在处理 (235/242): stock_daily_industry_20231220.csv\n",
      "  ✅ 成功读取 5090 条记录\n",
      "正在处理 (236/242): stock_daily_industry_20231221.csv\n",
      "  ✅ 成功读取 5091 条记录\n",
      "正在处理 (237/242): stock_daily_industry_20231222.csv\n",
      "  ✅ 成功读取 5092 条记录\n",
      "正在处理 (238/242): stock_daily_industry_20231225.csv\n",
      "  ✅ 成功读取 5092 条记录\n",
      "正在处理 (239/242): stock_daily_industry_20231226.csv\n",
      "  ✅ 成功读取 5093 条记录\n",
      "正在处理 (240/242): stock_daily_industry_20231227.csv\n",
      "  ✅ 成功读取 5094 条记录\n",
      "正在处理 (241/242): stock_daily_industry_20231228.csv\n",
      "  ✅ 成功读取 5095 条记录\n",
      "正在处理 (242/242): stock_daily_industry_20231229.csv\n",
      "  ✅ 成功读取 5096 条记录\n",
      "\n",
      "📊 合并所有数据...\n",
      "📈 总计 1211865 条记录（去重后）\n",
      "✅ 成功保存到: d:/workspace/xiaoyao/redis/parquet\\stock_daily_industry_to_merged.parquet\n",
      "📊 文件大小: 9.71 MB\n",
      "\n",
      "🎉 合并完成！\n",
      "\n",
      "📋 验证结果:\n",
      "   总行数: 1211865\n",
      "   日期范围: 2023-01-03 00:00:00 到 2023-12-29 00:00:00\n",
      "   股票数量: 5141\n",
      "   列名: ['date', 'stock_code', 'zjw_industry_code', 'zjw_industry_name', 'jq_l1_industry_code', 'jq_l1_industry_name', 'jq_l2_industry_code', 'jq_l2_industry_name', 'sw_l1_industry_code', 'sw_l1_industry_name', 'sw_l2_industry_code', 'sw_l2_industry_name', 'sw_l3_industry_code', 'sw_l3_industry_name']\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "将 /d:/workspace/xiaoyao/redis/ 目录下的所有 stock_***.csv 文件合并为一个 parquet 文件\n",
    "确保与现有 /d:/workspace/xiaoyao/data/stock_daily_price.parquet 保持字段、压缩方式一致\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "\n",
    "def merge_stock_csv_to_parquet(csv_dir, output_parquet_file):\n",
    "    \"\"\"\n",
    "    合并指定目录下的所有 stock_***.csv 文件到单个 parquet 文件\n",
    "    \n",
    "    Args:\n",
    "        csv_dir: CSV 文件所在目录\n",
    "        output_parquet_file: 输出的 parquet 文件路径\n",
    "    \"\"\"\n",
    "    print(f\"📁 开始处理目录: {csv_dir}\")\n",
    "    \n",
    "    # 获取所有 stock_***.csv 文件\n",
    "    csv_pattern = os.path.join(csv_dir, \"stock_daily_industry_*.csv\")\n",
    "    csv_files = glob.glob(csv_pattern)\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(\"❌ 未找到 stock_***.csv 文件\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"📊 找到 {len(csv_files)} 个 CSV 文件\")\n",
    "    \n",
    "    # 按文件名排序（确保按日期顺序处理）\n",
    "    csv_files.sort()\n",
    "    \n",
    "    # 读取并合并所有 CSV 文件\n",
    "    all_dataframes = []\n",
    "    total_records = 0\n",
    "    \n",
    "    for i, csv_file in enumerate(csv_files, 1):\n",
    "        filename = os.path.basename(csv_file)\n",
    "        print(f\"正在处理 ({i}/{len(csv_files)}): {filename}\")\n",
    "        \n",
    "        try:\n",
    "            # 读取 CSV 文件\n",
    "            df = pd.read_csv(csv_file)\n",
    "            \n",
    "            # 数据验证和清洗\n",
    "            # 确保 date 列是 datetime 类型\n",
    "            df['date'] = pd.to_datetime(df['date'])\n",
    "            \n",
    "            # 确保数值列的数据类型正确\n",
    "            numeric_columns = []\n",
    "            \n",
    "            for col in numeric_columns:\n",
    "                if col in df.columns:\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            \n",
    "            # 删除无效数据\n",
    "            df = df.dropna(subset=['date', 'stock_code'])\n",
    "            \n",
    "            all_dataframes.append(df)\n",
    "            total_records += len(df)\n",
    "            print(f\"  ✅ 成功读取 {len(df)} 条记录\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ❌ 处理失败: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not all_dataframes:\n",
    "        print(\"❌ 没有成功读取任何数据\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"\\n📊 合并所有数据...\")\n",
    "    # 合并所有数据框\n",
    "    combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "    \n",
    "    # 去重（按 date + stock_code）\n",
    "    combined_df = combined_df.drop_duplicates(subset=['date', 'stock_code'])\n",
    "    \n",
    "    # 按日期和股票代码排序\n",
    "    combined_df = combined_df.sort_values(['date', 'stock_code']).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"📈 总计 {len(combined_df)} 条记录（去重后）\")\n",
    "    \n",
    "    # 确保输出目录存在\n",
    "    output_dir = os.path.dirname(output_parquet_file)\n",
    "    if output_dir and not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\"📁 创建输出目录: {output_dir}\")\n",
    "    \n",
    "    # 转换为 pyarrow Table\n",
    "    table = pa.Table.from_pandas(combined_df)\n",
    "    \n",
    "    # 使用与目标文件相同的压缩方式 (snappy) 和格式写入 parquet\n",
    "    try:\n",
    "        pq.write_table(\n",
    "            table, \n",
    "            output_parquet_file,\n",
    "            compression='snappy',\n",
    "            version='2.6',  # 使用较新的 parquet 版本\n",
    "            use_dictionary=True,\n",
    "            write_batch_size=64 * 1024 * 1024  # 64MB batch size for better performance\n",
    "        )\n",
    "        \n",
    "        print(f\"✅ 成功保存到: {output_parquet_file}\")\n",
    "        print(f\"📊 文件大小: {os.path.getsize(output_parquet_file) / (1024*1024):.2f} MB\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 保存 parquet 文件失败: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数\"\"\"\n",
    "    # 设置路径\n",
    "    csv_directory = \"d:/workspace/xiaoyao/redis/\"\n",
    "    # 确保输出目录存在\n",
    "    output_dir = os.path.join(csv_directory, 'parquet')\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\"📁 创建输出目录: {output_dir}\")\n",
    "\n",
    "    output_file = os.path.join(output_dir, 'stock_daily_industry_to_merged.parquet')\n",
    "    \n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"🚀 开始合并 stock_***.csv 文件到 parquet\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 执行合并\n",
    "    success = merge_stock_csv_to_parquet(csv_directory, output_file)\n",
    "    \n",
    "    if success:\n",
    "        print(\"\\n🎉 合并完成！\")\n",
    "        \n",
    "        # 验证结果\n",
    "        try:\n",
    "            print(\"\\n📋 验证结果:\")\n",
    "            result_df = pd.read_parquet(output_file)\n",
    "            print(f\"   总行数: {len(result_df)}\")\n",
    "            print(f\"   日期范围: {result_df['date'].min()} 到 {result_df['date'].max()}\")\n",
    "            print(f\"   股票数量: {result_df['stock_code'].nunique()}\")\n",
    "            print(f\"   列名: {list(result_df.columns)}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️  验证失败: {e}\")\n",
    "    \n",
    "    else:\n",
    "        print(\"\\n❌ 合并失败！\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ab418c",
   "metadata": {},
   "source": [
    "## 将新生成的 stock_daily_auction_to_merged.parquet.parquet 与现有的 stock_daily_auction.parquet 合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a0e4253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "🚀 开始合并 parquet 文件\n",
      "============================================================\n",
      "📊 开始合并 parquet 文件...\n",
      "📖 读取现有文件: d:/workspace/xiaoyao/data/stock_daily_industry.parquet\n",
      "   现有数据行数: 2162114\n",
      "📖 读取新文件: D:/workspace/xiaoyao/redis/parquet/stock_daily_industry_to_merged.parquet\n",
      "   新数据行数: 1211865\n",
      "🔄 合并数据中...\n",
      "🧹 去重处理...\n",
      "📅 按日期排序...\n",
      "📈 合并后总行数: 3373979\n",
      "💾 保存合并结果: d:/workspace/xiaoyao/redis/parquet/stock_daily_industry.parquet\n",
      "✅ 合并完成！文件大小: 26.60 MB\n",
      "\n",
      "📋 验证结果:\n",
      "   最终行数: 3373979\n",
      "   日期范围: 2023-01-03 00:00:00 到 2025-09-25 00:00:00\n",
      "   股票数量: 5279\n",
      "\n",
      "🎉 合并成功！\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "将新生成的 stock_daily_auction_to_merged.parquet.parquet 与现有的 stock_daily_auction.parquet 合并\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import os\n",
    "\n",
    "\n",
    "def merge_parquet_files(existing_file, new_file, output_file):\n",
    "    \"\"\"\n",
    "    合并两个 parquet 文件\n",
    "    \n",
    "    Args:\n",
    "        existing_file: 现有的 parquet 文件路径\n",
    "        new_file: 新的 parquet 文件路径  \n",
    "        output_file: 输出的合并文件路径\n",
    "    \"\"\"\n",
    "    print(\"📊 开始合并 parquet 文件...\")\n",
    "    \n",
    "    try:\n",
    "        # 读取现有数据\n",
    "        print(f\"📖 读取现有文件: {existing_file}\")\n",
    "        existing_df = pd.read_parquet(existing_file)\n",
    "        print(f\"   现有数据行数: {len(existing_df)}\")\n",
    "        \n",
    "        # 读取新数据\n",
    "        print(f\"📖 读取新文件: {new_file}\")\n",
    "        new_df = pd.read_parquet(new_file)\n",
    "        print(f\"   新数据行数: {len(new_df)}\")\n",
    "        \n",
    "        # 合并数据\n",
    "        print(\"🔄 合并数据中...\")\n",
    "        combined_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
    "        \n",
    "        # 去重（按 date + stock_code）\n",
    "        print(\"🧹 去重处理...\")\n",
    "        combined_df = combined_df.drop_duplicates(subset=['date', 'stock_code'])\n",
    "        \n",
    "        # 排序\n",
    "        print(\"📅 按日期排序...\")\n",
    "        combined_df = combined_df.sort_values(['date', 'stock_code']).reset_index(drop=True)\n",
    "        \n",
    "        print(f\"📈 合并后总行数: {len(combined_df)}\")\n",
    "        \n",
    "        # 确保输出目录存在\n",
    "        output_dir = os.path.dirname(output_file)\n",
    "        if output_dir and not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        \n",
    "        # 转换为 pyarrow Table\n",
    "        table = pa.Table.from_pandas(combined_df)\n",
    "        \n",
    "        # 写入 parquet（使用与源文件相同的格式）\n",
    "        print(f\"💾 保存合并结果: {output_file}\")\n",
    "        pq.write_table(\n",
    "            table,\n",
    "            output_file,\n",
    "            compression='snappy',\n",
    "            version='2.6',\n",
    "            use_dictionary=True,\n",
    "            write_batch_size=64 * 1024 * 1024\n",
    "        )\n",
    "        \n",
    "        print(f\"✅ 合并完成！文件大小: {os.path.getsize(output_file) / (1024*1024):.2f} MB\")\n",
    "        \n",
    "        # 验证结果\n",
    "        print(\"\\n📋 验证结果:\")\n",
    "        result_df = pd.read_parquet(output_file)\n",
    "        print(f\"   最终行数: {len(result_df)}\")\n",
    "        print(f\"   日期范围: {result_df['date'].min()} 到 {result_df['date'].max()}\")\n",
    "        print(f\"   股票数量: {result_df['stock_code'].nunique()}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 合并失败: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数\"\"\"\n",
    "    # 设置文件路径\n",
    "\n",
    "    existing_file = r\"d:/workspace/xiaoyao/data/stock_daily_industry.parquet\"\n",
    "    new_file = r\"D:/workspace/xiaoyao/redis/parquet/stock_daily_industry_to_merged.parquet\"\n",
    "    output_file = r\"d:/workspace/xiaoyao/redis/parquet/stock_daily_industry.parquet\"\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(\"🚀 开始合并 parquet 文件\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 检查文件是否存在\n",
    "    if not os.path.exists(existing_file):\n",
    "        print(f\"❌ 现有文件不存在: {existing_file}\")\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(new_file):\n",
    "        print(f\"❌ 新文件不存在: {new_file}\")\n",
    "        return\n",
    "    \n",
    "    # 执行合并\n",
    "    success = merge_parquet_files(existing_file, new_file, output_file)\n",
    "    \n",
    "    if success:\n",
    "        print(\"\\n🎉 合并成功！\")\n",
    "    else:\n",
    "        print(\"\\n❌ 合并失败！\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8770ce2",
   "metadata": {},
   "source": [
    "## 删除已使用的csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10c223ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250102.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250103.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250106.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250107.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250108.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250109.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250110.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250113.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250114.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250115.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250116.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250117.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250120.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250121.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250122.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250123.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250124.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250127.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250205.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250206.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250207.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250210.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250211.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250212.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250213.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250214.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250217.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250218.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250219.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250220.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250221.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250224.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250225.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250226.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250227.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250228.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250303.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250304.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250305.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250306.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250307.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250310.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250311.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250312.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250313.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250314.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250317.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250318.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250319.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250320.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250321.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250324.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250325.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250326.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250327.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250328.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250331.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250401.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250402.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250403.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250407.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250408.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250409.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250410.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250411.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250414.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250415.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250416.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250417.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250418.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250421.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250422.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250423.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250424.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250425.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250428.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250429.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250430.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250506.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250507.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250508.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250509.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250512.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250513.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250514.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250515.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250516.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250519.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250520.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250521.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250522.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250523.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250526.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250527.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250528.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250529.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250530.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250603.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250604.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250605.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250606.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250609.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250610.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250611.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250612.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250613.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250616.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250617.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250618.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250619.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250620.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250623.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250624.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250625.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250626.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250627.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250630.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250701.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250702.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250703.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250704.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250707.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250708.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250709.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250710.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250711.csv\n",
      "已删除：D:\\workspace\\xiaoyao\\redis\\stock_daily_industry_20250714.csv\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "删除指定目录下的 stock_***.csv 文件\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def delete_stock_csv_files(target_directory, pattern=\"stock_*.csv\"):\n",
    "    #删除满足模式的所有文件\n",
    "    files = glob.glob(os.path.join(target_directory, pattern))\n",
    "    for file in files:\n",
    "        try:\n",
    "            os.remove(file)\n",
    "            print(f\"已删除：{file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"删除 {file} 失败：{e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    delete_stock_csv_files(r'D:\\workspace\\xiaoyao\\redis','stock_daily_industry_*.csv')\n",
    "    print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f46e4da",
   "metadata": {},
   "source": [
    "## 将新的parquet文件移动到data目录覆盖原文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2571397f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved: stock_daily_industry.parquet to D:\\workspace\\xiaoyao\\data\n",
      "Deleted: stock_daily_industry.parquet from D:\\workspace\\xiaoyao\\redis\\parquet\n"
     ]
    }
   ],
   "source": [
    "# 将子目录下的某个parquet文件移动到指定目录\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# 定义源目录和目标目录\n",
    "source_dir = \"D:\\\\workspace\\\\xiaoyao\\\\redis\\\\parquet\"\n",
    "target_dir = \"D:\\\\workspace\\\\xiaoyao\\\\data\"\n",
    "\n",
    "# 确保目标目录存在\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# 定义要移动的文件\n",
    "file_to_move = \"stock_daily_industry.parquet\"\n",
    "\n",
    "# 构建源文件的完整路径\n",
    "source_file_path = os.path.join(source_dir, file_to_move)\n",
    "\n",
    "# 构建目标文件的完整路径\n",
    "target_file_path = os.path.join(target_dir, file_to_move)\n",
    "\n",
    "# 检查源文件是否存在\n",
    "if os.path.exists(source_file_path):\n",
    "    # 移动文件\n",
    "    shutil.move(source_file_path, target_file_path)\n",
    "    print(f\"Moved: {file_to_move} to {target_dir}\")\n",
    "else:\n",
    "    print(f\"File not found: {file_to_move}\")\n",
    "\n",
    "# 删除指定的parquet文件\n",
    "file_to_delete = os.path.join(source_dir, 'stock_daily_industry_to_merged.parquet')\n",
    "if os.path.exists(file_to_delete):\n",
    "    os.remove(file_to_delete)\n",
    "    print(f\"Deleted: {file_to_move} from {source_dir}\")\n",
    "else:\n",
    "    print(f\"File not found: {file_to_move} in {source_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d277a27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xiaoyao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
