#!/usr/bin/env python3
"""
Parquetè½¬SQLiteç®€åŒ–æ¼”ç¤º
åŠŸèƒ½ï¼šå°†å•ä¸ªParquetæ–‡ä»¶è½¬æ¢ä¸ºSQLiteæ•°æ®åº“ï¼Œæ”¯æŒæŒ‡å®šç´¢å¼•åˆ—
"""

import pandas as pd
import sqlite3
from pathlib import Path
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def parquet_to_sqlite(input_file, output_file, index_columns=None):
    """
    å°†Parquetæ–‡ä»¶è½¬æ¢ä¸ºSQLiteæ•°æ®åº“
    
    Args:
        input_file: è¾“å…¥Parquetæ–‡ä»¶è·¯å¾„
        output_file: è¾“å‡ºSQLiteæ–‡ä»¶è·¯å¾„
        index_columns: éœ€è¦åˆ›å»ºç´¢å¼•çš„åˆ—ååˆ—è¡¨ï¼Œé»˜è®¤ä¸ºNone
    
    Returns:
        bool: è½¬æ¢æ˜¯å¦æˆåŠŸ
    """
    try:
        # è¯»å–Parquetæ–‡ä»¶
        logger.info(f"æ­£åœ¨è¯»å–Parquetæ–‡ä»¶: {input_file}")
        df = pd.read_parquet(input_file)
        logger.info(f"æ•°æ®è¯»å–å®Œæˆï¼Œå…±{len(df)}æ¡è®°å½•ï¼Œ{len(df.columns)}ä¸ªå­—æ®µ")
        
        # åˆ›å»ºSQLiteæ•°æ®åº“
        logger.info(f"æ­£åœ¨åˆ›å»ºSQLiteæ•°æ®åº“: {output_file}")
        conn = sqlite3.connect(output_file)
        
        # å†™å…¥æ•°æ®è¡¨ï¼ˆè¡¨åå›ºå®šä¸º'data'ï¼‰
        table_name = 'data'
        logger.info(f"æ­£åœ¨å†™å…¥æ•°æ®è¡¨: {table_name}")
        df.to_sql(table_name, conn, if_exists='replace', index=False)
        
        # åˆ›å»ºç´¢å¼•
        if index_columns:
            logger.info(f"æ­£åœ¨åˆ›å»ºç´¢å¼•ï¼Œåˆ—: {index_columns}")
            for col in index_columns:
                if col in df.columns:
                    try:
                        index_name = f"idx_{table_name}_{col}"
                        conn.execute(f"CREATE INDEX IF NOT EXISTS {index_name} ON {table_name} ({col})")
                        logger.info(f"æˆåŠŸåˆ›å»ºç´¢å¼•: {index_name}")
                    except Exception as e:
                        logger.warning(f"åˆ›å»ºç´¢å¼• {col} å¤±è´¥: {e}")
                else:
                    logger.warning(f"åˆ— {col} ä¸å­˜åœ¨ï¼Œè·³è¿‡ç´¢å¼•åˆ›å»º")
        
        # è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯
        cursor = conn.cursor()
        cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
        count = cursor.fetchone()[0]
        cursor.execute(f"PRAGMA table_info({table_name})")
        columns = [row[1] for row in cursor.fetchall()]
        
        logger.info(f"è½¬æ¢å®Œæˆ!")
        logger.info(f"  è®°å½•æ•°: {count:,}")
        logger.info(f"  å­—æ®µæ•°: {len(columns)}")
        logger.info(f"  å­—æ®µåˆ—è¡¨: {columns}")
        
        conn.close()
        return True
        
    except Exception as e:
        logger.error(f"è½¬æ¢å¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•°ï¼šæµ‹è¯•è½¬æ¢åŠŸèƒ½"""
    
    # è®¾ç½®è¾“å…¥è¾“å‡ºæ–‡ä»¶
    input_file = "../data/stock_daily_price.parquet"  # è¾“å…¥Parquetæ–‡ä»¶
    output_file = "../data/stock_daily_price_demo.db"  # è¾“å‡ºSQLiteæ–‡ä»¶
    
    # è®¾ç½®ç´¢å¼•åˆ—
    index_columns = ["date", "stock_code"]  # éœ€è¦åˆ›å»ºç´¢å¼•çš„åˆ—
    
    logger.info("=" * 50)
    logger.info("Parquetè½¬SQLiteè½¬æ¢æµ‹è¯•")
    logger.info("=" * 50)
    logger.info(f"è¾“å…¥æ–‡ä»¶: {input_file}")
    logger.info(f"è¾“å‡ºæ–‡ä»¶: {output_file}")
    logger.info(f"ç´¢å¼•åˆ—: {index_columns}")
    logger.info("-" * 50)
    
    # æ‰§è¡Œè½¬æ¢
    success = parquet_to_sqlite(input_file, output_file, index_columns)
    
    if success:
        logger.info("âœ… è½¬æ¢æˆåŠŸ!")
        
        # éªŒè¯è½¬æ¢ç»“æœ
        try:
            conn = sqlite3.connect(output_file)
            cursor = conn.cursor()
            
            # æŸ¥è¯¢è®°å½•æ•°
            cursor.execute("SELECT COUNT(*) FROM data")
            count = cursor.fetchone()[0]
            
            # æŸ¥è¯¢å‰5æ¡æ•°æ®
            cursor.execute("SELECT * FROM data LIMIT 5")
            sample_data = cursor.fetchall()
            
            # è·å–å­—æ®µå
            cursor.execute("PRAGMA table_info(data)")
            columns = [row[1] for row in cursor.fetchall()]
            
            logger.info("\nğŸ“Š è½¬æ¢ç»“æœéªŒè¯:")
            logger.info(f"  æ€»è®°å½•æ•°: {count:,}")
            logger.info(f"  å­—æ®µåˆ—è¡¨: {columns}")
            logger.info(f"  å‰5æ¡æ•°æ®:")
            for i, row in enumerate(sample_data, 1):
                logger.info(f"    {i}: {dict(zip(columns, row))}")
            
            conn.close()
            
        except Exception as e:
            logger.error(f"éªŒè¯å¤±è´¥: {e}")
    else:
        logger.error("âŒ è½¬æ¢å¤±è´¥!")


if __name__ == "__main__":
    main()