{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0097795b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "login success!\n",
      "logout success!\n",
      "成功获取 sh.600812 数据：7694 条（1994-01-14 至 2025-09-08）\n",
      "保存至：./stock_data\\sh.600812.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import baostock as bs\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class BaostockDataHandler:\n",
    "    \"\"\"修复索引越界问题的Baostock数据处理工具\"\"\"\n",
    "    \n",
    "    def fetch_ohlcv(self, stock_code: str, start_date: str = None, end_date: str = None) -> pd.DataFrame:\n",
    "        \"\"\"获取OHLCV数据，动态查找上市日期字段索引\"\"\"\n",
    "        bs.login()\n",
    "        \n",
    "        # 处理结束日期\n",
    "        today = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        end_date = end_date or today\n",
    "        \n",
    "        # 动态获取上市日期（核心修复点）\n",
    "        if not start_date:\n",
    "            rs_basic = bs.query_stock_basic(code=stock_code)\n",
    "            if rs_basic.error_code != \"0\":\n",
    "                raise Exception(f\"获取基本信息失败: {rs_basic.error_msg}\")\n",
    "            \n",
    "            # 获取字段列表，动态查找\"ipoDate\"索引（避免固定索引7导致越界）\n",
    "            fields = rs_basic.fields\n",
    "            if \"ipoDate\" not in fields:\n",
    "                # 找不到上市日期字段时，使用默认起始日期\n",
    "                start_date = \"2000-01-01\"\n",
    "            else:\n",
    "                rs_basic.next()\n",
    "                ipo_date_index = fields.index(\"ipoDate\")\n",
    "                start_date = rs_basic.get_row_data()[ipo_date_index]\n",
    "                # 容错处理\n",
    "                if start_date in [\"\", \"0000-00-00\"]:\n",
    "                    start_date = \"2000-01-01\"\n",
    "        \n",
    "        # 获取K线数据\n",
    "        rs_kline = bs.query_history_k_data_plus(\n",
    "            code=stock_code,\n",
    "            fields=\"date,open,high,low,close,volume\",\n",
    "            start_date=start_date,\n",
    "            end_date=end_date,\n",
    "            frequency=\"d\",\n",
    "            adjustflag=\"1\"\n",
    "        )\n",
    "        \n",
    "        data_list = []\n",
    "        while (rs_kline.error_code == \"0\") and rs_kline.next():\n",
    "            data_list.append(rs_kline.get_row_data())\n",
    "        \n",
    "        bs.logout()\n",
    "        \n",
    "        if not data_list:\n",
    "            raise ValueError(f\"未获取到 {stock_code} 的数据\")\n",
    "        \n",
    "        # 处理数据格式\n",
    "        df = pd.DataFrame(\n",
    "            data_list,\n",
    "            columns=[\"date\", \"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "        )\n",
    "        numeric_cols = [\"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "        df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "        df = df.dropna().reset_index(drop=True)\n",
    "        \n",
    "        print(f\"成功获取 {stock_code} 数据：{len(df)} 条（{start_date} 至 {end_date}）\")\n",
    "        return df\n",
    "    \n",
    "    def save_to_csv(self, df: pd.DataFrame, stock_code: str, save_dir: str = \"./stock_data\") -> str:\n",
    "        \"\"\"保存数据到CSV\"\"\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        csv_path = os.path.join(save_dir, f\"{stock_code}.csv\")\n",
    "        df[[\"date\", \"open\", \"high\", \"low\", \"close\", \"volume\"]].to_csv(csv_path, index=False)\n",
    "        print(f\"保存至：{csv_path}\")\n",
    "        return csv_path\n",
    "\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    handler = BaostockDataHandler()\n",
    "    try:\n",
    "        # 尝试获取恒生电子数据\n",
    "        stock_code = \"sh.600812\"\n",
    "        df = handler.fetch_ohlcv(stock_code)\n",
    "        handler.save_to_csv(df, stock_code)\n",
    "    except Exception as e:\n",
    "        print(f\"处理失败：{str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4bcfd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-08 22:40:17.813 | INFO     | __main__:_get_all_date:307 - start get all date......\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      " 50%|█████     | 1/2 [00:02<00:02,  2.69s/it]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.50s/it]\n",
      "2025-09-08 22:40:20.813 | INFO     | __main__:_get_all_date:326 - end of get all date.\n",
      "\n",
      "2025-09-08 22:40:20.814 | INFO     | __main__:_dump_calendars:329 - start dump calendars......\n",
      "2025-09-08 22:40:20.996 | INFO     | __main__:_dump_calendars:332 - end of calendars dump.\n",
      "\n",
      "2025-09-08 22:40:20.996 | INFO     | __main__:_dump_instruments:335 - start dump instruments......\n",
      "2025-09-08 22:40:21.000 | INFO     | __main__:_dump_instruments:337 - end of instruments dump.\n",
      "\n",
      "2025-09-08 22:40:21.000 | INFO     | __main__:_dump_features:340 - start dump features......\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      " 50%|█████     | 1/2 [00:02<00:02,  2.21s/it]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.24s/it]\n",
      "2025-09-08 22:40:23.479 | INFO     | __main__:_dump_features:347 - end of features dump.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 在conda环境下运行 \n",
    "!python ../qlib/scripts/dump_bin.py dump_all --data_path D:/workspace/xiaoyao/qlibusing/stock_data --qlib_dir D:/workspace/xiaoyao/qlib_data --include_fields open,close,high,low,volume --date_field_name \"date\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b3efcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class DataIntegrityChecker:\n",
    "    \"\"\"数据完整性检查和自动更新工具\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir: str = \"./stock_data\"):\n",
    "        self.data_dir = data_dir\n",
    "        self.handler = BaostockDataHandler()\n",
    "    \n",
    "    def get_csv_files(self) -> list:\n",
    "        \"\"\"获取stock_data目录下所有CSV文件\"\"\"\n",
    "        pattern = os.path.join(self.data_dir, \"*.csv\")\n",
    "        return glob.glob(pattern)\n",
    "    \n",
    "    def extract_stock_code(self, csv_path: str) -> str:\n",
    "        \"\"\"从CSV文件路径提取股票代码\"\"\"\n",
    "        filename = os.path.basename(csv_path)\n",
    "        return filename.replace('.csv', '')\n",
    "    \n",
    "    def get_last_date(self, csv_path: str) -> str:\n",
    "        \"\"\"获取CSV文件中的最后日期\"\"\"\n",
    "        try:\n",
    "            df = pd.read_csv(csv_path)\n",
    "            if df.empty or 'date' not in df.columns:\n",
    "                return None\n",
    "            # 确保日期列是datetime格式\n",
    "            df['date'] = pd.to_datetime(df['date'])\n",
    "            last_date = df['date'].max()\n",
    "            return last_date.strftime('%Y-%m-%d')\n",
    "        except Exception as e:\n",
    "            print(f\"读取文件 {csv_path} 失败: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def is_data_missing(self, last_date: str) -> bool:\n",
    "        \"\"\"检查数据是否缺失（最后日期到今天之间是否有工作日）\"\"\"\n",
    "        if not last_date:\n",
    "            return True\n",
    "        \n",
    "        try:\n",
    "            last_dt = datetime.strptime(last_date, '%Y-%m-%d')\n",
    "            today = datetime.now()\n",
    "            \n",
    "            # 如果最后日期是今天或未来，则不缺失\n",
    "            if last_dt.date() >= today.date():\n",
    "                return False\n",
    "            \n",
    "            # 检查是否有工作日缺失（简单检查：超过3天就认为可能缺失）\n",
    "            days_diff = (today - last_dt).days\n",
    "            return days_diff > 3\n",
    "        except Exception as e:\n",
    "            print(f\"日期检查失败: {e}\")\n",
    "            return True\n",
    "    \n",
    "    def update_stock_data(self, stock_code: str, start_date: str) -> bool:\n",
    "        \"\"\"更新股票数据\"\"\"\n",
    "        try:\n",
    "            print(f\"正在更新 {stock_code} 从 {start_date} 开始的数据...\")\n",
    "            \n",
    "            # 获取新数据\n",
    "            new_df = self.handler.fetch_ohlcv(stock_code, start_date)\n",
    "            \n",
    "            # 读取现有数据\n",
    "            csv_path = os.path.join(self.data_dir, f\"{stock_code}.csv\")\n",
    "            if os.path.exists(csv_path):\n",
    "                existing_df = pd.read_csv(csv_path)\n",
    "                existing_df['date'] = pd.to_datetime(existing_df['date'])\n",
    "                new_df['date'] = pd.to_datetime(new_df['date'])\n",
    "                \n",
    "                # 合并数据，去重\n",
    "                combined_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
    "                combined_df = combined_df.drop_duplicates(subset=['date'], keep='last')\n",
    "                combined_df = combined_df.sort_values('date').reset_index(drop=True)\n",
    "                \n",
    "                # 转换日期格式回字符串\n",
    "                combined_df['date'] = combined_df['date'].dt.strftime('%Y-%m-%d')\n",
    "                \n",
    "                # 保存合并后的数据\n",
    "                combined_df.to_csv(csv_path, index=False)\n",
    "                print(f\"更新完成，合并后共 {len(combined_df)} 条记录\")\n",
    "            else:\n",
    "                # 如果文件不存在，直接保存\n",
    "                self.handler.save_to_csv(new_df, stock_code, self.data_dir)\n",
    "            \n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"更新 {stock_code} 数据失败: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def check_and_update_all(self) -> dict:\n",
    "        \"\"\"检查所有CSV文件并更新缺失数据\"\"\"\n",
    "        results = {\n",
    "            'checked': 0,\n",
    "            'missing': 0,\n",
    "            'updated': 0,\n",
    "            'failed': 0,\n",
    "            'details': []\n",
    "        }\n",
    "        \n",
    "        csv_files = self.get_csv_files()\n",
    "        \n",
    "        if not csv_files:\n",
    "            print(f\"在 {self.data_dir} 目录下未找到CSV文件\")\n",
    "            return results\n",
    "        \n",
    "        print(f\"找到 {len(csv_files)} 个CSV文件，开始检查数据完整性...\")\n",
    "        \n",
    "        for csv_path in csv_files:\n",
    "            stock_code = self.extract_stock_code(csv_path)\n",
    "            last_date = self.get_last_date(csv_path)\n",
    "            \n",
    "            results['checked'] += 1\n",
    "            \n",
    "            if self.is_data_missing(last_date):\n",
    "                results['missing'] += 1\n",
    "                print(f\"检测到 {stock_code} 数据缺失，最后日期: {last_date}\")\n",
    "                \n",
    "                # 计算更新起始日期\n",
    "                if last_date:\n",
    "                    start_date = (datetime.strptime(last_date, '%Y-%m-%d') + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "                else:\n",
    "                    start_date = None  # 让fetch_ohlcv自动获取上市日期\n",
    "                \n",
    "                # 尝试更新数据\n",
    "                if self.update_stock_data(stock_code, start_date):\n",
    "                    results['updated'] += 1\n",
    "                    results['details'].append(f\"{stock_code}: 更新成功\")\n",
    "                else:\n",
    "                    results['failed'] += 1\n",
    "                    results['details'].append(f\"{stock_code}: 更新失败\")\n",
    "            else:\n",
    "                print(f\"{stock_code} 数据完整，最后日期: {last_date}\")\n",
    "                results['details'].append(f\"{stock_code}: 数据完整\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def print_summary(self, results: dict):\n",
    "        \"\"\"打印检查结果摘要\"\"\"\n",
    "        print(\"\\n=== 数据完整性检查结果 ===")\n",
    "        print(f\"检查文件数: {results['checked']}\")\n",
    "        print(f\"发现缺失: {results['missing']}\")\n",
    "        print(f\"更新成功: {results['updated']}\")\n",
    "        print(f\"更新失败: {results['failed']}\")\n",
    "        print(\"\\n详细结果:\")\n",
    "        for detail in results['details']:\n",
    "            print(f\"  - {detail}\")\n",
    "\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    checker = DataIntegrityChecker()\n",
    "    results = checker.check_and_update_all()\n",
    "    checker.print_summary(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data_integrity_demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 演示数据完整性检查和更新功能\n",
    "\n",
    "# 1. 创建数据完整性检查器\n",
    "checker = DataIntegrityChecker(data_dir='./stock_data')\n",
    "\n",
    "# 2. 检查并更新所有CSV文件的数据\n",
    "print('开始检查数据完整性...')\n",
    "results = checker.check_and_update_all()\n",
    "\n",
    "# 3. 显示检查结果摘要\n",
    "checker.print_summary(results)\n",
    "\n",
    "# 4. 如果需要手动检查特定股票\n",
    "# stock_code = 'sh.600812'\n",
    "# csv_path = f'./stock_data/{stock_code}.csv'\n",
    "# if os.path.exists(csv_path):\n",
    "#     last_date = checker.get_last_date(csv_path)\n",
    "#     print(f'{stock_code} 最后日期: {last_date}')\n",
    "#     if checker.is_data_missing(last_date):\n",
    "#         print('数据需要更新')\n",
    "#         start_date = (datetime.strptime(last_date, '%Y-%m-%d') + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "#         checker.update_stock_data(stock_code, start_date)\n",
    "#     else:\n",
    "#         print('数据完整')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xiaoyao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
