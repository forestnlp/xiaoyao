# ä»Jupyter Notebookè½¬æ¢è€Œæ¥çš„Pythonä»£ç 
# åŸå§‹æ–‡ä»¶ï¼šD:\workspace\xiaoyao\works\trytry\å…»å®¶å¿ƒæ³•\å›æµ‹.ipynb



# ----------------------------------------------------------------------import pandas as pd
import numpy as np
import os
from datetime import datetime

# --------------------------
# 1. é…ç½®å‚æ•°ï¼ˆä¸å˜ï¼‰
# --------------------------
CONFIG = {
    "selection_input_path": r'./yangjia_selection_result.csv',
    "widetable_input_path": r'D:\workspace\xiaoyao\data\widetable.parquet',
    "backtest_detail_path": r'./yangjia_backtest_detail.csv',
    "fund_growth_path": r'./yangjia_fund_growth.csv',
    "backtest_summary_path": r'./yangjia_backtest_summary.txt',
    "log_path": r'./yangjia_backtest_log.txt',
    "trade_rules": {
        "buy_delay": 1,        # Tæ—¥é€‰è‚¡â†’T+1ä¹°å…¥
        "sell_delay": 5,       # T+1ä¹°å…¥â†’T+5å–å‡º
        "stop_loss_ratio": 0.05,
        "stop_profit_ratio": 0.15,
        "initial_position": 0.5,
        "add_position_threshold": 0.03
    },
    "initial_fund": 100000  # åˆå§‹èµ„é‡‘ï¼ˆæ•´æ•°ï¼Œåç»­è½¬ä¸ºæµ®ç‚¹æ•°ï¼‰
}

# --------------------------
# 2. å·¥å…·å‡½æ•°ï¼ˆä¸å˜ï¼‰
# --------------------------
def init_log():
    with open(CONFIG["log_path"], 'w', encoding='utf-8') as f:
        f.write(f"ã€å…»å®¶å¿ƒæ³•å›æµ‹å¯åŠ¨ã€‘{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

def log_msg(msg):
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    log_line = f"[{timestamp}] {msg}"
    print(log_line)
    with open(CONFIG["log_path"], 'a', encoding='utf-8') as f:
        f.write(log_line + "\n")

# --------------------------
# 3. åŠ è½½å›æµ‹æ•°æ®ï¼ˆä¸å˜ï¼Œå·²ç»Ÿä¸€æ—¥æœŸç±»å‹ï¼‰
# --------------------------
def load_backtest_data():
    log_msg("å¼€å§‹åŠ è½½å›æµ‹æ•°æ®ï¼ˆé€‰è‚¡ç»“æœ+åŸå§‹å®½è¡¨ï¼‰...")
    
    # åŠ è½½é€‰è‚¡ç»“æœï¼ˆç»Ÿä¸€t_dateä¸ºdatetimeï¼‰
    selection_df = pd.read_csv(CONFIG["selection_input_path"])
    selection_df["date"] = pd.to_datetime(selection_df["date"])
    selection_df["t_date"] = pd.to_datetime(selection_df["selection_date"])  # è½¬ä¸ºdatetime
    selection_df = selection_df.drop(columns=["selection_date"])
    log_msg(f"âœ… é€‰è‚¡ç»“æœåŠ è½½ï¼š{len(selection_df)}æ¡è®°å½•ï¼Œ{selection_df['t_date'].nunique()}ä¸ªé€‰è‚¡æ—¥")
    
    # åŠ è½½å®½è¡¨ä»·æ ¼æ•°æ®
    price_cols = ['date', 'stock_code', 'open', 'close', 'paused']
    widetable_df = pd.read_parquet(CONFIG["widetable_input_path"], columns=price_cols)
    widetable_df["date"] = pd.to_datetime(widetable_df["date"])
    widetable_df = widetable_df.sort_values(by=["stock_code", "date"]).reset_index(drop=True)
    widetable_df["trade_seq"] = widetable_df.groupby("stock_code").cumcount()
    log_msg(f"âœ… å®½è¡¨ä»·æ ¼æ•°æ®åŠ è½½ï¼š{len(widetable_df)}æ¡è®°å½•ï¼Œ{widetable_df['stock_code'].nunique()}åªè‚¡ç¥¨")
    
    # åˆå¹¶é€‰è‚¡ç»“æœä¸äº¤æ˜“åºåˆ—
    selection_df = pd.merge(
        selection_df,
        widetable_df[["stock_code", "date", "trade_seq"]].rename(columns={"date": "t_date"}),
        on=["stock_code", "t_date"],
        how="left"
    ).dropna(subset=["trade_seq"])
    selection_df["trade_seq"] = selection_df["trade_seq"].astype(int)
    
    log_msg(f"âœ… æ•°æ®åˆå¹¶å®Œæˆï¼š{len(selection_df)}æ¡æœ‰æ•ˆé€‰è‚¡è®°å½•")
    return selection_df, widetable_df

# --------------------------
# 4. æ ¸å¿ƒå›æµ‹é€»è¾‘ï¼ˆä¸å˜ï¼‰
# --------------------------
def run_backtest(selection_df, widetable_df):
    log_msg("å¼€å§‹æ‰§è¡Œå…»å®¶å¿ƒæ³•å›æµ‹...")
    rules = CONFIG["trade_rules"]
    
    price_seq_map = widetable_df.set_index(["stock_code", "trade_seq"])[["open", "close", "paused", "date"]].to_dict('index')
    
    def calc_trade_info(row):
        stock_code = row["stock_code"]
        t_seq = row["trade_seq"]
        
        buy_seq = t_seq + rules["buy_delay"]
        sell_seq = buy_seq + rules["sell_delay"]
        
        buy_data = price_seq_map.get((stock_code, buy_seq), {})
        buy_price = buy_data.get("open", np.nan)
        buy_date = buy_data.get("date", np.nan)
        is_buy_paused = buy_data.get("paused", 1.0)
        
        sell_data = price_seq_map.get((stock_code, sell_seq), {})
        sell_price = sell_data.get("close", np.nan)
        sell_date = sell_data.get("date", np.nan)
        is_sell_paused = sell_data.get("paused", 1.0)
        
        if pd.isna(buy_price) or pd.isna(sell_price) or is_buy_paused == 1.0 or is_sell_paused == 1.0:
            return pd.Series({
                "buy_date": np.nan, "sell_date": np.nan,
                "buy_price": np.nan, "sell_price": np.nan,
                "return_rate": np.nan, "position": np.nan,
                "contribution_return": np.nan, "is_valid": False
            })
        
        return_rate = (sell_price - buy_price) / buy_price * 100
        position = rules["initial_position"]
        if return_rate >= 3:
            position = 1.0
        contribution_return = return_rate * position
        
        return pd.Series({
            "buy_date": buy_date, "sell_date": sell_date,
            "buy_price": buy_price, "sell_price": sell_price,
            "return_rate": return_rate, "position": position,
            "contribution_return": contribution_return, "is_valid": True
        })
    
    # æ‰§è¡Œè®¡ç®—å¹¶è¿”å›å®Œæ•´backtest_dfï¼ˆåŒ…å«æœ‰æ•ˆ+æ— æ•ˆäº¤æ˜“ï¼‰
    trade_info = selection_df.apply(calc_trade_info, axis=1)
    backtest_df = pd.concat([selection_df, trade_info], axis=1)
    valid_backtest_df = backtest_df[backtest_df["is_valid"]].copy()
    invalid_count = len(backtest_df) - len(valid_backtest_df)
    
    log_msg(f"âœ… äº¤æ˜“è®¡ç®—å®Œæˆï¼šæœ‰æ•ˆäº¤æ˜“{len(valid_backtest_df)}æ¡ï¼Œæ— æ•ˆäº¤æ˜“{invalid_count}æ¡")
    
    # æ­¢æŸæ­¢ç›ˆä¿®æ­£
    def apply_stop_rule(row):
        return_rate = row["return_rate"]
        if return_rate <= -rules["stop_loss_ratio"] * 100:
            return -rules["stop_loss_ratio"] * 100
        elif return_rate >= rules["stop_profit_ratio"] * 100:
            return rules["stop_profit_ratio"] * 100
        else:
            return return_rate
    
    valid_backtest_df["adjusted_return"] = valid_backtest_df.apply(apply_stop_rule, axis=1)
    valid_backtest_df["adjusted_contribution"] = valid_backtest_df["adjusted_return"] * valid_backtest_df["position"]
    
    return backtest_df, valid_backtest_df  # åŒæ—¶è¿”å›å®Œæ•´backtest_dfå’Œæœ‰æ•ˆäº¤æ˜“df

# --------------------------
# 5. èµ„é‡‘å¢é•¿è®¡ç®—ï¼ˆä¿®å¤dtypeè­¦å‘Šï¼‰
# --------------------------
def calculate_fund_growth(valid_backtest_df):
    log_msg("å¼€å§‹è®¡ç®—èµ„é‡‘å¢é•¿ï¼ˆæŒ‰æ—¥å¹³å‡æ”¶ç›Šè¿ä¹˜ï¼‰...")
    
    daily_return = valid_backtest_df.groupby("sell_date").agg({
        "adjusted_contribution": ["mean", "count"],
        "stock_code": "nunique"
    }).reset_index()
    daily_return.columns = ["sell_date", "daily_avg_return", "daily_trade_count", "daily_stock_count"]
    daily_return = daily_return[daily_return["daily_trade_count"] >= 2].sort_values("sell_date")
    
    # ä¿®å¤dtypeè­¦å‘Šï¼šåˆå§‹åŒ–ä¸ºæµ®ç‚¹æ•°
    daily_return["cumulative_fund"] = float(CONFIG["initial_fund"])  # ç›´æ¥ç”¨æµ®ç‚¹æ•°åˆå§‹åŒ–
    daily_return["daily_growth_rate"] = 1 + 0.5 * (daily_return["daily_avg_return"] / 100)
    
    # è®¡ç®—ç´¯è®¡èµ„é‡‘ï¼ˆä¿æŒæµ®ç‚¹æ•°ç±»å‹ï¼‰
    for i in range(len(daily_return)):
        if i == 0:
            daily_return.iloc[i, daily_return.columns.get_loc("cumulative_fund")] = float(CONFIG["initial_fund"]) * daily_return.iloc[i]["daily_growth_rate"]
        else:
            daily_return.iloc[i, daily_return.columns.get_loc("cumulative_fund")] = daily_return.iloc[i-1]["cumulative_fund"] * daily_return.iloc[i]["daily_growth_rate"]
    
    # æ ¼å¼åŒ–æ•°å€¼ï¼ˆä¿æŒæµ®ç‚¹æ•°ï¼‰
    daily_return["daily_avg_return"] = np.round(daily_return["daily_avg_return"], 2)
    daily_return["daily_growth_rate"] = np.round(daily_return["daily_growth_rate"], 4)
    daily_return["cumulative_fund"] = np.round(daily_return["cumulative_fund"], 2)
    
    log_msg(f"âœ… èµ„é‡‘å¢é•¿è®¡ç®—å®Œæˆï¼š{len(daily_return)}ä¸ªæœ‰æ•ˆæ”¶ç›Šæ—¥")
    return daily_return

# --------------------------
# 6. å›æµ‹ç»“æœç»Ÿè®¡ä¸ä¿å­˜ï¼ˆä¿®å¤backtest_dfä¼ é€’ï¼‰
# --------------------------
def summarize_and_save(backtest_df, valid_backtest_df, daily_return):
    log_msg("å¼€å§‹ç”Ÿæˆå›æµ‹æ±‡æ€»æŠ¥å‘Š...")
    
    total_trades = len(valid_backtest_df)
    total_selection = len(backtest_df)  # ç”¨å®Œæ•´backtest_dfè·å–æ€»é€‰è‚¡è®°å½•æ•°
    total_return_rate = (daily_return["cumulative_fund"].iloc[-1] / CONFIG["initial_fund"] - 1) * 100 if len(daily_return) > 0 else 0
    trading_days = len(daily_return)
    annual_return = total_return_rate / (trading_days / 250) if trading_days > 0 else 0
    positive_days = len(daily_return[daily_return["daily_avg_return"] > 0])
    positive_day_ratio = positive_days / trading_days * 100 if trading_days > 0 else 0
    max_drawdown = 0
    
    # è®¡ç®—æœ€å¤§å›æ’¤
    if len(daily_return) > 0:
        cumulative_fund = daily_return["cumulative_fund"].values
        peak = np.maximum.accumulate(cumulative_fund)
        drawdown = (cumulative_fund - peak) / peak * 100
        max_drawdown = np.min(drawdown)
    
    # å¼ºåŠ¿æ¿å—ç»Ÿè®¡
    industry_return = valid_backtest_df.groupby("sw_l1_industry_name").agg({
        "adjusted_return": ["mean", "count", lambda x: np.round((x>0).mean()*100, 2)],
        "stock_code": "nunique"
    }).reset_index()
    industry_return.columns = ["industry", "avg_return(%)", "trade_count", "positive_ratio(%)", "stock_count"]
    industry_return = industry_return.sort_values("avg_return(%)", ascending=False).head(10)
    
    # ä¿å­˜ç»“æœ
    valid_backtest_df.to_csv(CONFIG["backtest_detail_path"], index=False, encoding='utf-8-sig')
    daily_return.to_csv(CONFIG["fund_growth_path"], index=False, encoding='utf-8-sig')
    
    # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Šï¼ˆä½¿ç”¨backtest_dfè®¡ç®—æ€»é€‰è‚¡è®°å½•ï¼‰
    summary_content = f"""
ã€å…»å®¶å¿ƒæ³•å›æµ‹æ±‡æ€»æŠ¥å‘Šã€‘
==========================
å›æµ‹è§„åˆ™ï¼šTæ—¥é€‰è‚¡â†’T+{CONFIG['trade_rules']['buy_delay']}ä¹°å…¥â†’T+{CONFIG['trade_rules']['sell_delay']}å–å‡º
         åˆå§‹åŠä»“ï¼Œç›ˆåˆ©â‰¥3%åŠ ä»“è‡³æ»¡ä»“ï¼›æ­¢æŸ5%ï¼Œæ­¢ç›ˆ15%
==========================
1. åŸºç¡€äº¤æ˜“ç»Ÿè®¡
   - æ€»é€‰è‚¡è®°å½•ï¼š{total_selection}æ¡
   - æœ‰æ•ˆäº¤æ˜“è®°å½•ï¼š{total_trades}æ¡
   - æ— æ•ˆäº¤æ˜“è®°å½•ï¼š{total_selection - total_trades}æ¡
   - æœ‰æ•ˆäº¤æ˜“å¤©æ•°ï¼š{trading_days}å¤©
   - å¹³å‡æ¯æ—¥äº¤æ˜“ï¼š{total_trades/trading_days:.1f}åªï¼ˆè‹¥trading_days>0ï¼‰

2. æ”¶ç›Šè¡¨ç°
   - åˆå§‹èµ„é‡‘ï¼š{CONFIG['initial_fund']:.2f}å…ƒ
   - æœ€ç»ˆèµ„é‡‘ï¼š{daily_return['cumulative_fund'].iloc[-1]:.2f}å…ƒï¼ˆè‹¥trading_days>0ï¼‰
   - ç´¯è®¡æ”¶ç›Šç‡ï¼š{total_return_rate:.2f}%
   - å¹´åŒ–æ”¶ç›Šç‡ï¼š{annual_return:.2f}%ï¼ˆæŒ‰250ä¸ªäº¤æ˜“æ—¥/å¹´ï¼‰
   - æ­£æ”¶ç›Šæ—¥å æ¯”ï¼š{positive_day_ratio:.2f}%ï¼ˆ{positive_days}/{trading_days}ï¼‰
   - æœ€å¤§å›æ’¤ï¼š{max_drawdown:.2f}%

3. é£é™©æ§åˆ¶
   - æ­¢æŸè§¦å‘æ¬¡æ•°ï¼š{len(valid_backtest_df[valid_backtest_df['adjusted_return'] <= -5])}æ¬¡
   - æ­¢ç›ˆè§¦å‘æ¬¡æ•°ï¼š{len(valid_backtest_df[valid_backtest_df['adjusted_return'] >= 15])}æ¬¡
   - å¹³å‡å•ç¥¨æ”¶ç›Šï¼š{valid_backtest_df['adjusted_return'].mean():.2f}%
   - æ”¶ç›Šæ ‡å‡†å·®ï¼š{valid_backtest_df['adjusted_return'].std():.2f}%

4. å¼ºåŠ¿æ¿å—TOP10
{industry_return.to_string(index=False, float_format=lambda x: f"{x:.2f}")}
==========================
å›æµ‹å®Œæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
    with open(CONFIG["backtest_summary_path"], 'w', encoding='utf-8') as f:
        f.write(summary_content)
    
    # æ‰“å°æ ¸å¿ƒç»“æœ
    print("\n" + "="*60)
    print("ğŸ‰ å…»å®¶å¿ƒæ³•å›æµ‹æ ¸å¿ƒç»“æœ")
    print("="*60)
    print(f"ğŸ“Š ç´¯è®¡æ”¶ç›Šç‡ï¼š{total_return_rate:.2f}% | å¹´åŒ–æ”¶ç›Šç‡ï¼š{annual_return:.2f}%")
    print(f"ğŸ’° åˆå§‹èµ„é‡‘ï¼š{CONFIG['initial_fund']}å…ƒ â†’ æœ€ç»ˆèµ„é‡‘ï¼š{daily_return['cumulative_fund'].iloc[-1]:.2f}å…ƒ")
    print(f"ğŸ¯ æ­£æ”¶ç›Šæ—¥å æ¯”ï¼š{positive_day_ratio:.2f}% | æœ€å¤§å›æ’¤ï¼š{max_drawdown:.2f}%")
    print(f"ğŸ“ å›æµ‹æ˜ç»†ï¼š{CONFIG['backtest_detail_path']}")
    print(f"ğŸ“ èµ„é‡‘æ›²çº¿ï¼š{CONFIG['fund_growth_path']}")
    print(f"ğŸ“ æ±‡æ€»æŠ¥å‘Šï¼š{CONFIG['backtest_summary_path']}")
    print("="*60)
    
    return valid_backtest_df, daily_return

# --------------------------
# ä¸»å‡½æ•°ï¼ˆä¿®å¤backtest_dfä¼ é€’ï¼‰
# --------------------------
def main_yangjia_backtest():
    try:
        init_log()
        # æ­¥éª¤1ï¼šåŠ è½½æ•°æ®
        selection_df, widetable_df = load_backtest_data()
        # æ­¥éª¤2ï¼šæ‰§è¡Œå›æµ‹ï¼ˆè·å–å®Œæ•´backtest_dfå’Œæœ‰æ•ˆäº¤æ˜“dfï¼‰
        backtest_df, valid_backtest_df = run_backtest(selection_df, widetable_df)
        if len(valid_backtest_df) == 0:
            log_msg("âŒ æ— æœ‰æ•ˆäº¤æ˜“è®°å½•ï¼Œå›æµ‹ç»ˆæ­¢")
            return None, None
        # æ­¥éª¤3ï¼šè®¡ç®—èµ„é‡‘å¢é•¿
        daily_return = calculate_fund_growth(valid_backtest_df)
        # æ­¥éª¤4ï¼šç”ŸæˆæŠ¥å‘Šï¼ˆä¼ é€’backtest_dfï¼‰
        valid_backtest_df, daily_return = summarize_and_save(backtest_df, valid_backtest_df, daily_return)
        return valid_backtest_df, daily_return
    except Exception as e:
        log_msg(f"âŒ å›æµ‹å¤±è´¥ï¼š{str(e)}")
        raise

# æ‰§è¡Œå›æµ‹
if __name__ == "__main__":
    backtest_detail, fund_growth = main_yangjia_backtest()

