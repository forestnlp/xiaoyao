{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0d9273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-26 11:12:42] å¼€å§‹åŠ è½½å›æµ‹æ•°æ®ï¼ˆé€‰è‚¡ç»“æœ+åŸå§‹å®½è¡¨ï¼‰...\n",
      "[2025-10-26 11:12:42] âœ… é€‰è‚¡ç»“æœåŠ è½½ï¼š137æ¡è®°å½•ï¼Œ112ä¸ªé€‰è‚¡æ—¥\n",
      "[2025-10-26 11:12:45] âœ… å®½è¡¨ä»·æ ¼æ•°æ®åŠ è½½ï¼š3446202æ¡è®°å½•ï¼Œ5284åªè‚¡ç¥¨\n",
      "[2025-10-26 11:12:45] âœ… æ•°æ®åˆå¹¶å®Œæˆï¼š137æ¡æœ‰æ•ˆé€‰è‚¡è®°å½•\n",
      "[2025-10-26 11:12:45] å¼€å§‹æ‰§è¡Œå…»å®¶å¿ƒæ³•å›æµ‹...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# --------------------------\n",
    "# 1. é…ç½®å‚æ•°ï¼ˆä¸å˜ï¼‰\n",
    "# --------------------------\n",
    "CONFIG = {\n",
    "    \"selection_input_path\": r'./yangjia_selection_result.csv',\n",
    "    \"widetable_input_path\": r'D:\\workspace\\xiaoyao\\data\\widetable.parquet',\n",
    "    \"backtest_detail_path\": r'./yangjia_backtest_detail.csv',\n",
    "    \"fund_growth_path\": r'./yangjia_fund_growth.csv',\n",
    "    \"backtest_summary_path\": r'./yangjia_backtest_summary.txt',\n",
    "    \"log_path\": r'./yangjia_backtest_log.txt',\n",
    "    \"trade_rules\": {\n",
    "        \"buy_delay\": 1,        # Tæ—¥é€‰è‚¡â†’T+1ä¹°å…¥\n",
    "        \"sell_delay\": 5,       # T+1ä¹°å…¥â†’T+5å–å‡º\n",
    "        \"stop_loss_ratio\": 0.05,\n",
    "        \"stop_profit_ratio\": 0.15,\n",
    "        \"initial_position\": 0.5,\n",
    "        \"add_position_threshold\": 0.03\n",
    "    },\n",
    "    \"initial_fund\": 100000  # åˆå§‹èµ„é‡‘ï¼ˆæ•´æ•°ï¼Œåç»­è½¬ä¸ºæµ®ç‚¹æ•°ï¼‰\n",
    "}\n",
    "\n",
    "# --------------------------\n",
    "# 2. å·¥å…·å‡½æ•°ï¼ˆä¸å˜ï¼‰\n",
    "# --------------------------\n",
    "def init_log():\n",
    "    with open(CONFIG[\"log_path\"], 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"ã€å…»å®¶å¿ƒæ³•å›æµ‹å¯åŠ¨ã€‘{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "\n",
    "def log_msg(msg):\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    log_line = f\"[{timestamp}] {msg}\"\n",
    "    print(log_line)\n",
    "    with open(CONFIG[\"log_path\"], 'a', encoding='utf-8') as f:\n",
    "        f.write(log_line + \"\\n\")\n",
    "\n",
    "# --------------------------\n",
    "# 3. åŠ è½½å›æµ‹æ•°æ®ï¼ˆä¸å˜ï¼Œå·²ç»Ÿä¸€æ—¥æœŸç±»å‹ï¼‰\n",
    "# --------------------------\n",
    "def load_backtest_data():\n",
    "    log_msg(\"å¼€å§‹åŠ è½½å›æµ‹æ•°æ®ï¼ˆé€‰è‚¡ç»“æœ+åŸå§‹å®½è¡¨ï¼‰...\")\n",
    "    \n",
    "    # åŠ è½½é€‰è‚¡ç»“æœï¼ˆç»Ÿä¸€t_dateä¸ºdatetimeï¼‰\n",
    "    selection_df = pd.read_csv(CONFIG[\"selection_input_path\"])\n",
    "    selection_df[\"date\"] = pd.to_datetime(selection_df[\"date\"])\n",
    "    selection_df[\"t_date\"] = pd.to_datetime(selection_df[\"selection_date\"])  # è½¬ä¸ºdatetime\n",
    "    selection_df = selection_df.drop(columns=[\"selection_date\"])\n",
    "    log_msg(f\"âœ… é€‰è‚¡ç»“æœåŠ è½½ï¼š{len(selection_df)}æ¡è®°å½•ï¼Œ{selection_df['t_date'].nunique()}ä¸ªé€‰è‚¡æ—¥\")\n",
    "    \n",
    "    # åŠ è½½å®½è¡¨ä»·æ ¼æ•°æ®\n",
    "    price_cols = ['date', 'stock_code', 'open', 'close', 'paused']\n",
    "    widetable_df = pd.read_parquet(CONFIG[\"widetable_input_path\"], columns=price_cols)\n",
    "    widetable_df[\"date\"] = pd.to_datetime(widetable_df[\"date\"])\n",
    "    widetable_df = widetable_df.sort_values(by=[\"stock_code\", \"date\"]).reset_index(drop=True)\n",
    "    widetable_df[\"trade_seq\"] = widetable_df.groupby(\"stock_code\").cumcount()\n",
    "    log_msg(f\"âœ… å®½è¡¨ä»·æ ¼æ•°æ®åŠ è½½ï¼š{len(widetable_df)}æ¡è®°å½•ï¼Œ{widetable_df['stock_code'].nunique()}åªè‚¡ç¥¨\")\n",
    "    \n",
    "    # åˆå¹¶é€‰è‚¡ç»“æœä¸äº¤æ˜“åºåˆ—\n",
    "    selection_df = pd.merge(\n",
    "        selection_df,\n",
    "        widetable_df[[\"stock_code\", \"date\", \"trade_seq\"]].rename(columns={\"date\": \"t_date\"}),\n",
    "        on=[\"stock_code\", \"t_date\"],\n",
    "        how=\"left\"\n",
    "    ).dropna(subset=[\"trade_seq\"])\n",
    "    selection_df[\"trade_seq\"] = selection_df[\"trade_seq\"].astype(int)\n",
    "    \n",
    "    log_msg(f\"âœ… æ•°æ®åˆå¹¶å®Œæˆï¼š{len(selection_df)}æ¡æœ‰æ•ˆé€‰è‚¡è®°å½•\")\n",
    "    return selection_df, widetable_df\n",
    "\n",
    "# --------------------------\n",
    "# 4. æ ¸å¿ƒå›æµ‹é€»è¾‘ï¼ˆä¸å˜ï¼‰\n",
    "# --------------------------\n",
    "def run_backtest(selection_df, widetable_df):\n",
    "    log_msg(\"å¼€å§‹æ‰§è¡Œå…»å®¶å¿ƒæ³•å›æµ‹...\")\n",
    "    rules = CONFIG[\"trade_rules\"]\n",
    "    \n",
    "    price_seq_map = widetable_df.set_index([\"stock_code\", \"trade_seq\"])[[\"open\", \"close\", \"paused\", \"date\"]].to_dict('index')\n",
    "    \n",
    "    def calc_trade_info(row):\n",
    "        stock_code = row[\"stock_code\"]\n",
    "        t_seq = row[\"trade_seq\"]\n",
    "        \n",
    "        buy_seq = t_seq + rules[\"buy_delay\"]\n",
    "        sell_seq = buy_seq + rules[\"sell_delay\"]\n",
    "        \n",
    "        buy_data = price_seq_map.get((stock_code, buy_seq), {})\n",
    "        buy_price = buy_data.get(\"open\", np.nan)\n",
    "        buy_date = buy_data.get(\"date\", np.nan)\n",
    "        is_buy_paused = buy_data.get(\"paused\", 1.0)\n",
    "        \n",
    "        sell_data = price_seq_map.get((stock_code, sell_seq), {})\n",
    "        sell_price = sell_data.get(\"close\", np.nan)\n",
    "        sell_date = sell_data.get(\"date\", np.nan)\n",
    "        is_sell_paused = sell_data.get(\"paused\", 1.0)\n",
    "        \n",
    "        if pd.isna(buy_price) or pd.isna(sell_price) or is_buy_paused == 1.0 or is_sell_paused == 1.0:\n",
    "            return pd.Series({\n",
    "                \"buy_date\": np.nan, \"sell_date\": np.nan,\n",
    "                \"buy_price\": np.nan, \"sell_price\": np.nan,\n",
    "                \"return_rate\": np.nan, \"position\": np.nan,\n",
    "                \"contribution_return\": np.nan, \"is_valid\": False\n",
    "            })\n",
    "        \n",
    "        return_rate = (sell_price - buy_price) / buy_price * 100\n",
    "        position = rules[\"initial_position\"]\n",
    "        if return_rate >= 3:\n",
    "            position = 1.0\n",
    "        contribution_return = return_rate * position\n",
    "        \n",
    "        return pd.Series({\n",
    "            \"buy_date\": buy_date, \"sell_date\": sell_date,\n",
    "            \"buy_price\": buy_price, \"sell_price\": sell_price,\n",
    "            \"return_rate\": return_rate, \"position\": position,\n",
    "            \"contribution_return\": contribution_return, \"is_valid\": True\n",
    "        })\n",
    "    \n",
    "    # æ‰§è¡Œè®¡ç®—å¹¶è¿”å›å®Œæ•´backtest_dfï¼ˆåŒ…å«æœ‰æ•ˆ+æ— æ•ˆäº¤æ˜“ï¼‰\n",
    "    trade_info = selection_df.apply(calc_trade_info, axis=1)\n",
    "    backtest_df = pd.concat([selection_df, trade_info], axis=1)\n",
    "    valid_backtest_df = backtest_df[backtest_df[\"is_valid\"]].copy()\n",
    "    invalid_count = len(backtest_df) - len(valid_backtest_df)\n",
    "    \n",
    "    log_msg(f\"âœ… äº¤æ˜“è®¡ç®—å®Œæˆï¼šæœ‰æ•ˆäº¤æ˜“{len(valid_backtest_df)}æ¡ï¼Œæ— æ•ˆäº¤æ˜“{invalid_count}æ¡\")\n",
    "    \n",
    "    # æ­¢æŸæ­¢ç›ˆä¿®æ­£\n",
    "    def apply_stop_rule(row):\n",
    "        return_rate = row[\"return_rate\"]\n",
    "        if return_rate <= -rules[\"stop_loss_ratio\"] * 100:\n",
    "            return -rules[\"stop_loss_ratio\"] * 100\n",
    "        elif return_rate >= rules[\"stop_profit_ratio\"] * 100:\n",
    "            return rules[\"stop_profit_ratio\"] * 100\n",
    "        else:\n",
    "            return return_rate\n",
    "    \n",
    "    valid_backtest_df[\"adjusted_return\"] = valid_backtest_df.apply(apply_stop_rule, axis=1)\n",
    "    valid_backtest_df[\"adjusted_contribution\"] = valid_backtest_df[\"adjusted_return\"] * valid_backtest_df[\"position\"]\n",
    "    \n",
    "    return backtest_df, valid_backtest_df  # åŒæ—¶è¿”å›å®Œæ•´backtest_dfå’Œæœ‰æ•ˆäº¤æ˜“df\n",
    "\n",
    "# --------------------------\n",
    "# 5. èµ„é‡‘å¢é•¿è®¡ç®—ï¼ˆä¿®å¤dtypeè­¦å‘Šï¼‰\n",
    "# --------------------------\n",
    "def calculate_fund_growth(valid_backtest_df):\n",
    "    log_msg(\"å¼€å§‹è®¡ç®—èµ„é‡‘å¢é•¿ï¼ˆæŒ‰æ—¥å¹³å‡æ”¶ç›Šè¿ä¹˜ï¼‰...\")\n",
    "    \n",
    "    daily_return = valid_backtest_df.groupby(\"sell_date\").agg({\n",
    "        \"adjusted_contribution\": [\"mean\", \"count\"],\n",
    "        \"stock_code\": \"nunique\"\n",
    "    }).reset_index()\n",
    "    daily_return.columns = [\"sell_date\", \"daily_avg_return\", \"daily_trade_count\", \"daily_stock_count\"]\n",
    "    daily_return = daily_return[daily_return[\"daily_trade_count\"] >= 2].sort_values(\"sell_date\")\n",
    "    \n",
    "    # ä¿®å¤dtypeè­¦å‘Šï¼šåˆå§‹åŒ–ä¸ºæµ®ç‚¹æ•°\n",
    "    daily_return[\"cumulative_fund\"] = float(CONFIG[\"initial_fund\"])  # ç›´æ¥ç”¨æµ®ç‚¹æ•°åˆå§‹åŒ–\n",
    "    daily_return[\"daily_growth_rate\"] = 1 + 0.5 * (daily_return[\"daily_avg_return\"] / 100)\n",
    "    \n",
    "    # è®¡ç®—ç´¯è®¡èµ„é‡‘ï¼ˆä¿æŒæµ®ç‚¹æ•°ç±»å‹ï¼‰\n",
    "    for i in range(len(daily_return)):\n",
    "        if i == 0:\n",
    "            daily_return.iloc[i, daily_return.columns.get_loc(\"cumulative_fund\")] = float(CONFIG[\"initial_fund\"]) * daily_return.iloc[i][\"daily_growth_rate\"]\n",
    "        else:\n",
    "            daily_return.iloc[i, daily_return.columns.get_loc(\"cumulative_fund\")] = daily_return.iloc[i-1][\"cumulative_fund\"] * daily_return.iloc[i][\"daily_growth_rate\"]\n",
    "    \n",
    "    # æ ¼å¼åŒ–æ•°å€¼ï¼ˆä¿æŒæµ®ç‚¹æ•°ï¼‰\n",
    "    daily_return[\"daily_avg_return\"] = np.round(daily_return[\"daily_avg_return\"], 2)\n",
    "    daily_return[\"daily_growth_rate\"] = np.round(daily_return[\"daily_growth_rate\"], 4)\n",
    "    daily_return[\"cumulative_fund\"] = np.round(daily_return[\"cumulative_fund\"], 2)\n",
    "    \n",
    "    log_msg(f\"âœ… èµ„é‡‘å¢é•¿è®¡ç®—å®Œæˆï¼š{len(daily_return)}ä¸ªæœ‰æ•ˆæ”¶ç›Šæ—¥\")\n",
    "    return daily_return\n",
    "\n",
    "# --------------------------\n",
    "# 6. å›æµ‹ç»“æœç»Ÿè®¡ä¸ä¿å­˜ï¼ˆä¿®å¤backtest_dfä¼ é€’ï¼‰\n",
    "# --------------------------\n",
    "def summarize_and_save(backtest_df, valid_backtest_df, daily_return):\n",
    "    log_msg(\"å¼€å§‹ç”Ÿæˆå›æµ‹æ±‡æ€»æŠ¥å‘Š...\")\n",
    "    \n",
    "    total_trades = len(valid_backtest_df)\n",
    "    total_selection = len(backtest_df)  # ç”¨å®Œæ•´backtest_dfè·å–æ€»é€‰è‚¡è®°å½•æ•°\n",
    "    total_return_rate = (daily_return[\"cumulative_fund\"].iloc[-1] / CONFIG[\"initial_fund\"] - 1) * 100 if len(daily_return) > 0 else 0\n",
    "    trading_days = len(daily_return)\n",
    "    annual_return = total_return_rate / (trading_days / 250) if trading_days > 0 else 0\n",
    "    positive_days = len(daily_return[daily_return[\"daily_avg_return\"] > 0])\n",
    "    positive_day_ratio = positive_days / trading_days * 100 if trading_days > 0 else 0\n",
    "    max_drawdown = 0\n",
    "    \n",
    "    # è®¡ç®—æœ€å¤§å›æ’¤\n",
    "    if len(daily_return) > 0:\n",
    "        cumulative_fund = daily_return[\"cumulative_fund\"].values\n",
    "        peak = np.maximum.accumulate(cumulative_fund)\n",
    "        drawdown = (cumulative_fund - peak) / peak * 100\n",
    "        max_drawdown = np.min(drawdown)\n",
    "    \n",
    "    # å¼ºåŠ¿æ¿å—ç»Ÿè®¡\n",
    "    industry_return = valid_backtest_df.groupby(\"sw_l1_industry_name\").agg({\n",
    "        \"adjusted_return\": [\"mean\", \"count\", lambda x: np.round((x>0).mean()*100, 2)],\n",
    "        \"stock_code\": \"nunique\"\n",
    "    }).reset_index()\n",
    "    industry_return.columns = [\"industry\", \"avg_return(%)\", \"trade_count\", \"positive_ratio(%)\", \"stock_count\"]\n",
    "    industry_return = industry_return.sort_values(\"avg_return(%)\", ascending=False).head(10)\n",
    "    \n",
    "    # ä¿å­˜ç»“æœ\n",
    "    valid_backtest_df.to_csv(CONFIG[\"backtest_detail_path\"], index=False, encoding='utf-8-sig')\n",
    "    daily_return.to_csv(CONFIG[\"fund_growth_path\"], index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Šï¼ˆä½¿ç”¨backtest_dfè®¡ç®—æ€»é€‰è‚¡è®°å½•ï¼‰\n",
    "    summary_content = f\"\"\"\n",
    "ã€å…»å®¶å¿ƒæ³•å›æµ‹æ±‡æ€»æŠ¥å‘Šã€‘\n",
    "==========================\n",
    "å›æµ‹è§„åˆ™ï¼šTæ—¥é€‰è‚¡â†’T+{CONFIG['trade_rules']['buy_delay']}ä¹°å…¥â†’T+{CONFIG['trade_rules']['sell_delay']}å–å‡º\n",
    "         åˆå§‹åŠä»“ï¼Œç›ˆåˆ©â‰¥3%åŠ ä»“è‡³æ»¡ä»“ï¼›æ­¢æŸ5%ï¼Œæ­¢ç›ˆ15%\n",
    "==========================\n",
    "1. åŸºç¡€äº¤æ˜“ç»Ÿè®¡\n",
    "   - æ€»é€‰è‚¡è®°å½•ï¼š{total_selection}æ¡\n",
    "   - æœ‰æ•ˆäº¤æ˜“è®°å½•ï¼š{total_trades}æ¡\n",
    "   - æ— æ•ˆäº¤æ˜“è®°å½•ï¼š{total_selection - total_trades}æ¡\n",
    "   - æœ‰æ•ˆäº¤æ˜“å¤©æ•°ï¼š{trading_days}å¤©\n",
    "   - å¹³å‡æ¯æ—¥äº¤æ˜“ï¼š{total_trades/trading_days:.1f}åªï¼ˆè‹¥trading_days>0ï¼‰\n",
    "\n",
    "2. æ”¶ç›Šè¡¨ç°\n",
    "   - åˆå§‹èµ„é‡‘ï¼š{CONFIG['initial_fund']:.2f}å…ƒ\n",
    "   - æœ€ç»ˆèµ„é‡‘ï¼š{daily_return['cumulative_fund'].iloc[-1]:.2f}å…ƒï¼ˆè‹¥trading_days>0ï¼‰\n",
    "   - ç´¯è®¡æ”¶ç›Šç‡ï¼š{total_return_rate:.2f}%\n",
    "   - å¹´åŒ–æ”¶ç›Šç‡ï¼š{annual_return:.2f}%ï¼ˆæŒ‰250ä¸ªäº¤æ˜“æ—¥/å¹´ï¼‰\n",
    "   - æ­£æ”¶ç›Šæ—¥å æ¯”ï¼š{positive_day_ratio:.2f}%ï¼ˆ{positive_days}/{trading_days}ï¼‰\n",
    "   - æœ€å¤§å›æ’¤ï¼š{max_drawdown:.2f}%\n",
    "\n",
    "3. é£é™©æ§åˆ¶\n",
    "   - æ­¢æŸè§¦å‘æ¬¡æ•°ï¼š{len(valid_backtest_df[valid_backtest_df['adjusted_return'] <= -5])}æ¬¡\n",
    "   - æ­¢ç›ˆè§¦å‘æ¬¡æ•°ï¼š{len(valid_backtest_df[valid_backtest_df['adjusted_return'] >= 15])}æ¬¡\n",
    "   - å¹³å‡å•ç¥¨æ”¶ç›Šï¼š{valid_backtest_df['adjusted_return'].mean():.2f}%\n",
    "   - æ”¶ç›Šæ ‡å‡†å·®ï¼š{valid_backtest_df['adjusted_return'].std():.2f}%\n",
    "\n",
    "4. å¼ºåŠ¿æ¿å—TOP10\n",
    "{industry_return.to_string(index=False, float_format=lambda x: f\"{x:.2f}\")}\n",
    "==========================\n",
    "å›æµ‹å®Œæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\"\"\"\n",
    "    with open(CONFIG[\"backtest_summary_path\"], 'w', encoding='utf-8') as f:\n",
    "        f.write(summary_content)\n",
    "    \n",
    "    # æ‰“å°æ ¸å¿ƒç»“æœ\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ‰ å…»å®¶å¿ƒæ³•å›æµ‹æ ¸å¿ƒç»“æœ\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"ğŸ“Š ç´¯è®¡æ”¶ç›Šç‡ï¼š{total_return_rate:.2f}% | å¹´åŒ–æ”¶ç›Šç‡ï¼š{annual_return:.2f}%\")\n",
    "    print(f\"ğŸ’° åˆå§‹èµ„é‡‘ï¼š{CONFIG['initial_fund']}å…ƒ â†’ æœ€ç»ˆèµ„é‡‘ï¼š{daily_return['cumulative_fund'].iloc[-1]:.2f}å…ƒ\")\n",
    "    print(f\"ğŸ¯ æ­£æ”¶ç›Šæ—¥å æ¯”ï¼š{positive_day_ratio:.2f}% | æœ€å¤§å›æ’¤ï¼š{max_drawdown:.2f}%\")\n",
    "    print(f\"ğŸ“ å›æµ‹æ˜ç»†ï¼š{CONFIG['backtest_detail_path']}\")\n",
    "    print(f\"ğŸ“ èµ„é‡‘æ›²çº¿ï¼š{CONFIG['fund_growth_path']}\")\n",
    "    print(f\"ğŸ“ æ±‡æ€»æŠ¥å‘Šï¼š{CONFIG['backtest_summary_path']}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return valid_backtest_df, daily_return\n",
    "\n",
    "# --------------------------\n",
    "# ä¸»å‡½æ•°ï¼ˆä¿®å¤backtest_dfä¼ é€’ï¼‰\n",
    "# --------------------------\n",
    "def main_yangjia_backtest():\n",
    "    try:\n",
    "        init_log()\n",
    "        # æ­¥éª¤1ï¼šåŠ è½½æ•°æ®\n",
    "        selection_df, widetable_df = load_backtest_data()\n",
    "        # æ­¥éª¤2ï¼šæ‰§è¡Œå›æµ‹ï¼ˆè·å–å®Œæ•´backtest_dfå’Œæœ‰æ•ˆäº¤æ˜“dfï¼‰\n",
    "        backtest_df, valid_backtest_df = run_backtest(selection_df, widetable_df)\n",
    "        if len(valid_backtest_df) == 0:\n",
    "            log_msg(\"âŒ æ— æœ‰æ•ˆäº¤æ˜“è®°å½•ï¼Œå›æµ‹ç»ˆæ­¢\")\n",
    "            return None, None\n",
    "        # æ­¥éª¤3ï¼šè®¡ç®—èµ„é‡‘å¢é•¿\n",
    "        daily_return = calculate_fund_growth(valid_backtest_df)\n",
    "        # æ­¥éª¤4ï¼šç”ŸæˆæŠ¥å‘Šï¼ˆä¼ é€’backtest_dfï¼‰\n",
    "        valid_backtest_df, daily_return = summarize_and_save(backtest_df, valid_backtest_df, daily_return)\n",
    "        return valid_backtest_df, daily_return\n",
    "    except Exception as e:\n",
    "        log_msg(f\"âŒ å›æµ‹å¤±è´¥ï¼š{str(e)}\")\n",
    "        raise\n",
    "\n",
    "# æ‰§è¡Œå›æµ‹\n",
    "if __name__ == \"__main__\":\n",
    "    backtest_detail, fund_growth = main_yangjia_backtest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcbf78e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>return_rate</th>\n",
       "      <th>growth</th>\n",
       "      <th>cumulative_growth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>3.891914</td>\n",
       "      <td>1.019460</td>\n",
       "      <td>1.019460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-16</td>\n",
       "      <td>-3.735034</td>\n",
       "      <td>0.981325</td>\n",
       "      <td>1.000421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-17</td>\n",
       "      <td>-12.634132</td>\n",
       "      <td>0.936829</td>\n",
       "      <td>0.937224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-20</td>\n",
       "      <td>-14.437381</td>\n",
       "      <td>0.927813</td>\n",
       "      <td>0.869568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-27</td>\n",
       "      <td>15.711290</td>\n",
       "      <td>1.078556</td>\n",
       "      <td>0.937879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2025-09-05</td>\n",
       "      <td>4.777328</td>\n",
       "      <td>1.023887</td>\n",
       "      <td>0.587377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2025-09-15</td>\n",
       "      <td>-20.900322</td>\n",
       "      <td>0.895498</td>\n",
       "      <td>0.525995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2025-09-19</td>\n",
       "      <td>-3.132992</td>\n",
       "      <td>0.984335</td>\n",
       "      <td>0.517755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>2025-09-22</td>\n",
       "      <td>-24.368231</td>\n",
       "      <td>0.878159</td>\n",
       "      <td>0.454671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2025-10-15</td>\n",
       "      <td>12.188749</td>\n",
       "      <td>1.060944</td>\n",
       "      <td>0.482381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  return_rate    growth  cumulative_growth\n",
       "0   2023-02-06     3.891914  1.019460           1.019460\n",
       "1   2023-03-16    -3.735034  0.981325           1.000421\n",
       "2   2023-03-17   -12.634132  0.936829           0.937224\n",
       "3   2023-03-20   -14.437381  0.927813           0.869568\n",
       "4   2023-03-27    15.711290  1.078556           0.937879\n",
       "..         ...          ...       ...                ...\n",
       "107 2025-09-05     4.777328  1.023887           0.587377\n",
       "108 2025-09-15   -20.900322  0.895498           0.525995\n",
       "109 2025-09-19    -3.132992  0.984335           0.517755\n",
       "110 2025-09-22   -24.368231  0.878159           0.454671\n",
       "111 2025-10-15    12.188749  1.060944           0.482381\n",
       "\n",
       "[112 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'./yangjia_backtest_detail.csv')\n",
    "# æŒ‰æ—¥è·å–å¹³å‡çš„return_rateï¼Œå°†åˆ—åè®¾ç½®ä¸ºdateå’Œreturn_rate\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "daily_return = df.groupby('date')['return_rate'].mean().reset_index()\n",
    "daily_return.columns = ['date', 'return_rate']\n",
    "\n",
    "# å°†return_rateè½¬æ¢ä¸ºå¢é•¿ç‡\n",
    "daily_return['growth'] = 1+daily_return['return_rate']*0.5/100\n",
    "# è®¡ç®—ç´¯è®¡å¢é•¿ç‡\n",
    "daily_return['cumulative_growth'] = daily_return['growth'].cumprod()\n",
    "daily_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6aafbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xiaoyao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
