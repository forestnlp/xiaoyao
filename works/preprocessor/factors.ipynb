{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a696cf2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据量：972326 条，索引是否唯一：True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1280\\2186578339.py:63: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('stock_code', group_keys=False).apply(macd_vectorized)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'stock_code'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 79\u001b[0m\n\u001b[0;32m     76\u001b[0m     group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbollinger_lower_calc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m lower\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m group\n\u001b[1;32m---> 79\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstock_code\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mapply(bollinger_vectorized)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# --------------------------\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# 6. VWAP指标\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# --------------------------\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mvwap_vectorized\u001b[39m(group):\n",
      "File \u001b[1;32md:\\Sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\pandas\\core\\frame.py:9190\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   9187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   9188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 9190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   9191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9193\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9196\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9200\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1330\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   1327\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1330\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1333\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1334\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1335\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1337\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1338\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[0;32m   1341\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[1;32md:\\Sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py:1043\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[0;32m   1041\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1043\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1045\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'stock_code'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import talib as ta\n",
    "\n",
    "# --------------------------\n",
    "# 1. 读取数据与基础处理\n",
    "# --------------------------\n",
    "file_path = r'D:\\workspace\\xiaoyao\\data\\widetable.parquet'\n",
    "df = pd.read_parquet(file_path)\n",
    "# 排序并重置索引（确保唯一有序）\n",
    "df = df.sort_values(by=['stock_code', 'date']).reset_index(drop=True)\n",
    "print(f\"数据量：{len(df)} 条，索引是否唯一：{df.index.is_unique}\")\n",
    "\n",
    "# --------------------------\n",
    "# 2. 趋势类指标（MA/EMA）\n",
    "# --------------------------\n",
    "df['ma5'] = df.groupby('stock_code')['close'].transform(\n",
    "    lambda x: ta.SMA(x.values, timeperiod=5)\n",
    ")\n",
    "df['ma10'] = df.groupby('stock_code')['close'].transform(\n",
    "    lambda x: ta.SMA(x.values, timeperiod=10)\n",
    ")\n",
    "df['ma20'] = df.groupby('stock_code')['close'].transform(\n",
    "    lambda x: ta.SMA(x.values, timeperiod=20)\n",
    ")\n",
    "df['ma60'] = df.groupby('stock_code')['close'].transform(\n",
    "    lambda x: ta.SMA(x.values, timeperiod=60)\n",
    ")\n",
    "df['ema12'] = df.groupby('stock_code')['close'].transform(\n",
    "    lambda x: ta.EMA(x.values, timeperiod=12)\n",
    ")\n",
    "df['ema26'] = df.groupby('stock_code')['close'].transform(\n",
    "    lambda x: ta.EMA(x.values, timeperiod=26)\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# 3. 震荡类指标（RSI）\n",
    "# --------------------------\n",
    "df['rsi14'] = df.groupby('stock_code')['close'].transform(\n",
    "    lambda x: ta.RSI(x.values, timeperiod=14)\n",
    ")\n",
    "df['rsi6'] = df.groupby('stock_code')['close'].transform(\n",
    "    lambda x: ta.RSI(x.values, timeperiod=6)\n",
    ")\n",
    "df['rsi21'] = df.groupby('stock_code')['close'].transform(\n",
    "    lambda x: ta.RSI(x.values, timeperiod=21)\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# 4. MACD指标（修复：不删除stock_code列）\n",
    "# --------------------------\n",
    "def macd_vectorized(group):\n",
    "    # 不删除分组列，仅计算指标（避免后续groupby找不到列）\n",
    "    close = group['close'].values\n",
    "    macd_line, signal_line, macd_hist = ta.MACD(close, fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "    group['macd_line_calc'] = macd_line\n",
    "    group['signal_line_calc'] = signal_line\n",
    "    group['macd_hist_calc'] = macd_hist\n",
    "    return group\n",
    "\n",
    "# 用group_keys=False + 保留分组列，消除警告且不丢列\n",
    "df = df.groupby('stock_code', group_keys=False).apply(macd_vectorized)\n",
    "\n",
    "# --------------------------\n",
    "# 5. 布林带指标（修复：不删除stock_code列）\n",
    "# --------------------------\n",
    "def bollinger_vectorized(group):\n",
    "    close = group['close'].values\n",
    "    upper, mid, lower = ta.BBANDS(\n",
    "        close, timeperiod=20, nbdevup=2, nbdevdn=2, matype=0  # matype=0=SMA\n",
    "    )\n",
    "    group['bollinger_upper_calc'] = upper\n",
    "    group['bollinger_mid_calc'] = mid\n",
    "    group['bollinger_lower_calc'] = lower\n",
    "    return group\n",
    "\n",
    "df = df.groupby('stock_code', group_keys=False).apply(bollinger_vectorized)\n",
    "\n",
    "# --------------------------\n",
    "# 6. VWAP指标（修复：不删除stock_code列）\n",
    "# --------------------------\n",
    "def vwap_vectorized(group):\n",
    "    volume = group['volume'].replace(0, 0.0001).values\n",
    "    money = group['money'].values\n",
    "    cum_sum = (money / volume).cumsum()  # 向量化累积和\n",
    "    divisor = np.arange(1, len(group) + 1)  # 向量化除数（1,2,...,n）\n",
    "    group['vwap'] = cum_sum / divisor\n",
    "    return group\n",
    "\n",
    "df = df.groupby('stock_code', group_keys=False).apply(vwap_vectorized)\n",
    "\n",
    "# --------------------------\n",
    "# 7. Momentum与ROC指标（修复：不删除stock_code列）\n",
    "# --------------------------\n",
    "def momentum_vectorized(group):\n",
    "    group['momentum14'] = group['close'] - group['close'].shift(14)  # 14日动量\n",
    "    return group\n",
    "\n",
    "df = df.groupby('stock_code', group_keys=False).apply(momentum_vectorized)\n",
    "\n",
    "# TA-Lib ROC（价格变动率）\n",
    "df['roc10'] = df.groupby('stock_code')['close'].transform(\n",
    "    lambda x: ta.ROC(x.values, timeperiod=10)\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# 8. 量能类指标\n",
    "# --------------------------\n",
    "# 成交量对比（昨日）\n",
    "df['volume_ratio_vs_yesterday'] = df.groupby('stock_code')['volume'].transform(\n",
    "    lambda x: x / x.shift(1).replace(0, 0.0001)\n",
    ")\n",
    "# 成交量对比（5日平均）\n",
    "df['volume_ratio_vs_5d_avg'] = df.groupby('stock_code')['volume'].transform(\n",
    "    lambda x: x / x.rolling(window=5, min_periods=1).mean().shift(1).replace(0, 0.0001)\n",
    ")\n",
    "# 竞价量对比（昨日）\n",
    "df['auc_volume_ratio_vs_yesterday'] = df.groupby('stock_code')['auc_volume'].transform(\n",
    "    lambda x: x / x.shift(1).replace(0, 0.0001)\n",
    ")\n",
    "# 竞价量对比（5日平均）\n",
    "df['auc_volume_ratio_vs_5d_avg'] = df.groupby('stock_code')['auc_volume'].transform(\n",
    "    lambda x: x / x.rolling(window=5, min_periods=1).mean().shift(1).replace(0, 0.0001)\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# 9. 波动率与ATR指标（修复：不删除stock_code列）\n",
    "# --------------------------\n",
    "# 自定义波动率\n",
    "def volatility_vectorized(group):\n",
    "    open_price = group['open'].replace(0, 0.0001)\n",
    "    daily_range = (group['high'] - group['low']) / open_price  # 当日波动幅度\n",
    "    group['volatility'] = daily_range.rolling(window=20, min_periods=1).mean()  # 20日平均波动率\n",
    "    return group\n",
    "\n",
    "df = df.groupby('stock_code', group_keys=False).apply(volatility_vectorized)\n",
    "\n",
    "# TA-Lib ATR（平均真实波幅）—— 修复版\n",
    "def atr_vectorized(group):\n",
    "    high = group['high'].values\n",
    "    low = group['low'].values\n",
    "    close = group['close'].values\n",
    "    # 计算ATR并返回与group长度一致的数组\n",
    "    atr = ta.ATR(high, low, close, timeperiod=14)\n",
    "    return pd.Series(atr, index=group.index, name='atr14')  # 显式指定索引\n",
    "\n",
    "# 用transform确保结果与原df索引对齐\n",
    "df['atr14'] = df.groupby('stock_code', group_keys=False).apply(atr_vectorized)\n",
    "\n",
    "# --------------------------\n",
    "# 10. 盘口/活跃度指标\n",
    "# --------------------------\n",
    "# 盘口订单总量\n",
    "df['buy_total'] = df[['b1_v', 'b2_v', 'b3_v', 'b4_v', 'b5_v']].sum(axis=1)\n",
    "df['sell_total'] = df[['a1_v', 'a2_v', 'a3_v', 'a4_v', 'a5_v']].sum(axis=1)\n",
    "# 盘口订单量比\n",
    "df['order_book_volume_ratio'] = df.apply(\n",
    "    lambda row: row['buy_total'] / row['sell_total'] if row['sell_total'] != 0 else np.nan, axis=1\n",
    ")\n",
    "# 盘口量比（昨日）\n",
    "df['obv_ratio_vs_yesterday'] = df.groupby('stock_code')['order_book_volume_ratio'].transform(\n",
    "    lambda x: x / x.shift(1).replace(0, np.nan)\n",
    ")\n",
    "# 盘口量比（5日平均）\n",
    "df['obv_ratio_vs_5d_avg'] = df.groupby('stock_code')['order_book_volume_ratio'].transform(\n",
    "    lambda x: x / x.rolling(window=5, min_periods=1).mean().shift(1).replace(0, np.nan)\n",
    ")\n",
    "\n",
    "# 换手率对比\n",
    "df['turnover_ratio_vs_yesterday'] = df.groupby('stock_code')['turnover_ratio'].transform(\n",
    "    lambda x: x / x.shift(1).replace(0, np.nan)\n",
    ")\n",
    "df['turnover_ratio_vs_5d_avg'] = df.groupby('stock_code')['turnover_ratio'].transform(\n",
    "    lambda x: x / x.rolling(window=5, min_periods=1).mean().shift(1).replace(0, np.nan)\n",
    ")\n",
    "\n",
    "# 资金额对比\n",
    "df['money_ratio_vs_yesterday'] = df.groupby('stock_code')['money'].transform(\n",
    "    lambda x: x / x.shift(1).replace(0, 0.0001)\n",
    ")\n",
    "df['money_ratio_vs_5d_avg'] = df.groupby('stock_code')['money'].transform(\n",
    "    lambda x: x / x.rolling(window=5, min_periods=1).mean().shift(1).replace(0, 0.0001)\n",
    ")\n",
    "\n",
    "# 振幅指标\n",
    "df['amplitude'] = (df['high'] - df['low']) / df['pre_close'] * 100  # 当日振幅（%）\n",
    "df['amplitude_vs_yesterday'] = df.groupby('stock_code')['amplitude'].transform(\n",
    "    lambda x: x / x.shift(1).replace(0, np.nan)\n",
    ")\n",
    "df['amplitude_vs_5d_avg'] = df.groupby('stock_code')['amplitude'].transform(\n",
    "    lambda x: x / x.rolling(window=5, min_periods=1).mean().shift(1).replace(0, np.nan)\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# 11. 资金流向/趋势强度/波动风险/量价结构\n",
    "# --------------------------\n",
    "# OBV（能量潮）—— 向量化实现\n",
    "def obv_vectorized(group):\n",
    "    close = group['close'].values\n",
    "    volume = group['volume'].values\n",
    "    # 向量化判断涨跌（无需循环）\n",
    "    delta = np.sign(close[1:] - close[:-1])  # 涨=1，跌=-1，平=0\n",
    "    delta = np.pad(delta, (1, 0), mode='constant')  # 首行补0（无历史数据）\n",
    "    group['obv'] = (delta * volume).cumsum()  # 累积求和\n",
    "    return group\n",
    "\n",
    "df = df.groupby('stock_code', group_keys=False).apply(obv_vectorized)\n",
    "\n",
    "# 主力净流入\n",
    "df['main_force_net_flow'] = df['buy_total'] - df['sell_total']\n",
    "\n",
    "# ADX（平均趋向指数）\n",
    "def calculate_adx(group):\n",
    "    high = group['high']\n",
    "    low = group['low']\n",
    "    close = group['close']\n",
    "    prev_close = close.shift(1)\n",
    "    \n",
    "    # 计算+DM、-DM\n",
    "    plus_dm = high - high.shift(1)\n",
    "    minus_dm = low.shift(1) - low\n",
    "    plus_dm = plus_dm.where((plus_dm > minus_dm) & (plus_dm > 0), 0)\n",
    "    minus_dm = minus_dm.where((minus_dm > plus_dm) & (minus_dm > 0), 0)\n",
    "    \n",
    "    # 计算TR（真实波幅）\n",
    "    tr1 = high - low\n",
    "    tr2 = abs(high - prev_close)\n",
    "    tr3 = abs(low - prev_close)\n",
    "    tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
    "    \n",
    "    # 计算ATR、+DI、-DI、ADX\n",
    "    atr = tr.rolling(window=14, min_periods=1).mean()\n",
    "    plus_di = (plus_dm.rolling(window=14, min_periods=1).mean() / atr) * 100\n",
    "    minus_di = (minus_dm.rolling(window=14, min_periods=1).mean() / atr) * 100\n",
    "    dx = (abs(plus_di - minus_di) / (plus_di + minus_di.replace(0, 0.0001))) * 100\n",
    "    group['adx'] = dx.rolling(window=14, min_periods=1).mean()\n",
    "    group['plus_di'] = plus_di\n",
    "    group['minus_di'] = minus_di\n",
    "    return group\n",
    "\n",
    "df = df.groupby('stock_code', group_keys=False).apply(calculate_adx)\n",
    "\n",
    "# MA20斜率\n",
    "df['ma20_slope'] = df.groupby('stock_code')['ma20'].transform(\n",
    "    lambda x: (x - x.shift(1)) / x.shift(1).replace(0, 0.0001) * 100\n",
    ")\n",
    "\n",
    "# 滚动最大回撤（20天）\n",
    "def calculate_rolling_max_drawdown(group):\n",
    "    rolling_max = group['close'].rolling(window=20, min_periods=1).max()  # 20天内最高价\n",
    "    drawdown = (group['close'] - rolling_max) / rolling_max  # 回撤率\n",
    "    group['rolling_max_drawdown_20d'] = drawdown.rolling(window=20, min_periods=1).min()  # 最大回撤\n",
    "    return group\n",
    "\n",
    "df = df.groupby('stock_code', group_keys=False).apply(calculate_rolling_max_drawdown)\n",
    "\n",
    "# 量价结构指标\n",
    "df['volume_ratio'] = df.groupby('stock_code')['volume'].transform(\n",
    "    lambda x: x / x.rolling(window=5, min_periods=1).mean().replace(0, 0.0001)\n",
    ")\n",
    "\n",
    "# 量价背离\n",
    "def calculate_price_volume_divergence(group):\n",
    "    period = 5\n",
    "    price_gain = (group['close'] / group['close'].shift(period) - 1) * 100  # 价格涨幅（%）\n",
    "    volume_gain = (group['volume'] / group['volume'].shift(period).replace(0, 0.0001) - 1) * 100  # 成交量涨幅（%）\n",
    "    group['price_volume_divergence'] = price_gain - volume_gain  # 背离值\n",
    "    return group\n",
    "\n",
    "df = df.groupby('stock_code', group_keys=False).apply(calculate_price_volume_divergence)\n",
    "\n",
    "# --------------------------\n",
    "# 12. TA-Lib新增核心因子\n",
    "# --------------------------\n",
    "# 12.1 成交量加权RSI（VI）\n",
    "def calculate_vol_rsi(group):\n",
    "    close = group['close'].values\n",
    "    volume = group['volume'].values\n",
    "    vol_weighted_price = (close * volume) / np.maximum(volume.sum(), 0.0001)  # 成交量加权价格\n",
    "    group['vol_rsi14'] = ta.RSI(vol_weighted_price, timeperiod=14)  # 基于加权价格的RSI\n",
    "    return group\n",
    "\n",
    "df = df.groupby('stock_code', group_keys=False).apply(calculate_vol_rsi)\n",
    "\n",
    "# 12.2 DMA（平行线差）\n",
    "df['dma'] = df.groupby('stock_code')['close'].transform(\n",
    "    lambda x: ta.EMA(x.values, timeperiod=10) - ta.EMA(x.values, timeperiod=50)\n",
    ")\n",
    "df['dma_signal'] = df.groupby('stock_code')['dma'].transform(\n",
    "    lambda x: ta.EMA(x.values, timeperiod=10)  # DMA信号线（10日EMA）\n",
    ")\n",
    "\n",
    "# 12.3 KDJ（随机指标）\n",
    "def calculate_kdj(group):\n",
    "    high = group['high'].values\n",
    "    low = group['low'].values\n",
    "    close = group['close'].values\n",
    "    # TA-Lib计算K、D值\n",
    "    k, d = ta.STOCH(\n",
    "        high, low, close,\n",
    "        fastk_period=9, slowk_period=3, slowk_matype=0,\n",
    "        slowd_period=3, slowd_matype=0\n",
    "    )\n",
    "    j = 3 * k - 2 * d  # J值计算公式\n",
    "    group['kdj_k'] = k\n",
    "    group['kdj_d'] = d\n",
    "    group['kdj_j'] = j\n",
    "    return group\n",
    "\n",
    "df = df.groupby('stock_code', group_keys=False).apply(calculate_kdj)\n",
    "\n",
    "# 12.4 OBV的EMA（平滑资金流向）\n",
    "df['obv_ema10'] = df.groupby('stock_code')['obv'].transform(\n",
    "    lambda x: ta.EMA(x.values, timeperiod=10)\n",
    ")\n",
    "\n",
    "# 12.5 价格标准差（波动程度）\n",
    "df['price_std20'] = df.groupby('stock_code')['close'].transform(\n",
    "    lambda x: ta.STDDEV(x.values, timeperiod=20, nbdev=1)\n",
    ")\n",
    "\n",
    "# 12.6 TRIX（三重指数平滑平均线）\n",
    "df['trix'] = df.groupby('stock_code')['close'].transform(\n",
    "    lambda x: ta.TRIX(x.values, timeperiod=12)\n",
    ")\n",
    "df['trix_signal'] = df.groupby('stock_code')['trix'].transform(\n",
    "    lambda x: ta.EMA(x.values, timeperiod=9)  # TRIX信号线（9日EMA）\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# 13. 异常值处理\n",
    "# --------------------------\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "df[numeric_cols] = df[numeric_cols].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# --------------------------\n",
    "# 14. 结果保存\n",
    "# --------------------------\n",
    "output_parquet = r'D:\\workspace\\xiaoyao\\data\\factortable.parquet'\n",
    "df.to_parquet(output_parquet, index=False)\n",
    "\n",
    "# 导出样本\n",
    "df_sample = df.sample(5, random_state=42)\n",
    "df_sample.to_csv('./sample_factortable.csv', index=False)\n",
    "\n",
    "print(f\"所有指标计算完成！结果已保存至：\")\n",
    "print(f\"- Parquet文件：{output_parquet}\")\n",
    "print(f\"- 样本CSV：./sample_factortable.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feec64c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xiaoyao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
