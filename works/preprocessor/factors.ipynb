{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a696cf2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-24 11:44:20] âœ… ç¯å¢ƒåˆå§‹åŒ–å®Œæˆï¼Œè¾“å‡ºè·¯å¾„ï¼š./factortable.parquet\n",
      "[2025-10-24 11:44:20] åŠ è½½widetableæ•°æ®...\n",
      "[2025-10-24 11:44:21] âœ… æ•°æ®åŠ è½½å®Œæˆï¼š998123æ¡è®°å½•ï¼Œ5187åªè‚¡ç¥¨\n",
      "[2025-10-24 11:44:23] âœ… é¢„å¤„ç†å®Œæˆï¼š998123æ¡æœ‰æ•ˆè®°å½•\n",
      "[2025-10-24 11:44:23] è®¡ç®—æ ¸å¿ƒæŒ‡æ ‡...\n",
      "[2025-10-24 11:44:27] âœ… è¿ç»­ä¸Šæ¶¨å¤©æ•°è®¡ç®—å®Œæˆ\n",
      "[2025-10-24 11:44:27] âœ… ç«ä»·æŒ‡æ ‡è®¡ç®—å®Œæˆ\n",
      "[2025-10-24 11:44:28] âœ… å‡çº¿æŒ‡æ ‡è®¡ç®—å®Œæˆ\n",
      "[2025-10-24 11:44:30] âœ… MACDæŒ‡æ ‡è®¡ç®—å®Œæˆ\n",
      "[2025-10-24 11:44:32] âœ… é‡èƒ½æŒ‡æ ‡è®¡ç®—å®Œæˆ\n",
      "[2025-10-24 11:45:36] âœ… å›è°ƒæŒ‡æ ‡è®¡ç®—å®Œæˆï¼ˆä¿®å¤æ•´æ•°è½¬æ¢é”™è¯¯ï¼‰\n",
      "[2025-10-24 11:45:38] âœ… æ”¯æ’‘ä½ä¸RSIè®¡ç®—å®Œæˆ\n",
      "[2025-10-24 11:45:38] âœ… æŒ¯å¹…è®¡ç®—å®Œæˆ\n",
      "[2025-10-24 11:45:38] ç­›é€‰å­—æ®µå¹¶ä¿å­˜...\n",
      "[2025-10-24 11:45:38] âœ… æœ€ç»ˆFactortableï¼š899630æ¡è®°å½•ï¼Œ5179åªè‚¡ç¥¨\n",
      "[2025-10-24 11:45:38] âœ… ä¿å­˜å®Œæˆï¼š\n",
      "[2025-10-24 11:45:38] ğŸ“ ä¸»æ–‡ä»¶ï¼š./factortable.parquet\n",
      "[2025-10-24 11:45:38] ğŸ“ æ ·æœ¬æ–‡ä»¶ï¼š./factortable_sample.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import talib as ta\n",
    "import os\n",
    "\n",
    "# --------------------------\n",
    "# é…ç½®å‚æ•°ï¼ˆæœ¬åœ°å­˜å‚¨è·¯å¾„ï¼‰\n",
    "# --------------------------\n",
    "CONFIG = {\n",
    "    \"raw_data_path\": r'D:\\workspace\\xiaoyao\\data\\widetable.parquet',  # åŸå§‹widetableè·¯å¾„\n",
    "    \"factortable_output_path\": r'./factortable.parquet',  # æœ¬åœ°è¾“å‡ºè·¯å¾„\n",
    "    \"sample_output_path\": r'./factortable_sample.csv',  # æ ·æœ¬æ–‡ä»¶\n",
    "    \"log_path\": r'./calc_factortable_log.txt'  # æ—¥å¿—è·¯å¾„\n",
    "}\n",
    "\n",
    "# --------------------------\n",
    "# å·¥å…·å‡½æ•°\n",
    "# --------------------------\n",
    "def init_environment():\n",
    "    \"\"\"åˆå§‹åŒ–æœ¬åœ°ç›®å½•å’Œæ—¥å¿—\"\"\"\n",
    "    os.makedirs(os.path.dirname(CONFIG[\"factortable_output_path\"]), exist_ok=True)\n",
    "    with open(CONFIG[\"log_path\"], 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"ã€Factortableè®¡ç®—å¯åŠ¨ã€‘{pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    log_msg(\"âœ… ç¯å¢ƒåˆå§‹åŒ–å®Œæˆï¼Œè¾“å‡ºè·¯å¾„ï¼š./factortable.parquet\")\n",
    "\n",
    "def log_msg(msg):\n",
    "    \"\"\"æ—¥å¿—è¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ–‡ä»¶\"\"\"\n",
    "    timestamp = pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    log_line = f\"[{timestamp}] {msg}\"\n",
    "    print(log_line)\n",
    "    with open(CONFIG[\"log_path\"], 'a', encoding='utf-8') as f:\n",
    "        f.write(log_line + \"\\n\")\n",
    "\n",
    "# --------------------------\n",
    "# æ ¸å¿ƒé€»è¾‘ï¼šè®¡ç®—å®éªŒæ‰€éœ€æŒ‡æ ‡\n",
    "# --------------------------\n",
    "def calculate_factortable():\n",
    "    try:\n",
    "        init_environment()\n",
    "        \n",
    "        # 1. åŠ è½½widetableå¹¶é¢„å¤„ç†ï¼ˆå‚è€ƒæ—§ä»£ç é€»è¾‘ï¼‰\n",
    "        log_msg(\"åŠ è½½widetableæ•°æ®...\")\n",
    "        df = pd.read_parquet(CONFIG[\"raw_data_path\"])\n",
    "        \n",
    "        # éªŒè¯å¿…éœ€å­—æ®µï¼ˆä¸æ—§ä»£ç ä¸€è‡´ï¼‰\n",
    "        must_have_cols = ['stock_code', 'date', 'close', 'open', 'volume', 'high', 'low']\n",
    "        missing_cols = [col for col in must_have_cols if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"widetableç¼ºå°‘å¿…éœ€å­—æ®µï¼š{missing_cols}\")\n",
    "        log_msg(f\"âœ… æ•°æ®åŠ è½½å®Œæˆï¼š{len(df)}æ¡è®°å½•ï¼Œ{df['stock_code'].nunique()}åªè‚¡ç¥¨\")\n",
    "        \n",
    "        # é¢„å¤„ç†ï¼ˆæ’åº+æ—¥æœŸè½¬æ¢+å»é‡ï¼‰\n",
    "        df = df.sort_values(by=['stock_code', 'date']).reset_index(drop=True)\n",
    "        df['date'] = pd.to_datetime(df['date'], errors='coerce')  # å­—ç¬¦ä¸²è½¬datetime\n",
    "        df = df.dropna(subset=['date', 'close', 'open'])  # è¿‡æ»¤æ— æ•ˆæ—¥æœŸå’Œä»·æ ¼\n",
    "        df = df.drop_duplicates(subset=['stock_code', 'date'], keep='first')  # å»é‡\n",
    "        log_msg(f\"âœ… é¢„å¤„ç†å®Œæˆï¼š{len(df)}æ¡æœ‰æ•ˆè®°å½•\")\n",
    "\n",
    "        # 2. è®¡ç®—å®éªŒæ‰€éœ€æ ¸å¿ƒæŒ‡æ ‡ï¼ˆå‚è€ƒæ—§ä»£ç ï¼Œä»…ä¿ç•™å¿…è¦æŒ‡æ ‡ï¼‰\n",
    "        log_msg(\"è®¡ç®—æ ¸å¿ƒæŒ‡æ ‡...\")\n",
    "        \n",
    "        # ï¼ˆ1ï¼‰è¿ç»­ä¸Šæ¶¨å¤©æ•°ï¼ˆä¸æ—§ä»£ç ä¸€è‡´ï¼‰\n",
    "        def calc_consecutive_up_days(close_series):\n",
    "            up = close_series > close_series.shift(1)\n",
    "            consecutive_up = up.groupby(up.ne(up.shift()).cumsum()).cumsum()\n",
    "            return consecutive_up.astype(int)\n",
    "        df['consecutive_up_days'] = df.groupby('stock_code', group_keys=False)['close'].apply(calc_consecutive_up_days)\n",
    "        log_msg(\"âœ… è¿ç»­ä¸Šæ¶¨å¤©æ•°è®¡ç®—å®Œæˆ\")\n",
    "        \n",
    "        # ï¼ˆ2ï¼‰ç«ä»·ç›¸å…³æŒ‡æ ‡ï¼ˆä¸æ—§ä»£ç ä¸€è‡´ï¼Œé€‚é…widetableçš„auc_volumeï¼‰\n",
    "        if 'auc_volume' in df.columns:\n",
    "            df['auction_volume_ratio'] = df['auc_volume'] / \\\n",
    "                                       df.groupby('stock_code')['volume'].shift(1).replace(0, 0.0001)\n",
    "        else:\n",
    "            df['auction_volume_ratio'] = np.nan\n",
    "            log_msg(\"âš ï¸ æ— auc_volumeå­—æ®µï¼Œauction_volume_ratioå¡«å……ä¸ºNaN\")\n",
    "        df['auction_rise_ratio'] = (df['open'] - df.groupby('stock_code')['close'].shift(1)) / \\\n",
    "                                  df.groupby('stock_code')['close'].shift(1).replace(0, 0.0001)\n",
    "        df['is_high_open'] = df['open'] > df.groupby('stock_code')['close'].shift(1)\n",
    "        log_msg(\"âœ… ç«ä»·æŒ‡æ ‡è®¡ç®—å®Œæˆ\")\n",
    "        \n",
    "        # ï¼ˆ3ï¼‰å‡çº¿æŒ‡æ ‡ï¼ˆä¸æ—§ä»£ç ä¸€è‡´ï¼‰\n",
    "        df['ma5'] = df.groupby('stock_code')['close'].transform(lambda x: ta.SMA(x, 5))\n",
    "        df['ma20'] = df.groupby('stock_code')['close'].transform(lambda x: ta.SMA(x, 20))\n",
    "        log_msg(\"âœ… å‡çº¿æŒ‡æ ‡è®¡ç®—å®Œæˆ\")\n",
    "        \n",
    "        # ï¼ˆ4ï¼‰MACDæŒ‡æ ‡ï¼ˆä¸æ—§ä»£ç ä¸€è‡´ï¼‰\n",
    "        def calc_macd(close_series):\n",
    "            macd, signal, hist = ta.MACD(close_series, 12, 26, 9)\n",
    "            return pd.DataFrame({\n",
    "                'macd_line': macd,\n",
    "                'signal_line': signal,\n",
    "                'macd_hist': hist\n",
    "            }, index=close_series.index)\n",
    "        df = df.join(df.groupby('stock_code', group_keys=False)['close'].apply(calc_macd))\n",
    "        log_msg(\"âœ… MACDæŒ‡æ ‡è®¡ç®—å®Œæˆ\")\n",
    "        \n",
    "        # ï¼ˆ5ï¼‰é‡èƒ½æŒ‡æ ‡ï¼ˆä¸æ—§ä»£ç ä¸€è‡´ï¼‰\n",
    "        df['volume_ratio_5d'] = df.groupby('stock_code')['volume'].transform(\n",
    "            lambda x: x / x.rolling(5, min_periods=1).mean().shift(1).replace(0, 0.0001)\n",
    "        )\n",
    "        log_msg(\"âœ… é‡èƒ½æŒ‡æ ‡è®¡ç®—å®Œæˆ\")\n",
    "        \n",
    "        # ï¼ˆ6ï¼‰å›è°ƒæŒ‡æ ‡ï¼ˆæ ¸å¿ƒä¿®å¤ï¼šå‚è€ƒæ—§ä»£ç ï¼Œé¿å…æ•´æ•°è½¬æ¢é”™è¯¯ï¼‰\n",
    "        def calc_30d_high(group):\n",
    "            # 30æ—¥æœ€é«˜ä»·ï¼ˆç”¨closeè¿˜æ˜¯highï¼Ÿæ—§ä»£ç ç”¨closeï¼Œè¿™é‡Œä¿æŒä¸€è‡´ï¼‰\n",
    "            group['high_30d'] = group['close'].rolling(30, min_periods=5).max()  # é™ä½min_periodsé¿å…è¿‡å¤šNaN\n",
    "            \n",
    "            # è®¡ç®—æœ€é«˜ä»·å¯¹åº”çš„ç´¢å¼•ï¼ˆä¸ç«‹å³è½¬intï¼Œé¿å…NaNé”™è¯¯ï¼‰\n",
    "            def get_high_idx(window):\n",
    "                return window.idxmax()  # å¯èƒ½è¿”å›NaNï¼Œä½†å…ˆä¿ç•™float\n",
    "            group['high_idx_30d'] = group['close'].rolling(30, min_periods=5).apply(get_high_idx, raw=False)\n",
    "            \n",
    "            # åŒ¹é…æœ€é«˜ä»·æ—¥æœŸï¼ˆæ—§ä»£ç é€»è¾‘ï¼šç”¨ç´¢å¼•å®šä½ï¼‰\n",
    "            # å¤„ç†NaNç´¢å¼•ï¼šå¡«å……ä¸ºå½“å‰è¡Œç´¢å¼•ï¼ˆé¿å…åç»­locæŠ¥é”™ï¼‰\n",
    "            group['high_idx_30d'] = group['high_idx_30d'].fillna(group.index.to_series())\n",
    "            # è½¬æ¢ä¸ºæ•´æ•°ç´¢å¼•ï¼ˆæ­¤æ—¶å·²æ— NaNï¼Œå¯å®‰å…¨è½¬æ¢ï¼‰\n",
    "            group['high_idx_30d'] = group['high_idx_30d'].astype(int)\n",
    "            # ç”¨ç´¢å¼•åŒ¹é…æ—¥æœŸ\n",
    "            group['high_date_30d'] = group.loc[group['high_idx_30d'], 'date'].values\n",
    "            return group.drop(columns=['high_idx_30d'])\n",
    "        \n",
    "        # åº”ç”¨è®¡ç®—å¹¶åˆå¹¶ç»“æœï¼ˆå‚è€ƒæ—§ä»£ç çš„joinæ–¹å¼ï¼‰\n",
    "        high_30d_df = df.groupby('stock_code', group_keys=False)[['close', 'date']].apply(calc_30d_high)\n",
    "        df = df.join(high_30d_df[['high_30d', 'high_date_30d']], how='left')\n",
    "        \n",
    "        # è½¬æ¢æ—¥æœŸå¹¶è¿‡æ»¤æ— æ•ˆå€¼ï¼ˆå…³é”®ï¼šåˆ é™¤æ—¥æœŸä¸ºç©ºçš„è®°å½•ï¼‰\n",
    "        df['high_date_30d'] = pd.to_datetime(df['high_date_30d'], errors='coerce')\n",
    "        df = df.dropna(subset=['high_date_30d'])\n",
    "        \n",
    "        # è®¡ç®—å›æ’¤æ¯”ä¾‹å’Œå¤©æ•°ï¼ˆä¸æ—§ä»£ç ä¸€è‡´ï¼‰\n",
    "        df['pullback_ratio'] = (df['high_30d'] - df['close']) / df['high_30d'].replace(0, 0.0001)\n",
    "        df['pullback_days'] = (df['date'] - df['high_date_30d']).dt.days\n",
    "        log_msg(\"âœ… å›è°ƒæŒ‡æ ‡è®¡ç®—å®Œæˆï¼ˆä¿®å¤æ•´æ•°è½¬æ¢é”™è¯¯ï¼‰\")\n",
    "        \n",
    "        # ï¼ˆ7ï¼‰æ”¯æ’‘ä½ä¸RSIï¼ˆä¸æ—§ä»£ç ä¸€è‡´ï¼‰\n",
    "        df['bollinger_lower'] = df.groupby('stock_code', group_keys=False)['close'].apply(\n",
    "            lambda x: ta.BBANDS(x, 20, 2, 2)[2]\n",
    "        )\n",
    "        df['rsi14'] = df.groupby('stock_code')['close'].transform(lambda x: ta.RSI(x, 14))\n",
    "        log_msg(\"âœ… æ”¯æ’‘ä½ä¸RSIè®¡ç®—å®Œæˆ\")\n",
    "        \n",
    "        # ï¼ˆ8ï¼‰æŒ¯å¹…ï¼ˆä¸æ—§ä»£ç ä¸€è‡´ï¼Œç”¨closeåšåˆ†æ¯ï¼‰\n",
    "        df['amplitude'] = (df['high'] - df['low']) / df['close'].replace(0, 0.0001)\n",
    "        log_msg(\"âœ… æŒ¯å¹…è®¡ç®—å®Œæˆ\")\n",
    "        \n",
    "        # 3. ç­›é€‰å­—æ®µå¹¶ä¿å­˜ï¼ˆä»…ä¿ç•™å®éªŒæ‰€éœ€ï¼‰\n",
    "        log_msg(\"ç­›é€‰å­—æ®µå¹¶ä¿å­˜...\")\n",
    "        keep_cols = [\n",
    "            # åŸºç¡€å­—æ®µ\n",
    "            'stock_code', 'date', 'close', 'open', 'volume', 'high', 'low', 'amplitude',\n",
    "            # è¶‹åŠ¿ä¸ç«ä»·\n",
    "            'consecutive_up_days', 'auction_rise_ratio', 'auction_volume_ratio', 'is_high_open',\n",
    "            # å‡çº¿ä¸MACD\n",
    "            'ma5', 'ma20', 'macd_line', 'signal_line', 'macd_hist',\n",
    "            # é‡èƒ½ä¸å›è°ƒ\n",
    "            'volume_ratio_5d', 'high_30d', 'high_date_30d', 'pullback_ratio', 'pullback_days',\n",
    "            # æ”¯æ’‘ä¸è¶…ä¹°è¶…å–\n",
    "            'bollinger_lower', 'rsi14'\n",
    "        ]\n",
    "        df_final = df[keep_cols].copy()\n",
    "        # æœ€ç»ˆè¿‡æ»¤å…³é”®æŒ‡æ ‡ï¼ˆç¡®ä¿é€‰è‚¡å¯ç”¨ï¼‰\n",
    "        df_final = df_final.dropna(subset=['close', 'ma5', 'ma20', 'high_30d', 'rsi14'])\n",
    "        log_msg(f\"âœ… æœ€ç»ˆFactortableï¼š{len(df_final)}æ¡è®°å½•ï¼Œ{df_final['stock_code'].nunique()}åªè‚¡ç¥¨\")\n",
    "        \n",
    "        # ä¿å­˜åˆ°æœ¬åœ°\n",
    "        df_final.to_parquet(CONFIG[\"factortable_output_path\"], index=False)\n",
    "        df_final.sample(5, random_state=42).to_csv(CONFIG[\"sample_output_path\"], index=False, encoding='utf-8-sig')\n",
    "        log_msg(f\"âœ… ä¿å­˜å®Œæˆï¼š\")\n",
    "        log_msg(f\"ğŸ“ ä¸»æ–‡ä»¶ï¼š{CONFIG['factortable_output_path']}\")\n",
    "        log_msg(f\"ğŸ“ æ ·æœ¬æ–‡ä»¶ï¼š{CONFIG['sample_output_path']}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        log_msg(f\"âŒ è®¡ç®—å¤±è´¥ï¼š{str(e)}\")\n",
    "        raise\n",
    "\n",
    "# --------------------------\n",
    "# æ‰§è¡Œå…¥å£\n",
    "# --------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    calculate_factortable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade12f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xiaoyao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
