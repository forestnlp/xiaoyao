{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a696cf2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jay\\AppData\\Local\\Temp\\ipykernel_26828\\2189716409.py:102: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df['vwap'] = df.groupby('stock_code', group_keys=False).apply(calculate_vwap)\n",
      "C:\\Users\\jay\\AppData\\Local\\Temp\\ipykernel_26828\\2189716409.py:147: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df['volatility'] = df.groupby('stock_code', group_keys=False).apply(\n",
      "C:\\Users\\jay\\AppData\\Local\\Temp\\ipykernel_26828\\2189716409.py:222: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df['obv'] = df.groupby('stock_code', group_keys=False).apply(calculate_obv)\n",
      "C:\\Users\\jay\\AppData\\Local\\Temp\\ipykernel_26828\\2189716409.py:264: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  adx_results = df.groupby('stock_code', group_keys=False).apply(calculate_adx)\n",
      "C:\\Users\\jay\\AppData\\Local\\Temp\\ipykernel_26828\\2189716409.py:288: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df['atr'] = df.groupby('stock_code', group_keys=False).apply(calculate_atr)\n",
      "C:\\Users\\jay\\AppData\\Local\\Temp\\ipykernel_26828\\2189716409.py:297: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df['rolling_max_drawdown_20d'] = df.groupby('stock_code', group_keys=False).apply(\n",
      "C:\\Users\\jay\\AppData\\Local\\Temp\\ipykernel_26828\\2189716409.py:317: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df['price_volume_divergence'] = df.groupby('stock_code', group_keys=False).apply(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot compare types 'ndarray(dtype=object)' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 324\u001b[0m\n\u001b[0;32m    317\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice_volume_divergence\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstock_code\u001b[39m\u001b[38;5;124m'\u001b[39m, group_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m    318\u001b[0m     calculate_price_volume_divergence\n\u001b[0;32m    319\u001b[0m )\n\u001b[0;32m    321\u001b[0m \u001b[38;5;66;03m# --------------------------\u001b[39;00m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;66;03m# 异常值处理：规避无穷值/负无穷值\u001b[39;00m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;66;03m# --------------------------\u001b[39;00m\n\u001b[1;32m--> 324\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minf\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;66;03m# 将df写入到parquet文件里\u001b[39;00m\n\u001b[0;32m    327\u001b[0m df\u001b[38;5;241m.\u001b[39mto_parquet(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mworkspace\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mxiaoyao\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mfactortable.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32md:\\sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\pandas\\core\\generic.py:8118\u001b[0m, in \u001b[0;36mNDFrame.replace\u001b[1;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[0;32m   8113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(to_replace) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(value):\n\u001b[0;32m   8114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   8115\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReplacement lists must match in length. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   8116\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(to_replace)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(value)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   8117\u001b[0m         )\n\u001b[1;32m-> 8118\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace_list\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   8119\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mto_replace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdest_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8121\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8123\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   8125\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m to_replace \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   8126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[0;32m   8127\u001b[0m         is_re_compilable(regex)\n\u001b[0;32m   8128\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m is_list_like(regex)\n\u001b[0;32m   8129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m is_dict_like(regex)\n\u001b[0;32m   8130\u001b[0m     ):\n",
      "File \u001b[1;32md:\\sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\pandas\\core\\internals\\base.py:278\u001b[0m, in \u001b[0;36mDataManager.replace_list\u001b[1;34m(self, src_list, dest_list, inplace, regex)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"do a list replace\"\"\"\u001b[39;00m\n\u001b[0;32m    276\u001b[0m inplace \u001b[38;5;241m=\u001b[39m validate_bool_kwarg(inplace, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minplace\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 278\u001b[0m bm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_with_block\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreplace_list\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43msrc_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdest_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdest_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mregex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43malready_warned\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_AlreadyWarned\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m bm\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bm\n",
      "File \u001b[1;32md:\\sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32md:\\sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:1160\u001b[0m, in \u001b[0;36mBlock.replace_list\u001b[1;34m(self, src_list, dest_list, inplace, regex, using_cow, already_warned)\u001b[0m\n\u001b[0;32m   1157\u001b[0m         already_warned\u001b[38;5;241m.\u001b[39mwarned_already \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1159\u001b[0m opt \u001b[38;5;241m=\u001b[39m get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfuture.no_silent_downcasting\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1160\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, ((src, dest), mask) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(pairs, masks)):\n\u001b[0;32m   1161\u001b[0m     convert \u001b[38;5;241m=\u001b[39m i \u001b[38;5;241m==\u001b[39m src_len  \u001b[38;5;66;03m# only convert once at the end\u001b[39;00m\n\u001b[0;32m   1162\u001b[0m     new_rb: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32md:\\sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:1123\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_string_dtype(values\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m   1116\u001b[0m     \u001b[38;5;66;03m# Calculate the mask once, prior to the call of comp\u001b[39;00m\n\u001b[0;32m   1117\u001b[0m     \u001b[38;5;66;03m# in order to avoid repeating the same computations\u001b[39;00m\n\u001b[0;32m   1118\u001b[0m     na_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39misna(values)\n\u001b[0;32m   1119\u001b[0m     masks: Iterable[npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mbool_]] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1120\u001b[0m         extract_bool_array(\n\u001b[0;32m   1121\u001b[0m             cast(\n\u001b[0;32m   1122\u001b[0m                 ArrayLike,\n\u001b[1;32m-> 1123\u001b[0m                 \u001b[43mcompare_or_regex_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1124\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_mask\u001b[49m\n\u001b[0;32m   1125\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   1126\u001b[0m             )\n\u001b[0;32m   1127\u001b[0m         )\n\u001b[0;32m   1128\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m pairs\n\u001b[0;32m   1129\u001b[0m     )\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;66;03m# GH#38086 faster if we know we dont need to check for regex\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m     masks \u001b[38;5;241m=\u001b[39m (missing\u001b[38;5;241m.\u001b[39mmask_missing(values, s[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m pairs)\n",
      "File \u001b[1;32md:\\sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\pandas\\core\\array_algos\\replace.py:108\u001b[0m, in \u001b[0;36mcompare_or_regex_search\u001b[1;34m(a, b, regex, mask)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    106\u001b[0m     result \u001b[38;5;241m=\u001b[39m op(a)\n\u001b[1;32m--> 108\u001b[0m \u001b[43m_check_comparison_types\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\pandas\\core\\array_algos\\replace.py:80\u001b[0m, in \u001b[0;36mcompare_or_regex_search.<locals>._check_comparison_types\u001b[1;34m(result, a, b)\u001b[0m\n\u001b[0;32m     76\u001b[0m type_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtype\u001b[39m(a)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mtype\u001b[39m(b)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m]\n\u001b[0;32m     78\u001b[0m type_names[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndarray(dtype=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ma\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 80\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot compare types \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(type_names[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(type_names[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     82\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot compare types 'ndarray(dtype=object)' and 'float'"
     ]
    }
   ],
   "source": [
    "# 从Jupyter Notebook转换而来的Python代码\n",
    "# 原始文件：D:\\workspace\\xiaoyao\\works\\preprocessor\\factors.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 读取widetable.parquet文件\n",
    "file_path = r'D:\\workspace\\xiaoyao\\data\\widetable.parquet'\n",
    "df = pd.read_parquet(file_path)\n",
    "\n",
    "# --------------------------\n",
    "# 基础准备：数据排序与初始化\n",
    "# --------------------------\n",
    "df = df.sort_values(by=['stock_code', 'date']).reset_index(drop=True)\n",
    "\n",
    "# --------------------------\n",
    "# 1. 趋势类指标：移动平均线（MA）\n",
    "# --------------------------\n",
    "df['ma5'] = df.groupby('stock_code')['close'].transform(\n",
    "    lambda x: x.rolling(window=5, min_periods=1).mean()\n",
    ")\n",
    "df['ma10'] = df.groupby('stock_code')['close'].transform(\n",
    "    lambda x: x.rolling(window=10, min_periods=1).mean()\n",
    ")\n",
    "df['ma20'] = df.groupby('stock_code')['close'].transform(\n",
    "    lambda x: x.rolling(window=20, min_periods=1).mean()\n",
    ")\n",
    "df['ma60'] = df.groupby('stock_code')['close'].transform(\n",
    "    lambda x: x.rolling(window=60, min_periods=1).mean()\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# 2. 震荡类指标：相对强弱指数（RSI）\n",
    "# --------------------------\n",
    "def calculate_rsi(series, window=14):\n",
    "    delta = series.diff()\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "    avg_gain = gain.rolling(window=window, min_periods=1).mean()\n",
    "    avg_loss = loss.rolling(window=window, min_periods=1).mean()\n",
    "    avg_loss = avg_loss.replace(0, 0.0001)\n",
    "    rs = avg_gain / avg_loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "df['rsi14'] = df.groupby('stock_code')['close'].transform(\n",
    "    lambda x: calculate_rsi(x, window=14)\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# 3. 趋势类指标：MACD\n",
    "# --------------------------\n",
    "def calculate_macd(series, fast_period=12, slow_period=26, signal_period=9):\n",
    "    ema_fast = series.ewm(span=fast_period, adjust=False).mean()\n",
    "    ema_slow = series.ewm(span=slow_period, adjust=False).mean()\n",
    "    macd_line = ema_fast - ema_slow\n",
    "    signal_line = macd_line.ewm(span=signal_period, adjust=False).mean()\n",
    "    macd_hist = macd_line - signal_line\n",
    "    return pd.DataFrame({\n",
    "        'macd_line': macd_line,\n",
    "        'signal_line': signal_line,\n",
    "        'macd_hist': macd_hist\n",
    "    })\n",
    "\n",
    "macd_results = df.groupby('stock_code')['close'].apply(calculate_macd)\n",
    "df = df.join(macd_results.reset_index(level=0, drop=True), rsuffix='_calc')\n",
    "\n",
    "# --------------------------\n",
    "# 4. 波动类指标：布林带\n",
    "# --------------------------\n",
    "def calculate_bollinger_bands(series, window=20, num_std=2):\n",
    "    rolling_mean = series.rolling(window=window, min_periods=1).mean()\n",
    "    rolling_std = series.rolling(window=window, min_periods=1).std().replace(0, 0.0001)\n",
    "    upper_band = rolling_mean + (rolling_std * num_std)\n",
    "    lower_band = rolling_mean - (rolling_std * num_std)\n",
    "    return pd.DataFrame({\n",
    "        'bollinger_mid': rolling_mean,\n",
    "        'bollinger_upper': upper_band,\n",
    "        'bollinger_lower': lower_band\n",
    "    })\n",
    "\n",
    "bollinger_results = df.groupby('stock_code')['close'].apply(calculate_bollinger_bands)\n",
    "df = df.join(bollinger_results.reset_index(level=0, drop=True), rsuffix='_calc')\n",
    "\n",
    "# --------------------------\n",
    "# 5. 量价类指标：VWAP（修改1：添加include_groups=False）\n",
    "# --------------------------\n",
    "def calculate_vwap(group):\n",
    "    volume = group['volume'].replace(0, 0.0001)\n",
    "    vwap = (group['money'] / volume).cumsum() / np.arange(1, len(group) + 1)\n",
    "    return vwap\n",
    "\n",
    "# 关键修改：添加include_groups=False\n",
    "df['vwap'] = df.groupby('stock_code', group_keys=False, include_groups=False).apply(calculate_vwap)\n",
    "\n",
    "# --------------------------\n",
    "# 6. 趋势类指标：Momentum\n",
    "# --------------------------\n",
    "def calculate_momentum(series, period=14):\n",
    "    return series - series.shift(period)\n",
    "\n",
    "df['momentum14'] = df.groupby('stock_code')['close'].transform(\n",
    "    lambda x: calculate_momentum(x, period=14)\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# 7. 量能类指标：成交量对比\n",
    "# --------------------------\n",
    "df['volume_ratio_vs_yesterday'] = df.groupby('stock_code')['volume'].transform(\n",
    "    lambda x: x / x.shift(1).replace(0, 0.0001)\n",
    ")\n",
    "df['volume_ratio_vs_5d_avg'] = df.groupby('stock_code')['volume'].transform(\n",
    "    lambda x: x / x.rolling(window=5, min_periods=1).mean().shift(1).replace(0, 0.0001)\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# 8. 量能类指标：竞价量对比\n",
    "# --------------------------\n",
    "df['auc_volume_ratio_vs_yesterday'] = df.groupby('stock_code')['auc_volume'].transform(\n",
    "    lambda x: x / x.shift(1).replace(0, 0.0001)\n",
    ")\n",
    "df['auc_volume_ratio_vs_5d_avg'] = df.groupby('stock_code')['auc_volume'].transform(\n",
    "    lambda x: x / x.rolling(window=5, min_periods=1).mean().shift(1).replace(0, 0.0001)\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# 9. 波动类指标：波动率（修改2：添加include_groups=False）\n",
    "# --------------------------\n",
    "def calculate_volatility(series, window=20):\n",
    "    open_price = series['open'].replace(0, 0.0001)\n",
    "    daily_range = (series['high'] - series['low']) / open_price\n",
    "    return daily_range.rolling(window=window, min_periods=1).mean()\n",
    "\n",
    "# 关键修改：添加include_groups=False\n",
    "df['volatility'] = df.groupby('stock_code', group_keys=False, include_groups=False).apply(\n",
    "    lambda x: calculate_volatility(x, window=20)\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# 10. 盘口类指标：五档盘口量比\n",
    "# --------------------------\n",
    "df['buy_total'] = df['b1_v'] + df['b2_v'] + df['b3_v'] + df['b4_v'] + df['b5_v']\n",
    "df['sell_total'] = df['a1_v'] + df['a2_v'] + df['a3_v'] + df['a4_v'] + df['a5_v']\n",
    "df['order_book_volume_ratio'] = df.apply(\n",
    "    lambda row: row['buy_total'] / row['sell_total'] if row['sell_total'] != 0 else np.nan,\n",
    "    axis=1\n",
    ")\n",
    "df['obv_ratio_vs_yesterday'] = df.groupby('stock_code')['order_book_volume_ratio'].transform(\n",
    "    lambda x: x / x.shift(1).replace(0, np.nan)\n",
    ")\n",
    "df['obv_ratio_vs_5d_avg'] = df.groupby('stock_code')['order_book_volume_ratio'].transform(\n",
    "    lambda x: x / x.rolling(window=5, min_periods=1).mean().shift(1).replace(0, np.nan)\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# 11. 活跃度指标\n",
    "# --------------------------\n",
    "df['turnover_ratio_vs_yesterday'] = df.groupby('stock_code')['turnover_ratio'].transform(\n",
    "    lambda x: x / x.shift(1).replace(0, np.nan)\n",
    ")\n",
    "df['turnover_ratio_vs_5d_avg'] = df.groupby('stock_code')['turnover_ratio'].transform(\n",
    "    lambda x: x / x.rolling(window=5, min_periods=1).mean().shift(1).replace(0, np.nan)\n",
    ")\n",
    "df['money_ratio_vs_yesterday'] = df.groupby('stock_code')['money'].transform(\n",
    "    lambda x: x / x.shift(1).replace(0, 0.0001)\n",
    ")\n",
    "df['money_ratio_vs_5d_avg'] = df.groupby('stock_code')['money'].transform(\n",
    "    lambda x: x / x.rolling(window=5, min_periods=1).mean().shift(1).replace(0, 0.0001)\n",
    ")\n",
    "df['amplitude'] = (df['high'] - df['low']) / df['pre_close'] * 100\n",
    "df['amplitude_vs_yesterday'] = df.groupby('stock_code')['amplitude'].transform(\n",
    "    lambda x: x / x.shift(1).replace(0, np.nan)\n",
    ")\n",
    "df['amplitude_vs_5d_avg'] = df.groupby('stock_code')['amplitude'].transform(\n",
    "    lambda x: x / x.rolling(window=5, min_periods=1).mean().shift(1).replace(0, np.nan)\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# 12. 新增：资金流向类指标（修改3：添加include_groups=False）\n",
    "# --------------------------\n",
    "def calculate_obv(group):\n",
    "    obv = pd.Series(0.0, index=group.index)\n",
    "    for i in range(1, len(group)):\n",
    "        if group['close'].iloc[i] > group['close'].iloc[i-1]:\n",
    "            obv.iloc[i] = obv.iloc[i-1] + group['volume'].iloc[i]\n",
    "        elif group['close'].iloc[i] < group['close'].iloc[i-1]:\n",
    "            obv.iloc[i] = obv.iloc[i-1] - group['volume'].iloc[i]\n",
    "        else:\n",
    "            obv.iloc[i] = obv.iloc[i-1]\n",
    "    return obv\n",
    "\n",
    "# 关键修改：添加include_groups=False\n",
    "df['obv'] = df.groupby('stock_code', group_keys=False, include_groups=False).apply(calculate_obv)\n",
    "df['main_force_net_flow'] = df['buy_total'] - df['sell_total']\n",
    "\n",
    "# --------------------------\n",
    "# 13. 新增：趋势强度类指标（修改4：添加include_groups=False）\n",
    "# --------------------------\n",
    "def calculate_adx(group, window=14):\n",
    "    high = group['high']\n",
    "    low = group['low']\n",
    "    close = group['close']\n",
    "    prev_close = close.shift(1)\n",
    "    plus_dm = high - high.shift(1)\n",
    "    minus_dm = low.shift(1) - low\n",
    "    plus_dm = plus_dm.where((plus_dm > minus_dm) & (plus_dm > 0), 0)\n",
    "    minus_dm = minus_dm.where((minus_dm > plus_dm) & (minus_dm > 0), 0)\n",
    "    tr1 = high - low\n",
    "    tr2 = abs(high - prev_close)\n",
    "    tr3 = abs(low - prev_close)\n",
    "    tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
    "    atr = tr.rolling(window=window, min_periods=1).mean()\n",
    "    plus_di = (plus_dm.rolling(window=window, min_periods=1).mean() / atr) * 100\n",
    "    minus_di = (minus_dm.rolling(window=window, min_periods=1).mean() / atr) * 100\n",
    "    dx = (abs(plus_di - minus_di) / (plus_di + minus_di.replace(0, 0.0001))) * 100\n",
    "    adx = dx.rolling(window=window, min_periods=1).mean()\n",
    "    return pd.DataFrame({\n",
    "        'adx': adx,\n",
    "        'plus_di': plus_di,\n",
    "        'minus_di': minus_di\n",
    "    })\n",
    "\n",
    "# 关键修改：添加include_groups=False\n",
    "adx_results = df.groupby('stock_code', group_keys=False, include_groups=False).apply(calculate_adx)\n",
    "df = df.join(adx_results)\n",
    "\n",
    "df['ma20_slope'] = df.groupby('stock_code')['ma20'].transform(\n",
    "    lambda x: (x - x.shift(1)) / x.shift(1).replace(0, 0.0001) * 100\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# 14. 新增：波动风险类指标（修改5-6：添加include_groups=False）\n",
    "# --------------------------\n",
    "def calculate_atr(group, window=14):\n",
    "    high = group['high']\n",
    "    low = group['low']\n",
    "    prev_close = group['pre_close']\n",
    "    tr1 = high - low\n",
    "    tr2 = abs(high - prev_close)\n",
    "    tr3 = abs(low - prev_close)\n",
    "    tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
    "    return tr.rolling(window=window, min_periods=1).mean()\n",
    "\n",
    "# 关键修改：添加include_groups=False\n",
    "df['atr'] = df.groupby('stock_code', group_keys=False, include_groups=False).apply(calculate_atr)\n",
    "\n",
    "def calculate_rolling_max_drawdown(group, window=20):\n",
    "    rolling_high = group['close'].rolling(window=window, min_periods=1).max()\n",
    "    drawdown = (group['close'] - rolling_high) / rolling_high * 100\n",
    "    return drawdown\n",
    "\n",
    "# 关键修改：添加include_groups=False\n",
    "df['rolling_max_drawdown_20d'] = df.groupby('stock_code', group_keys=False, include_groups=False).apply(\n",
    "    calculate_rolling_max_drawdown\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# 15. 新增：量价结构类指标（修改7：添加include_groups=False）\n",
    "# --------------------------\n",
    "df['volume_ratio'] = df.groupby('stock_code')['volume'].transform(\n",
    "    lambda x: x / x.rolling(window=5, min_periods=1).mean().replace(0, 0.0001)\n",
    ")\n",
    "\n",
    "def calculate_price_volume_divergence(group, period=5):\n",
    "    price_gain = (group['close'] / group['close'].shift(period) - 1) * 100\n",
    "    volume_gain = (group['volume'] / group['volume'].shift(period).replace(0, 0.0001) - 1) * 100\n",
    "    return price_gain - volume_gain\n",
    "\n",
    "# 关键修改：添加include_groups=False\n",
    "df['price_volume_divergence'] = df.groupby('stock_code', group_keys=False, include_groups=False).apply(\n",
    "    calculate_price_volume_divergence\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# 异常值处理（修改8：仅对数值型列执行replace，跳过object列）\n",
    "# --------------------------\n",
    "# 1. 获取所有数值型列（排除object类型，如concept_name_list）\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "# 2. 仅对数值型列替换异常值\n",
    "df[numeric_cols] = df[numeric_cols].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# --------------------------\n",
    "# 结果保存与样本导出\n",
    "# --------------------------\n",
    "df.to_parquet(r'D:\\workspace\\xiaoyao\\data\\factortable.parquet', index=False)\n",
    "# 读取并采样（固定random_state确保可复现）\n",
    "df_sample = pd.read_parquet(r'D:\\workspace\\xiaoyao\\data\\factortable.parquet')\n",
    "df_sample.sample(5, random_state=42).to_csv('./sample.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xiaoyao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
