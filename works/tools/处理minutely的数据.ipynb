{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fdbc7046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 删除D:\\workspace\\xiaoyao\\data\\stock_minutely_price下的所有文件和子目录\n",
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# # 定义路径\n",
    "# path = r\"D:\\workspace\\xiaoyao\\data\\stock_minutely_price\"\n",
    "\n",
    "# # 检查路径是否存在\n",
    "# if os.path.exists(path):\n",
    "#     # 删除所有文件和子目录\n",
    "#     shutil.rmtree(path)\n",
    "#     print(f\"已删除路径: {path}\")\n",
    "# else:\n",
    "#     print(f\"路径不存在: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33deb43d",
   "metadata": {},
   "source": [
    "# 统计数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86f1ac11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5449\n"
     ]
    }
   ],
   "source": [
    "# 统计D:\\workspace\\xiaoyao\\data\\stock_minutely_price目录下的子目录数量\n",
    "import os\n",
    "\n",
    "dir_path = r'D:\\workspace\\xiaoyao\\data\\stock_minutely_price'\n",
    "sub_dir_count = len(os.listdir(dir_path))\n",
    "print(sub_dir_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499fe57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 开始读取分钟数据目录：D:\\workspace\\xiaoyao\\data\\stock_minutely_price\n",
      "✅ 处理完成：000001.XSHE（193天数据）\n",
      "✅ 处理完成：000002.XSHE（193天数据）\n",
      "✅ 处理完成：000004.XSHE（193天数据）\n",
      "✅ 处理完成：000005.XSHE（187天数据）\n",
      "✅ 处理完成：000006.XSHE（193天数据）\n",
      "✅ 处理完成：000007.XSHE（193天数据）\n",
      "✅ 处理完成：000008.XSHE（193天数据）\n",
      "✅ 处理完成：000009.XSHE（193天数据）\n",
      "✅ 处理完成：000010.XSHE（193天数据）\n",
      "✅ 处理完成：000011.XSHE（193天数据）\n",
      "✅ 处理完成：000012.XSHE（193天数据）\n",
      "✅ 处理完成：000014.XSHE（193天数据）\n",
      "✅ 处理完成：000016.XSHE（193天数据）\n",
      "✅ 处理完成：000017.XSHE（193天数据）\n",
      "✅ 处理完成：000018.XSHE（187天数据）\n",
      "✅ 处理完成：000019.XSHE（193天数据）\n",
      "✅ 处理完成：000020.XSHE（193天数据）\n",
      "✅ 处理完成：000021.XSHE（193天数据）\n",
      "✅ 处理完成：000022.XSHE（187天数据）\n",
      "✅ 处理完成：000023.XSHE（187天数据）\n",
      "✅ 处理完成：000024.XSHE（187天数据）\n",
      "✅ 处理完成：000025.XSHE（193天数据）\n",
      "✅ 处理完成：000026.XSHE（193天数据）\n",
      "✅ 处理完成：000027.XSHE（193天数据）\n",
      "✅ 处理完成：000028.XSHE（193天数据）\n",
      "✅ 处理完成：000029.XSHE（193天数据）\n",
      "✅ 处理完成：000030.XSHE（193天数据）\n",
      "✅ 处理完成：000031.XSHE（193天数据）\n",
      "✅ 处理完成：000032.XSHE（193天数据）\n",
      "✅ 处理完成：000033.XSHE（187天数据）\n",
      "✅ 处理完成：000034.XSHE（193天数据）\n",
      "✅ 处理完成：000035.XSHE（193天数据）\n",
      "✅ 处理完成：000036.XSHE（193天数据）\n",
      "✅ 处理完成：000037.XSHE（193天数据）\n",
      "✅ 处理完成：000038.XSHE（187天数据）\n",
      "✅ 处理完成：000039.XSHE（193天数据）\n",
      "✅ 处理完成：000040.XSHE（187天数据）\n",
      "✅ 处理完成：000042.XSHE（193天数据）\n",
      "✅ 处理完成：000043.XSHE（187天数据）\n",
      "✅ 处理完成：000045.XSHE（193天数据）\n",
      "✅ 处理完成：000046.XSHE（187天数据）\n",
      "✅ 处理完成：000048.XSHE（193天数据）\n",
      "✅ 处理完成：000049.XSHE（193天数据）\n",
      "✅ 处理完成：000050.XSHE（193天数据）\n",
      "✅ 处理完成：000055.XSHE（193天数据）\n",
      "✅ 处理完成：000056.XSHE（193天数据）\n",
      "✅ 处理完成：000058.XSHE（193天数据）\n",
      "✅ 处理完成：000059.XSHE（193天数据）\n",
      "✅ 处理完成：000060.XSHE（193天数据）\n",
      "✅ 处理完成：000061.XSHE（193天数据）\n",
      "✅ 处理完成：000062.XSHE（193天数据）\n",
      "✅ 处理完成：000063.XSHE（193天数据）\n",
      "✅ 处理完成：000065.XSHE（193天数据）\n",
      "✅ 处理完成：000066.XSHE（193天数据）\n",
      "✅ 处理完成：000068.XSHE（193天数据）\n",
      "✅ 处理完成：000069.XSHE（193天数据）\n",
      "✅ 处理完成：000070.XSHE（193天数据）\n",
      "✅ 处理完成：000078.XSHE（193天数据）\n",
      "✅ 处理完成：000088.XSHE（193天数据）\n",
      "✅ 处理完成：000089.XSHE（193天数据）\n",
      "✅ 处理完成：000090.XSHE（193天数据）\n",
      "✅ 处理完成：000096.XSHE（193天数据）\n",
      "✅ 处理完成：000099.XSHE（193天数据）\n",
      "✅ 处理完成：000100.XSHE（193天数据）\n",
      "✅ 处理完成：000150.XSHE（187天数据）\n",
      "✅ 处理完成：000151.XSHE（193天数据）\n",
      "✅ 处理完成：000153.XSHE（193天数据）\n",
      "✅ 处理完成：000155.XSHE（193天数据）\n",
      "✅ 处理完成：000156.XSHE（193天数据）\n",
      "✅ 处理完成：000157.XSHE（193天数据）\n",
      "✅ 处理完成：000158.XSHE（193天数据）\n",
      "✅ 处理完成：000159.XSHE（193天数据）\n",
      "✅ 处理完成：000166.XSHE（193天数据）\n",
      "✅ 处理完成：000301.XSHE（193天数据）\n",
      "✅ 处理完成：000333.XSHE（193天数据）\n",
      "✅ 处理完成：000338.XSHE（193天数据）\n",
      "✅ 处理完成：000400.XSHE（193天数据）\n",
      "✅ 处理完成：000401.XSHE（193天数据）\n",
      "✅ 处理完成：000402.XSHE（193天数据）\n",
      "✅ 处理完成：000403.XSHE（193天数据）\n",
      "✅ 处理完成：000404.XSHE（193天数据）\n",
      "✅ 处理完成：000406.XSHE（187天数据）\n",
      "✅ 处理完成：000407.XSHE（193天数据）\n",
      "✅ 处理完成：000408.XSHE（193天数据）\n",
      "✅ 处理完成：000409.XSHE（193天数据）\n",
      "✅ 处理完成：000410.XSHE（193天数据）\n",
      "✅ 处理完成：000411.XSHE（193天数据）\n",
      "✅ 处理完成：000413.XSHE（187天数据）\n",
      "✅ 处理完成：000415.XSHE（193天数据）\n",
      "✅ 处理完成：000416.XSHE（187天数据）\n",
      "✅ 处理完成：000417.XSHE（193天数据）\n",
      "✅ 处理完成：000418.XSHE（187天数据）\n",
      "✅ 处理完成：000419.XSHE（193天数据）\n",
      "✅ 处理完成：000420.XSHE（193天数据）\n",
      "✅ 处理完成：000421.XSHE（193天数据）\n",
      "✅ 处理完成：000422.XSHE（193天数据）\n",
      "✅ 处理完成：000423.XSHE（193天数据）\n",
      "✅ 处理完成：000425.XSHE（193天数据）\n",
      "✅ 处理完成：000426.XSHE（193天数据）\n",
      "✅ 处理完成：000428.XSHE（193天数据）\n",
      "✅ 处理完成：000429.XSHE（193天数据）\n",
      "✅ 处理完成：000430.XSHE（193天数据）\n",
      "✅ 处理完成：000488.XSHE（193天数据）\n",
      "✅ 处理完成：000498.XSHE（193天数据）\n",
      "✅ 处理完成：000501.XSHE（193天数据）\n",
      "✅ 处理完成：000502.XSHE（187天数据）\n",
      "✅ 处理完成：000503.XSHE（193天数据）\n",
      "✅ 处理完成：000504.XSHE（193天数据）\n",
      "✅ 处理完成：000505.XSHE（193天数据）\n",
      "✅ 处理完成：000506.XSHE（193天数据）\n",
      "✅ 处理完成：000507.XSHE（193天数据）\n",
      "✅ 处理完成：000509.XSHE（193天数据）\n",
      "✅ 处理完成：000510.XSHE（193天数据）\n",
      "✅ 处理完成：000511.XSHE（187天数据）\n",
      "✅ 处理完成：000513.XSHE（193天数据）\n",
      "✅ 处理完成：000514.XSHE（193天数据）\n",
      "✅ 处理完成：000515.XSHE（187天数据）\n",
      "✅ 处理完成：000516.XSHE（193天数据）\n",
      "✅ 处理完成：000517.XSHE（193天数据）\n",
      "✅ 处理完成：000518.XSHE（193天数据）\n",
      "✅ 处理完成：000519.XSHE（193天数据）\n",
      "✅ 处理完成：000520.XSHE（193天数据）\n",
      "✅ 处理完成：000521.XSHE（193天数据）\n",
      "✅ 处理完成：000522.XSHE（187天数据）\n",
      "✅ 处理完成：000523.XSHE（193天数据）\n",
      "✅ 处理完成：000524.XSHE（193天数据）\n",
      "✅ 处理完成：000525.XSHE（193天数据）\n",
      "✅ 处理完成：000526.XSHE（193天数据）\n",
      "✅ 处理完成：000527.XSHE（187天数据）\n",
      "✅ 处理完成：000528.XSHE（193天数据）\n",
      "✅ 处理完成：000529.XSHE（193天数据）\n",
      "✅ 处理完成：000530.XSHE（193天数据）\n",
      "✅ 处理完成：000531.XSHE（193天数据）\n",
      "✅ 处理完成：000532.XSHE（193天数据）\n",
      "✅ 处理完成：000533.XSHE（193天数据）\n",
      "✅ 处理完成：000534.XSHE（193天数据）\n",
      "✅ 处理完成：000535.XSHE（187天数据）\n",
      "✅ 处理完成：000536.XSHE（193天数据）\n",
      "✅ 处理完成：000537.XSHE（193天数据）\n",
      "✅ 处理完成：000538.XSHE（193天数据）\n",
      "✅ 处理完成：000539.XSHE（193天数据）\n",
      "✅ 处理完成：000540.XSHE（187天数据）\n",
      "✅ 处理完成：000541.XSHE（193天数据）\n",
      "✅ 处理完成：000543.XSHE（193天数据）\n",
      "✅ 处理完成：000544.XSHE（193天数据）\n",
      "✅ 处理完成：000545.XSHE（193天数据）\n",
      "✅ 处理完成：000546.XSHE（193天数据）\n",
      "✅ 处理完成：000547.XSHE（193天数据）\n",
      "✅ 处理完成：000548.XSHE（193天数据）\n",
      "✅ 处理完成：000549.XSHE（187天数据）\n",
      "✅ 处理完成：000550.XSHE（193天数据）\n",
      "✅ 处理完成：000551.XSHE（193天数据）\n",
      "✅ 处理完成：000552.XSHE（193天数据）\n",
      "✅ 处理完成：000553.XSHE（193天数据）\n",
      "✅ 处理完成：000554.XSHE（193天数据）\n",
      "✅ 处理完成：000555.XSHE（193天数据）\n",
      "✅ 处理完成：000557.XSHE（193天数据）\n",
      "✅ 处理完成：000558.XSHE（193天数据）\n",
      "✅ 处理完成：000559.XSHE（193天数据）\n",
      "✅ 处理完成：000560.XSHE（193天数据）\n",
      "✅ 处理完成：000561.XSHE（193天数据）\n",
      "✅ 处理完成：000562.XSHE（187天数据）\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 106\u001b[0m\n\u001b[0;32m    102\u001b[0m DAILY_DATA_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mworkspace\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mxiaoyao\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mstock_daily_price.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# 日线数据路径\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;66;03m# 1. 生成minutely_data_count.csv\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m     minutely_count_df \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_minutely_count_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMINUTELY_ROOT_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMINUTELY_COUNT_CSV\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;66;03m# 2. 比对股票代码差异\u001b[39;00m\n\u001b[0;32m    109\u001b[0m     compare_stock_code_diff(minutely_count_df, DAILY_DATA_PATH)\n",
      "Cell \u001b[1;32mIn[2], line 28\u001b[0m, in \u001b[0;36mgenerate_minutely_count_csv\u001b[1;34m(root_dir, output_csv)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m# 仅读取date列，统计日期分布\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(data_path, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m---> 28\u001b[0m     df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrftime\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm-\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m# 按日期统计数据条数（单股票单日）\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     daily_count \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;241m.\u001b[39mreset_index(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_count\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\pandas\\core\\accessor.py:112\u001b[0m, in \u001b[0;36mPandasDelegate._add_delegate_accessors.<locals>._create_delegator_method.<locals>.f\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mf\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_delegate_method(name, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\pandas\\core\\indexes\\accessors.py:132\u001b[0m, in \u001b[0;36mProperties._delegate_method\u001b[1;34m(self, name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_values()\n\u001b[0;32m    131\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(values, name)\n\u001b[1;32m--> 132\u001b[0m result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(result):\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\pandas\\core\\indexes\\datetimes.py:279\u001b[0m, in \u001b[0;36mDatetimeIndex.strftime\u001b[1;34m(self, date_format)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;129m@doc\u001b[39m(DatetimeArray\u001b[38;5;241m.\u001b[39mstrftime)\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstrftime\u001b[39m(\u001b[38;5;28mself\u001b[39m, date_format) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[0;32m    278\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mstrftime(date_format)\n\u001b[1;32m--> 279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mIndex\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\pandas\\core\\indexes\\base.py:485\u001b[0m, in \u001b[0;36mIndex.__new__\u001b[1;34m(cls, data, dtype, copy, name, tupleize_cols)\u001b[0m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__new__\u001b[39m(\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m    477\u001b[0m     data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    481\u001b[0m     tupleize_cols: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    482\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrange\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RangeIndex\n\u001b[1;32m--> 485\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_extract_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    487\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    488\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m pandas_dtype(dtype)\n",
      "File \u001b[1;32md:\\sdk\\Anaconda3\\envs\\xiaoyao\\lib\\site-packages\\pandas\\core\\indexes\\base.py:7764\u001b[0m, in \u001b[0;36mmaybe_extract_name\u001b[1;34m(name, obj, cls)\u001b[0m\n\u001b[0;32m   7761\u001b[0m     name \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m   7763\u001b[0m \u001b[38;5;66;03m# GH#29069\u001b[39;00m\n\u001b[1;32m-> 7764\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mis_hashable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   7765\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.name must be a hashable type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7767\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m name\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def generate_minutely_count_csv(root_dir: str, output_csv: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    读取stock_minutely_price目录，生成minutely_data_count.csv（统计每只股票的分钟数据日期分布）\n",
    "    \"\"\"\n",
    "    print(f\"📥 开始读取分钟数据目录：{root_dir}\")\n",
    "    stats_list = []\n",
    "    \n",
    "    # 遍历所有股票子目录（格式：stock_code=XXX.XSHE/XSHG）\n",
    "    for stock_folder in Path(root_dir).iterdir():\n",
    "        if not stock_folder.is_dir() or \"stock_code=\" not in stock_folder.name:\n",
    "            continue\n",
    "        \n",
    "        # 提取股票代码\n",
    "        stock_code = stock_folder.name.split(\"stock_code=\")[-1]\n",
    "        data_path = stock_folder / \"data.parquet\"\n",
    "        \n",
    "        if not data_path.exists():\n",
    "            print(f\"⚠️ 跳过{stock_code}：缺少data.parquet文件\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # 仅读取date列，统计日期分布\n",
    "            df = pd.read_parquet(data_path, columns=[\"date\"])\n",
    "            df[\"date\"] = pd.to_datetime(df[\"date\"]).dt.strftime(\"%Y-%m-%d\")\n",
    "            # 按日期统计数据条数（单股票单日）\n",
    "            daily_count = df.groupby(\"date\").size().reset_index(name=\"data_count\")\n",
    "            daily_count[\"stock_code\"] = stock_code\n",
    "            stats_list.append(daily_count)\n",
    "            print(f\"✅ 处理完成：{stock_code}（{len(daily_count)}天数据）\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ 读取{stock_code}失败：{str(e)[:50]}...\")\n",
    "            continue\n",
    "    \n",
    "    # 合并统计结果并保存\n",
    "    if not stats_list:\n",
    "        raise ValueError(\"❌ 未读取到任何有效分钟数据\")\n",
    "    \n",
    "    minutely_count_df = pd.concat(stats_list, ignore_index=True)\n",
    "    minutely_count_df = minutely_count_df.sort_values([\"stock_code\", \"date\"]).reset_index(drop=True)\n",
    "    minutely_count_df.to_csv(output_csv, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"\\n💾 minutely_data_count.csv已保存至：{output_csv}\")\n",
    "    print(f\"📊 分钟数据统计：共{minutely_count_df['stock_code'].nunique()}只股票，{len(minutely_count_df)}个（日期-股票）组合\")\n",
    "    return minutely_count_df\n",
    "\n",
    "def compare_stock_code_diff(minutely_count_df: pd.DataFrame, daily_data_path: str) -> None:\n",
    "    \"\"\"\n",
    "    比对分钟数据与日线数据（2025年+paused==0）的股票代码差异\n",
    "    \"\"\"\n",
    "    print(f\"\\n🔍 开始比对股票代码差异...\")\n",
    "    \n",
    "    # 1. 提取分钟数据中的所有股票代码（去重）\n",
    "    minutely_stocks = set(minutely_count_df[\"stock_code\"].unique())\n",
    "    print(f\"分钟数据中的股票数：{len(minutely_stocks)}\")\n",
    "    \n",
    "    # 2. 提取日线数据中2025年未停牌的股票代码（去重）\n",
    "    daily_df = pd.read_parquet(daily_data_path)\n",
    "    daily_df[\"date\"] = pd.to_datetime(daily_df[\"date\"])\n",
    "    # 筛选条件：2025年 + 未停牌\n",
    "    daily_2025_paused_0 = daily_df[\n",
    "        (daily_df[\"date\"].dt.year == 2025) & \n",
    "        (daily_df[\"paused\"] == 0)\n",
    "    ]\n",
    "    daily_stocks = set(daily_2025_paused_0[\"stock_code\"].unique())\n",
    "    print(f\"日线数据（2025年+未停牌）中的股票数：{len(daily_stocks)}\")\n",
    "    \n",
    "    # 3. 计算差异\n",
    "    # 分钟数据有但日线数据无的股票（可能是日线数据缺失或股票已退市）\n",
    "    min_only_stocks = minutely_stocks - daily_stocks\n",
    "    # 日线数据有但分钟数据无的股票（需重点关注，可能是分钟数据未抓取）\n",
    "    daily_only_stocks = daily_stocks - minutely_stocks\n",
    "    \n",
    "    # 4. 输出差异结果\n",
    "    print(f\"\\n📊 股票代码差异统计：\")\n",
    "    print(f\"1. 分钟数据独有股票数：{len(min_only_stocks)}\")\n",
    "    if len(min_only_stocks) > 0:\n",
    "        print(f\"   示例（前10只）：{list(min_only_stocks)[:10]}\")\n",
    "    \n",
    "    print(f\"\\n2. 日线数据（2025+未停牌）独有股票数：{len(daily_only_stocks)}\")\n",
    "    if len(daily_only_stocks) > 0:\n",
    "        print(f\"   示例（前10只）：{list(daily_only_stocks)[:10]}\")\n",
    "    \n",
    "    # 5. 保存差异结果（便于后续处理）\n",
    "    diff_result = pd.DataFrame({\n",
    "        \"diff_type\": [\"min_only\"] * len(min_only_stocks) + [\"daily_only\"] * len(daily_only_stocks),\n",
    "        \"stock_code\": list(min_only_stocks) + list(daily_only_stocks)\n",
    "    })\n",
    "    diff_output = r\"D:\\workspace\\xiaoyao\\works\\tools\\stock_code_diff.csv\"\n",
    "    diff_result.to_csv(diff_output, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"\\n💾 差异结果已保存至：{diff_output}\")\n",
    "\n",
    "# --------------------------\n",
    "# 执行入口：生成CSV + 比对差异\n",
    "# --------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # 配置路径\n",
    "    MINUTELY_ROOT_DIR = r\"D:\\workspace\\xiaoyao\\data\\stock_minutely_price\"  # 分钟数据根目录\n",
    "    MINUTELY_COUNT_CSV = r\"D:\\workspace\\xiaoyao\\works\\tools\\minutely_data_count.csv\"  # 生成的统计CSV\n",
    "    DAILY_DATA_PATH = r\"D:\\workspace\\xiaoyao\\data\\stock_daily_price.parquet\"  # 日线数据路径\n",
    "    \n",
    "    try:\n",
    "        # 1. 生成minutely_data_count.csv\n",
    "        minutely_count_df = generate_minutely_count_csv(MINUTELY_ROOT_DIR, MINUTELY_COUNT_CSV)\n",
    "        \n",
    "        # 2. 比对股票代码差异\n",
    "        compare_stock_code_diff(minutely_count_df, DAILY_DATA_PATH)\n",
    "        \n",
    "        print(f\"\\n✅ 所有流程完成！\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ 执行失败：{str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61d7ef96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📅 开始统计目标日期：2025-10-28 的分钟数据分布\n",
      "🔍 已处理100只股票，当前：000517.XSHE\n",
      "🔍 已处理200只股票，当前：000670.XSHE\n",
      "🔍 已处理300只股票，当前：000821.XSHE\n",
      "🔍 已处理400只股票，当前：000980.XSHE\n",
      "🔍 已处理500只股票，当前：001373.XSHE\n",
      "🔍 已处理600只股票，当前：002086.XSHE\n",
      "🔍 已处理700只股票，当前：002192.XSHE\n",
      "🔍 已处理800只股票，当前：002297.XSHE\n",
      "🔍 已处理900只股票，当前：002402.XSHE\n",
      "🔍 已处理1000只股票，当前：002517.XSHE\n",
      "🔍 已处理1100只股票，当前：002623.XSHE\n",
      "🔍 已处理1200只股票，当前：002731.XSHE\n",
      "🔍 已处理1300只股票，当前：002846.XSHE\n",
      "🔍 已处理1400只股票，当前：002955.XSHE\n",
      "🔍 已处理1500只股票，当前：300017.XSHE\n",
      "🔍 已处理1600只股票，当前：300130.XSHE\n",
      "🔍 已处理1700只股票，当前：300237.XSHE\n",
      "🔍 已处理1800只股票，当前：300347.XSHE\n",
      "🔍 已处理1900只股票，当前：300456.XSHE\n",
      "🔍 已处理2000只股票，当前：300560.XSHE\n",
      "🔍 已处理2100只股票，当前：300663.XSHE\n",
      "🔍 已处理2200只股票，当前：300771.XSHE\n",
      "🔍 已处理2300只股票，当前：300873.XSHE\n",
      "🔍 已处理2400只股票，当前：300980.XSHE\n",
      "🔍 已处理2500只股票，当前：301087.XSHE\n",
      "🔍 已处理2600只股票，当前：301205.XSHE\n",
      "🔍 已处理2700只股票，当前：301325.XSHE\n",
      "🔍 已处理2800只股票，当前：301528.XSHE\n",
      "🔍 已处理2900只股票，当前：600039.XSHG\n",
      "🔍 已处理3000只股票，当前：600177.XSHG\n",
      "🔍 已处理3100只股票，当前：600310.XSHG\n",
      "🔍 已处理3200只股票，当前：600455.XSHG\n",
      "🔍 已处理3300只股票，当前：600582.XSHG\n",
      "🔍 已处理3400只股票，当前：600706.XSHG\n",
      "🔍 已处理3500只股票，当前：600822.XSHG\n",
      "🔍 已处理3600只股票，当前：600973.XSHG\n",
      "🔍 已处理3700只股票，当前：601222.XSHG\n",
      "🔍 已处理3800只股票，当前：601860.XSHG\n",
      "🔍 已处理3900只股票，当前：603061.XSHG\n",
      "🔍 已处理4000只股票，当前：603187.XSHG\n",
      "🔍 已处理4100只股票，当前：603318.XSHG\n",
      "🔍 已处理4200只股票，当前：603535.XSHG\n",
      "🔍 已处理4300只股票，当前：603717.XSHG\n",
      "🔍 已处理4400只股票，当前：603915.XSHG\n",
      "🔍 已处理4500只股票，当前：605177.XSHG\n",
      "🔍 已处理4600只股票，当前：688045.XSHG\n",
      "🔍 已处理4700只股票，当前：688159.XSHG\n",
      "🔍 已处理4800只股票，当前：688275.XSHG\n",
      "🔍 已处理4900只股票，当前：688388.XSHG\n",
      "🔍 已处理5000只股票，当前：688562.XSHG\n",
      "🔍 已处理5100只股票，当前：688693.XSHG\n",
      "\n",
      "💾 结果已保存至：D:\\workspace\\xiaoyao\\works\\tools\\20251023_minutely_count.csv\n",
      "📊 统计结果：2025-10-28共有5153只股票有分钟数据，平均每只240.0条\n",
      "✅ 单个日期统计完成！\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def generate_single_date_minutely_count(root_dir: str, target_date: str, output_csv: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    只统计指定日期的分钟数据分布（如2025-10-23），输出包含股票代码和该日期数据条数的CSV\n",
    "    \n",
    "    参数:\n",
    "        root_dir: 分钟数据根目录（包含stock_code=XXX子文件夹）\n",
    "        target_date: 目标日期，格式需为\"YYYY-MM-DD\"\n",
    "        output_csv: 结果保存路径\n",
    "    \"\"\"\n",
    "    print(f\"📅 开始统计目标日期：{target_date} 的分钟数据分布\")\n",
    "    stats_list = []\n",
    "    \n",
    "    # 遍历所有股票子目录\n",
    "    for stock_folder in Path(root_dir).iterdir():\n",
    "        if not stock_folder.is_dir() or \"stock_code=\" not in stock_folder.name:\n",
    "            continue\n",
    "        \n",
    "        # 提取股票代码\n",
    "        stock_code = stock_folder.name.split(\"stock_code=\")[-1]\n",
    "        data_path = stock_folder / \"data.parquet\"\n",
    "        \n",
    "        if not data_path.exists():\n",
    "            # print(f\"⚠️ 跳过{stock_code}：无data.parquet文件\")  # 可选：减少输出加快速度\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # 仅读取date列，聚焦目标日期\n",
    "            df = pd.read_parquet(data_path, columns=[\"date\"])\n",
    "            # 转换日期格式并筛选目标日期\n",
    "            df[\"date\"] = pd.to_datetime(df[\"date\"]).dt.strftime(\"%Y-%m-%d\")\n",
    "            target_data = df[df[\"date\"] == target_date]\n",
    "            \n",
    "            if not target_data.empty:\n",
    "                # 统计该日期的分钟数据条数\n",
    "                data_count = len(target_data)\n",
    "                stats_list.append({\n",
    "                    \"stock_code\": stock_code,\n",
    "                    \"target_date\": target_date,\n",
    "                    \"data_count\": data_count\n",
    "                })\n",
    "                # 每100只股票打印一次进度（减少IO耗时）\n",
    "                if len(stats_list) % 100 == 0:\n",
    "                    print(f\"🔍 已处理{len(stats_list)}只股票，当前：{stock_code}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ {stock_code}处理失败：{str(e)[:30]}...\")\n",
    "            continue\n",
    "    \n",
    "    # 处理结果\n",
    "    if not stats_list:\n",
    "        raise ValueError(f\"❌ 未找到{target_date}的任何分钟数据\")\n",
    "    \n",
    "    result_df = pd.DataFrame(stats_list)\n",
    "    result_df = result_df.sort_values(\"stock_code\").reset_index(drop=True)\n",
    "    result_df.to_csv(output_csv, index=False, encoding=\"utf-8-sig\")\n",
    "    \n",
    "    print(f\"\\n💾 结果已保存至：{output_csv}\")\n",
    "    print(f\"📊 统计结果：{target_date}共有{len(result_df)}只股票有分钟数据，平均每只{result_df['data_count'].mean():.1f}条\")\n",
    "    return result_df\n",
    "\n",
    "\n",
    "# 执行示例\n",
    "if __name__ == \"__main__\":\n",
    "    # 配置参数\n",
    "    MINUTELY_ROOT_DIR = r\"D:\\workspace\\xiaoyao\\data\\stock_minutely_price\"  # 分钟数据根目录\n",
    "    TARGET_DATE = \"2025-10-28\"  # 目标日期\n",
    "    OUTPUT_CSV = r\"D:\\workspace\\xiaoyao\\works\\tools\\20251023_minutely_count.csv\"  # 输出路径\n",
    "    \n",
    "    try:\n",
    "        df = generate_single_date_minutely_count(\n",
    "            root_dir=MINUTELY_ROOT_DIR,\n",
    "            target_date=TARGET_DATE,\n",
    "            output_csv=OUTPUT_CSV\n",
    "        )\n",
    "        print(\"✅ 单个日期统计完成！\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 执行失败：{e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af36822",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xiaoyao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
