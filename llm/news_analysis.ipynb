{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c2b9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-11 16:40:05,740 - INFO - LLM客户端初始化成功\n",
      "2025-10-11 16:40:05,740 - INFO - 读取输入Parquet：../data/stock_daily_cctvnews.parquet\n",
      "2025-10-11 16:40:05,822 - INFO - 读取 16 条新闻，已按id逆序\n",
      "2025-10-11 16:40:05,824 - INFO - 分析第 1/16 条新闻（ID：118222）\n",
      "2025-10-11 16:40:05,825 - INFO - 开始分析单条新闻（ID：news_single_20251011164005_894，标题：习近平就朝鲜劳动党成立80周年向朝鲜劳动党总书记金正恩致贺电...）\n",
      "2025-10-11 16:40:05,826 - INFO - 请求模型: qwen3:30b-a3b-instruct-2507-q4_K_M\n",
      "2025-10-11 16:40:05,827 - INFO - 用户消息: 标题：习近平就朝鲜劳动党成立80周年向朝鲜劳动党总书记金正恩致贺电\n",
      "内容：央视网消息\n",
      "（新闻联播）：10月10日，中共中央总书记习近平致电朝鲜劳动党总书记金正恩，祝贺朝鲜劳动党成立80周年。\n",
      "习近平在贺电中说，在朝鲜劳动党成立80周年之际，我谨代表中国共产党中央委员会，并以我个人名义，向总书记同志和朝鲜劳动党中央、全体朝鲜劳动党党员以及朝鲜人民致以热烈祝贺和美好祝福。\n",
      "习近平表示，80年来，朝鲜劳动党团结带领朝鲜人民奋发进取、攻坚克难，推动朝鲜社会主义事业取得可喜成就。近年来，总书记同志领导朝鲜党和人民积极致力于加强党建、发展经济、改善民生。祝愿在以总书记同志为首的朝鲜劳动党坚强领导下，朝鲜社会主义事业不断取得新成就，迎接朝鲜劳动党九大胜利召开。\n",
      "习近平强调，中朝两国同为共产党领导的社会主义国家。近年来，我同总书记同志多次会晤，为两党两国关系发展领航把舵，开启中朝友谊崭新篇章。前不久，总书记同志来华出席纪念中国人民抗日战争暨世界反法西斯战争胜利80周年活动，我同总书记同志深入会谈，为中朝双方进一步发展友好合作关系指明了前进方向。无论国际形势如何变化，维护好、巩固好、发展好中朝关系，始终是中国党和政府不变的方针。中方愿同朝方一道，加强战略沟通，深化务实合作，密切协调配合，推动中朝关系不断向前发展，服务两国社会主义建设事业，为地区乃至世界和平稳定和发展繁荣作出积极贡献。祝愿朝鲜劳动党不断取得更大成就！祝愿中朝友谊万古长青！\n",
      "2025-10-11 16:40:05,828 - INFO - 参数: {'temperature': 0.4, 'max_tokens': 20000}\n",
      "2025-10-11 16:40:07,565 - INFO - 响应内容: {\"positive\": []}...\n",
      "2025-10-11 16:40:07,566 - INFO - 响应时间: 1738.51毫秒\n",
      "2025-10-11 16:40:07,567 - INFO - 请求模型: qwen3:30b-a3b-instruct-2507-q4_K_M\n",
      "2025-10-11 16:40:07,568 - INFO - 用户消息: 正方首次观点：{\"positive\": []}\n",
      "新闻内容：标题：习近平就朝鲜劳动党成立80周年向朝鲜劳动党总书记金正恩致贺电\n",
      "内容：央视网消息\n",
      "（新闻联播）：10月10日，中共中央总书记习近平致电朝鲜劳动党总书记金正恩，祝贺朝鲜劳动党成立80周年。\n",
      "习近平在贺电中说，在朝鲜劳动党成立80周年之际，我谨代表中国共产党中央委员会，并以我个人名义，向总书记同志和朝鲜劳动党中央、全体朝鲜劳动党党员以及朝鲜人民致以热烈祝贺和美好祝福。\n",
      "习近平表示，80年来，朝鲜劳动党团结带领朝鲜人民奋发进取、攻坚克难，推动朝鲜社会主义事业取得可喜成就。近年来，总书记同志领导朝鲜党和人民积极致力于加强党建、发展经济、改善民生。祝愿在以总书记同志为首的朝鲜劳动党坚强领导下，朝鲜社会主义事业不断取得新成就，迎接朝鲜劳动党九大胜利召开。\n",
      "习近平强调，中朝两国同为共产党领导的社会主义国家。近年来，我同总书记同志多次会晤，为两党两国关系发展领航把舵，开启中朝友谊崭新篇章。前不久，总书记同志来华出席纪念中国人民抗日战争暨世界反法西斯战争胜利80周年活动，我同总书记同志深入会谈，为中朝双方进一步发展友好合作关系指明了前进方向。无论国际形势如何变化，维护好、巩固好、发展好中朝关系，始终是中国党和政府不变的方针。中方愿同朝方一道，加强战略沟通，深化务实合作，密切协调配合，推动中朝关系不断向前发展，服务两国社会主义建设事业，为地区乃至世界和平稳定和发展繁荣作出积极贡献。祝愿朝鲜劳动党不断取得更大成就！祝愿中朝友谊万古长青！\n",
      "请针对正方观点进行驳斥并提出利空\n",
      "2025-10-11 16:40:07,569 - INFO - 参数: {'temperature': 0.4, 'max_tokens': 20000}\n",
      "2025-10-11 16:40:10,516 - INFO - 响应内容: {\"negative\": [], \"refute\": \"中朝关系升温属地缘政治利好，但对A股相关行业无实质经济拉动，难形成可交易的产业逻辑，纯属情绪驱动，不具备投资价值。\"}...\n",
      "2025-10-11 16:40:10,517 - INFO - 响应时间: 2948.77毫秒\n",
      "2025-10-11 16:40:10,518 - INFO - 请求模型: qwen3:30b-a3b-instruct-2507-q4_K_M\n",
      "2025-10-11 16:40:10,519 - INFO - 用户消息: 之前的辩论内容：{\"pro_initial\": {\"positive\": []}, \"anti_initial\": {\"negative\": [], \"refute\": \"中朝关系升温属地缘政治利好，但对A股相关行业无实质经济拉动，难形成可交易的产业逻辑，纯属情绪驱动，不具备投资价值。\"}}\n",
      "新闻内容：标题：习近平就朝鲜劳动党成立80周年向朝鲜劳动党总书记金正恩致贺电\n",
      "内容：央视网消息\n",
      "（新闻联播）：10月10日，中共中央总书记习近平致电朝鲜劳动党总书记金正恩，祝贺朝鲜劳动党成立80周年。\n",
      "习近平在贺电中说，在朝鲜劳动党成立80周年之际，我谨代表中国共产党中央委员会，并以我个人名义，向总书记同志和朝鲜劳动党中央、全体朝鲜劳动党党员以及朝鲜人民致以热烈祝贺和美好祝福。\n",
      "习近平表示，80年来，朝鲜劳动党团结带领朝鲜人民奋发进取、攻坚克难，推动朝鲜社会主义事业取得可喜成就。近年来，总书记同志领导朝鲜党和人民积极致力于加强党建、发展经济、改善民生。祝愿在以总书记同志为首的朝鲜劳动党坚强领导下，朝鲜社会主义事业不断取得新成就，迎接朝鲜劳动党九大胜利召开。\n",
      "习近平强调，中朝两国同为共产党领导的社会主义国家。近年来，我同总书记同志多次会晤，为两党两国关系发展领航把舵，开启中朝友谊崭新篇章。前不久，总书记同志来华出席纪念中国人民抗日战争暨世界反法西斯战争胜利80周年活动，我同总书记同志深入会谈，为中朝双方进一步发展友好合作关系指明了前进方向。无论国际形势如何变化，维护好、巩固好、发展好中朝关系，始终是中国党和政府不变的方针。中方愿同朝方一道，加强战略沟通，深化务实合作，密切协调配合，推动中朝关系不断向前发展，服务两国社会主义建设事业，为地区乃至世界和平稳定和发展繁荣作出积极贡献。祝愿朝鲜劳动党不断取得更大成就！祝愿中朝友谊万古长青！\n",
      "请根据上述信息进行回应\n",
      "2025-10-11 16:40:10,519 - INFO - 参数: {'temperature': 0.5, 'max_tokens': 20000}\n",
      "2025-10-11 16:40:12,667 - INFO - 响应内容: {\"positive\": [{\"industry\":\"军工\",\"reason\":\"中朝关系升温释放地缘政治缓和信号，但更关键的是强化区域安全预期，军工板块受益于潜在防御需求上升，具备明确产业逻辑，非纯情绪驱动。\",\"stocks\":[{\"name\":\"中航沈飞\",\"code\":\"600760\",\"reason\":\"受益于区域安全局势变化，军工主机厂核心标的，订单预期明确。\"}]}],\"respon...\n",
      "2025-10-11 16:40:12,668 - INFO - 响应时间: 2149.31毫秒\n",
      "2025-10-11 16:40:12,669 - INFO - 请求模型: qwen3:30b-a3b-instruct-2507-q4_K_M\n",
      "2025-10-11 16:40:12,670 - INFO - 用户消息: 之前的辩论内容：{\"previous\": \"{\\\"pro_initial\\\": {\\\"positive\\\": []}, \\\"anti_initial\\\": {\\\"negative\\\": [], \\\"refute\\\": \\\"中朝关系升温属地缘政治利好，但对A股相关行业无实质经济拉动，难形成可交易的产业逻辑，纯属情绪驱动，不具备投资价值。\\\"}}\", \"pro_resp\": {\"positive\": [{\"industry\": \"军工\", \"reason\": \"中朝关系升温释放地缘政治缓和信号，但更关键的是强化区域安全预期，军工板块受益于潜在防御需求上升，具备明确产业逻辑，非纯情绪驱动。\", \"stocks\": [{\"name\": \"中航沈飞\", \"code\": \"600760\", \"reason\": \"受益于区域安全局势变化，军工主机厂核心标的，订单预期明确。\"}]}], \"response\": \"地缘政治升温直接推动军工防御逻辑强化，相关企业订单与政策支持预期提升，具备可交易产业基础，非情绪驱动。\"}}\n",
      "新闻内容：标题：习近平就朝鲜劳动党成立80周年向朝鲜劳动党总书记金正恩致贺电\n",
      "内容：央视网消息\n",
      "（新闻联播）：10月10日，中共中央总书记习近平致电朝鲜劳动党总书记金正恩，祝贺朝鲜劳动党成立80周年。\n",
      "习近平在贺电中说，在朝鲜劳动党成立80周年之际，我谨代表中国共产党中央委员会，并以我个人名义，向总书记同志和朝鲜劳动党中央、全体朝鲜劳动党党员以及朝鲜人民致以热烈祝贺和美好祝福。\n",
      "习近平表示，80年来，朝鲜劳动党团结带领朝鲜人民奋发进取、攻坚克难，推动朝鲜社会主义事业取得可喜成就。近年来，总书记同志领导朝鲜党和人民积极致力于加强党建、发展经济、改善民生。祝愿在以总书记同志为首的朝鲜劳动党坚强领导下，朝鲜社会主义事业不断取得新成就，迎接朝鲜劳动党九大胜利召开。\n",
      "习近平强调，中朝两国同为共产党领导的社会主义国家。近年来，我同总书记同志多次会晤，为两党两国关系发展领航把舵，开启中朝友谊崭新篇章。前不久，总书记同志来华出席纪念中国人民抗日战争暨世界反法西斯战争胜利80周年活动，我同总书记同志深入会谈，为中朝双方进一步发展友好合作关系指明了前进方向。无论国际形势如何变化，维护好、巩固好、发展好中朝关系，始终是中国党和政府不变的方针。中方愿同朝方一道，加强战略沟通，深化务实合作，密切协调配合，推动中朝关系不断向前发展，服务两国社会主义建设事业，为地区乃至世界和平稳定和发展繁荣作出积极贡献。祝愿朝鲜劳动党不断取得更大成就！祝愿中朝友谊万古长青！\n",
      "请根据上述信息进行回应\n",
      "2025-10-11 16:40:12,671 - INFO - 参数: {'temperature': 0.5, 'max_tokens': 20000}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import logging\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Optional, Dict, List, Tuple\n",
    "from client import LocalLLMClient, create_client\n",
    "from news_function import analyze_news_single  # 复用单条分析函数\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 1. 基础配置\n",
    "# --------------------------\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - 批量拆分分析 - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"batch_split_analysis.log\", encoding='utf-8'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# 结果存储目录（自动创建）\n",
    "OUTPUT_DIR = Path(\"batch_split_results\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# 定期保存的批次大小（每处理10条新闻保存一次）\n",
    "CHECKPOINT_BATCH_SIZE = 10\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 2. 工具函数：追加数据到Parquet文件\n",
    "# --------------------------\n",
    "def append_to_parquet(df: pd.DataFrame, file_path: str, schema: Optional[pa.Schema] = None):\n",
    "    \"\"\"\n",
    "    将DataFrame追加到现有的Parquet文件\n",
    "    \n",
    "    参数：\n",
    "    - df: 要追加的数据\n",
    "    - file_path: 目标Parquet文件路径\n",
    "    - schema: 数据 schema，确保一致性\n",
    "    \"\"\"\n",
    "    table = pa.Table.from_pandas(df)\n",
    "    \n",
    "    # 如果文件不存在，创建新文件；否则追加\n",
    "    if not Path(file_path).exists():\n",
    "        # 使用当前表的schema作为初始schema\n",
    "        pq.write_table(table, file_path)\n",
    "    else:\n",
    "        # 确保schema一致\n",
    "        if schema is None:\n",
    "            existing_table = pq.read_table(file_path)\n",
    "            schema = existing_table.schema\n",
    "        \n",
    "        # 追加数据\n",
    "        with pq.ParquetWriter(file_path, schema) as writer:\n",
    "            writer.write_table(table)\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 3. 核心函数：生成双表数据（单批次）\n",
    "# --------------------------\n",
    "def _process_batch(batch_results: List[Dict]) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"处理单批次结果，生成行业裁决表和个股推荐表的DataFrame片段\"\"\"\n",
    "    industry_records: List[Dict] = []\n",
    "    stock_records: List[Dict] = []\n",
    "\n",
    "    for result in batch_results:\n",
    "        # 基础元数据\n",
    "        base_meta = {\n",
    "            \"original_news_id\": result[\"original_news_id\"],\n",
    "            \"original_news_date\": result[\"original_news_date\"],\n",
    "            \"original_news_title\": result[\"original_news_title\"],\n",
    "            \"analysis_status\": result[\"status\"],\n",
    "            \"error_msg\": result[\"error_msg\"],\n",
    "            \"log_path\": result[\"log_path\"],\n",
    "            \"analysis_time\": result[\"analysis_batch_time\"]\n",
    "        }\n",
    "\n",
    "        # 处理分析失败的记录\n",
    "        if result[\"status\"] == \"failed\":\n",
    "            industry_records.append({\n",
    "                **base_meta,\n",
    "                \"analysis_id\": f\"ana_{uuid.uuid4().hex[:8]}\",\n",
    "                \"industry\": \"\",\n",
    "                \"impact_direction\": \"\",\n",
    "                \"confidence_score\": 0,\n",
    "                \"comprehensive_reason\": \"\"\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # 处理分析成功的记录\n",
    "        for industry in result[\"ruled_industries\"]:\n",
    "            current_analysis_id = f\"ana_{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "            # 行业裁决主表记录\n",
    "            industry_records.append({\n",
    "                **base_meta,\n",
    "                \"analysis_id\": current_analysis_id,\n",
    "                \"industry\": industry.get(\"industry\", \"\"),\n",
    "                \"impact_direction\": industry.get(\"impact\", \"\"),\n",
    "                \"confidence_score\": industry.get(\"confidence\", 0),\n",
    "                \"comprehensive_reason\": industry.get(\"comprehensive_reason\", \"\")\n",
    "            })\n",
    "\n",
    "            # 个股推荐副表记录\n",
    "            for rank, stock in enumerate(industry.get(\"stocks\", []), 1):\n",
    "                stock_records.append({\n",
    "                    \"analysis_id\": current_analysis_id,\n",
    "                    \"stock_name\": stock.get(\"name\", \"\"),\n",
    "                    \"stock_code\": stock.get(\"code\", \"\"),\n",
    "                    \"recommendation_reason\": stock.get(\"reason\", \"\"),\n",
    "                    \"stock_rank\": rank\n",
    "                })\n",
    "\n",
    "    # 转换为DataFrame并调整字段顺序\n",
    "    industry_df = pd.DataFrame(industry_records)[[\n",
    "        \"analysis_id\", \"original_news_id\", \"original_news_date\", \"original_news_title\",\n",
    "        \"industry\", \"impact_direction\", \"confidence_score\", \"comprehensive_reason\",\n",
    "        \"analysis_status\", \"error_msg\", \"log_path\", \"analysis_time\"\n",
    "    ]]\n",
    "\n",
    "    stock_df = pd.DataFrame(stock_records)[[\n",
    "        \"analysis_id\", \"stock_name\", \"stock_code\", \"recommendation_reason\", \"stock_rank\"\n",
    "    ]]\n",
    "\n",
    "    return industry_df, stock_df\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 4. 批量分析主函数（带定期保存功能）\n",
    "# --------------------------\n",
    "def batch_analyze_split_parquet(\n",
    "    input_parquet: str,\n",
    "    news_date: str,\n",
    "    debate_rounds: int = 2,\n",
    "    llm_client: Optional[LocalLLMClient] = None,\n",
    "    checkpoint_batch_size: int = CHECKPOINT_BATCH_SIZE,** llm_kwargs\n",
    ") -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    批量分析Parquet新闻，带定期保存功能，防止程序崩溃导致数据丢失\n",
    "    \n",
    "    参数：\n",
    "    - input_parquet: 输入新闻Parquet路径\n",
    "    - news_date: 新闻日期\n",
    "    - debate_rounds: 辩论轮次\n",
    "    - llm_client: 已实例化的LLM客户端\n",
    "    - checkpoint_batch_size: 每处理多少条新闻保存一次\n",
    "    - **llm_kwargs: 创建LLM客户端的参数\n",
    "    \n",
    "    返回：\n",
    "    - 行业裁决表路径, 个股推荐表路径\n",
    "    \"\"\"\n",
    "    # 1. 初始化LLM客户端\n",
    "    if not llm_client:\n",
    "        try:\n",
    "            llm_client = create_client(** llm_kwargs)\n",
    "            logger.info(\"LLM客户端初始化成功\")\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"LLM客户端初始化失败：{str(e)}\")\n",
    "\n",
    "    # 2. 读取并处理输入Parquet（逆序）\n",
    "    try:\n",
    "        logger.info(f\"读取输入Parquet：{input_parquet}\")\n",
    "        input_df = pd.read_parquet(input_parquet)\n",
    "        required_cols = [\"id\", \"date\", \"title\", \"content\"]\n",
    "        missing_cols = [col for col in required_cols if col not in input_df.columns]\n",
    "        if missing_cols:\n",
    "            raise Exception(f\"输入缺少字段：{', '.join(missing_cols)}\")\n",
    "        \n",
    "        # 逆序处理（按新闻id降序）\n",
    "        # 筛选出指定日期的新闻\n",
    "        input_df_sorted = input_df[input_df[\"date\"] == news_date].sort_values(by=\"id\", ascending=True).reset_index(drop=True)\n",
    "        total_news = len(input_df_sorted)\n",
    "        logger.info(f\"读取 {total_news} 条新闻，已按id逆序\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"读取输入失败：{str(e)}\")\n",
    "\n",
    "    # 3. 准备输出文件路径（带时间戳）\n",
    "    time_suffix = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    industry_path = OUTPUT_DIR / f\"industry_verdict_{time_suffix}.parquet\"\n",
    "    stock_path = OUTPUT_DIR / f\"stock_recommendation_{time_suffix}.parquet\"\n",
    "    \n",
    "    # 4. 批量处理新闻，定期保存\n",
    "    batch_results: List[Dict] = []\n",
    "    processed_count = 0\n",
    "    industry_schema = None\n",
    "    stock_schema = None\n",
    "\n",
    "    for idx, row in input_df_sorted.iterrows():\n",
    "        news_id = str(row[\"id\"])\n",
    "        logger.info(f\"分析第 {idx+1}/{total_news} 条新闻（ID：{news_id}）\")\n",
    "        \n",
    "        # 调用单条分析函数\n",
    "        single_result = analyze_news_single(\n",
    "            news_title=str(row[\"title\"]),\n",
    "            news_content=str(row[\"content\"]),\n",
    "            debate_rounds=debate_rounds,\n",
    "            llm_client=llm_client\n",
    "        )\n",
    "\n",
    "        # 补充原始新闻元数据\n",
    "        single_result.update({\n",
    "            \"original_news_id\": news_id,\n",
    "            \"original_news_date\": str(row[\"date\"]),\n",
    "            \"original_news_title\": str(row[\"title\"]),\n",
    "            \"analysis_batch_time\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        })\n",
    "        batch_results.append(single_result)\n",
    "        processed_count += 1\n",
    "\n",
    "        # 达到批次大小，保存一次数据\n",
    "        if processed_count % checkpoint_batch_size == 0 or processed_count == total_news:\n",
    "            logger.info(f\"已处理 {processed_count}/{total_news} 条新闻，开始保存中间结果...\")\n",
    "            \n",
    "            # 处理当前批次结果\n",
    "            batch_industry_df, batch_stock_df = _process_batch(batch_results)\n",
    "            \n",
    "            # 首次保存时确定schema\n",
    "            if industry_schema is None and not batch_industry_df.empty:\n",
    "                industry_schema = pa.Table.from_pandas(batch_industry_df).schema\n",
    "            if stock_schema is None and not batch_stock_df.empty:\n",
    "                stock_schema = pa.Table.from_pandas(batch_stock_df).schema\n",
    "            \n",
    "            # 追加保存\n",
    "            append_to_parquet(batch_industry_df, str(industry_path), industry_schema)\n",
    "            append_to_parquet(batch_stock_df, str(stock_path), stock_schema)\n",
    "            \n",
    "            # 清空批次结果列表，准备下一批\n",
    "            batch_results = []\n",
    "            logger.info(f\"中间结果保存完成，行业裁决表：{industry_path}，个股推荐表：{stock_path}\")\n",
    "\n",
    "    logger.info(f\"全部处理完成，共处理 {processed_count} 条新闻\")\n",
    "    return str(industry_path), str(stock_path)\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 5. 使用示例\n",
    "# --------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # 配置参数\n",
    "    INPUT_PARQUET = \"../data/stock_daily_cctvnews.parquet\"  # 输入新闻路径\n",
    "    DEBATE_ROUNDS = 2  # 辩论轮次\n",
    "    CHECKPOINT_SIZE = 10  # 每处理10条新闻保存一次\n",
    "    LLM_KWARGS = {\n",
    "        # \"model\": \"gpt-4-turbo\",  # 实际使用时填写LLM参数\n",
    "        # \"api_key\": \"your_api_key\"\n",
    "    }\n",
    "    # 设定获取数据的日期为昨日\n",
    "    news_date = '2025-03-30' #(datetime.now() - timedelta(days=1)).strftime(\"%Y%m%d\")\n",
    "    try:\n",
    "        # 执行批量拆分分析\n",
    "        industry_table_path, stock_table_path = batch_analyze_split_parquet(\n",
    "            input_parquet=INPUT_PARQUET,\n",
    "            news_date=news_date,\n",
    "            debate_rounds=DEBATE_ROUNDS,\n",
    "            checkpoint_batch_size=CHECKPOINT_SIZE,\n",
    "            **LLM_KWARGS\n",
    "        )\n",
    "\n",
    "        # 打印结果\n",
    "        print(\"=\"*70)\n",
    "        print(\"批量拆分分析完成！\")\n",
    "        print(f\"输入文件：{INPUT_PARQUET}\")\n",
    "        print(f\"日期：{news_date}\")\n",
    "        print(f\"行业裁决表：{industry_table_path}\")\n",
    "        print(f\"个股推荐表：{stock_table_path}\")\n",
    "        print(f\"提示：程序在处理过程中已自动保存中间结果，可通过 'analysis_id' 字段关联两张表\")\n",
    "        print(\"=\"*70)\n",
    "    except Exception as e:\n",
    "        print(f\"批量分析失败：{str(e)}\")\n",
    "        logger.error(f\"批量分析失败：{str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c202206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xiaoyao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
